#!/usr/bin/env python3
"""
DocGate Agent æ€§èƒ½æµ‹è¯•
æµ‹è¯•ä¸åŒè§„æ¨¡æ–‡æ¡£çš„å¤„ç†æ€§èƒ½
"""

import sys
import os
import time
import tempfile
from pathlib import Path
sys.path.append('/home/xx/dev/Claude Enhancer 5.0')

from docgate_agent import DocGateAgent

def create_test_document(word_count: int, title: str = "Test Document") -> str:
    """åˆ›å»ºæµ‹è¯•æ–‡æ¡£"""
    content = f"# {title}\n\n"

    # ç”ŸæˆæŒ‡å®šå­—æ•°çš„å†…å®¹
    words_per_paragraph = 50
    paragraphs_needed = max(1, word_count // words_per_paragraph)

    sample_text = """
    This is a sample paragraph that demonstrates typical documentation content.
    It includes technical terms, explanations, and various sentence structures
    that would be found in real documentation. The content covers features,
    implementation details, usage examples, and best practices.
    """

    sample_words = sample_text.split()
    current_word_count = 0

    for i in range(paragraphs_needed):
        content += f"\n## Section {i+1}\n\n"

        paragraph_words = []
        while len(paragraph_words) < words_per_paragraph and current_word_count < word_count:
            word_index = current_word_count % len(sample_words)
            paragraph_words.append(sample_words[word_index])
            current_word_count += 1

        content += " ".join(paragraph_words) + "\n\n"

        if current_word_count >= word_count:
            break

    # æ·»åŠ ä¸€äº›ç»“æ„å…ƒç´ 
    content += """
## Features

- Feature one with detailed explanation
- Feature two with code examples
- Feature three with performance metrics

## Code Example

```python
def example_function():
    return "Hello, World!"
```

## Links

- [Documentation](https://example.com/docs)
- [GitHub Repository](https://github.com/example/repo)

## Table

| Feature | Status | Notes |
|---------|--------|-------|
| Quality | âœ… | High |
| Speed   | âœ… | Fast |
| Memory  | âš ï¸  | Medium |
"""

    return content

def performance_test_single_document():
    """æµ‹è¯•å•æ–‡æ¡£åˆ†ææ€§èƒ½"""
    print("ğŸ“Š å•æ–‡æ¡£åˆ†ææ€§èƒ½æµ‹è¯•")
    print("-" * 40)

    docgate = DocGateAgent()

    # æµ‹è¯•ä¸åŒå¤§å°çš„æ–‡æ¡£
    test_sizes = [100, 500, 1000, 2000, 5000]  # å­—æ•°

    results = []

    for word_count in test_sizes:
        print(f"\nğŸ“ æµ‹è¯• {word_count} å­—æ–‡æ¡£:")

        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        content = create_test_document(word_count, f"Test Doc {word_count} words")

        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8') as f:
            f.write(content)
            temp_file = f.name

        try:
            # æµ‹è¯•è´¨é‡åˆ†æ
            start_time = time.time()
            quality_result = docgate.analyze_document_quality(temp_file)
            quality_time = time.time() - start_time

            # æµ‹è¯•æ‘˜è¦ç”Ÿæˆ
            start_time = time.time()
            summary_result = docgate.generate_document_summary(temp_file)
            summary_time = time.time() - start_time

            if 'error' not in quality_result and 'error' not in summary_result:
                print(f"   âœ… è´¨é‡åˆ†æ: {quality_time:.3f}s (è¯„åˆ†: {quality_result['overall_score']:.1f})")
                print(f"   âœ… æ‘˜è¦ç”Ÿæˆ: {summary_time:.3f}s")

                results.append({
                    'word_count': word_count,
                    'quality_time': quality_time,
                    'summary_time': summary_time,
                    'total_time': quality_time + summary_time,
                    'quality_score': quality_result['overall_score']
                })
            else:
                print(f"   âŒ åˆ†æå¤±è´¥")

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_file)

    # åˆ†ææ€§èƒ½è¶‹åŠ¿
    if results:
        print(f"\nğŸ“ˆ æ€§èƒ½åˆ†æ:")
        print(f"   æœ€å¿«åˆ†æ: {min(r['total_time'] for r in results):.3f}s")
        print(f"   æœ€æ…¢åˆ†æ: {max(r['total_time'] for r in results):.3f}s")

        # è®¡ç®—å¤„ç†é€Ÿåº¦ï¼ˆå­—/ç§’ï¼‰
        speeds = [r['word_count'] / r['total_time'] for r in results]
        avg_speed = sum(speeds) / len(speeds)
        print(f"   å¹³å‡å¤„ç†é€Ÿåº¦: {avg_speed:.0f} å­—/ç§’")

    return results

def performance_test_batch_processing():
    """æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½"""
    print("\nğŸ”„ æ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•")
    print("-" * 40)

    docgate = DocGateAgent()

    # åˆ›å»ºå¤šä¸ªæµ‹è¯•æ–‡æ¡£
    test_files = []
    temp_dir = tempfile.mkdtemp()

    try:
        # åˆ›å»ºä¸åŒå¤§å°çš„æ–‡æ¡£
        for i in range(5):
            word_count = 200 + i * 100  # 200, 300, 400, 500, 600å­—
            content = create_test_document(word_count, f"Batch Test Doc {i+1}")

            file_path = os.path.join(temp_dir, f"test_doc_{i+1}.md")
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            test_files.append(file_path)

        print(f"ğŸ“ åˆ›å»ºäº† {len(test_files)} ä¸ªæµ‹è¯•æ–‡æ¡£")

        # æµ‹è¯•æ‰¹é‡åˆ†æ
        start_time = time.time()
        batch_result = docgate.batch_analyze_documents(['*.md'])
        batch_time = time.time() - start_time

        if 'error' not in batch_result:
            analyzed_count = len(batch_result.get('analyzed_files', []))
            stats = batch_result.get('summary_statistics', {})

            print(f"âœ… æ‰¹é‡åˆ†æå®Œæˆ:")
            print(f"   å¤„ç†æ—¶é—´: {batch_time:.3f}s")
            print(f"   åˆ†ææ–‡æ¡£æ•°: {analyzed_count}")
            if stats:
                print(f"   å¹³å‡è´¨é‡: {stats.get('average_quality', 0):.1f}/100")

            if analyzed_count > 0:
                print(f"   å¹³å‡å•æ–‡æ¡£æ—¶é—´: {batch_time/analyzed_count:.3f}s")
        else:
            print(f"âŒ æ‰¹é‡åˆ†æå¤±è´¥: {batch_result['error']}")

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for file_path in test_files:
            if os.path.exists(file_path):
                os.unlink(file_path)
        os.rmdir(temp_dir)

def performance_test_similarity_detection():
    """æµ‹è¯•ç›¸ä¼¼åº¦æ£€æµ‹æ€§èƒ½"""
    print("\nğŸ” ç›¸ä¼¼åº¦æ£€æµ‹æ€§èƒ½æµ‹è¯•")
    print("-" * 40)

    docgate = DocGateAgent()

    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£å¯¹
    temp_dir = tempfile.mkdtemp()
    test_files = []

    try:
        # åˆ›å»ºç›¸ä¼¼å’Œä¸åŒçš„æ–‡æ¡£å¯¹
        base_content = create_test_document(500, "Base Document")

        # åŸå§‹æ–‡æ¡£
        file1 = os.path.join(temp_dir, "original.md")
        with open(file1, 'w', encoding='utf-8') as f:
            f.write(base_content)
        test_files.append(file1)

        # ç•¥å¾®ä¿®æ”¹çš„æ–‡æ¡£ï¼ˆé«˜ç›¸ä¼¼åº¦ï¼‰
        modified_content = base_content.replace("Feature one", "Enhanced feature one")
        file2 = os.path.join(temp_dir, "modified.md")
        with open(file2, 'w', encoding='utf-8') as f:
            f.write(modified_content)
        test_files.append(file2)

        # å®Œå…¨ä¸åŒçš„æ–‡æ¡£ï¼ˆä½ç›¸ä¼¼åº¦ï¼‰
        different_content = create_test_document(500, "Different Document")
        file3 = os.path.join(temp_dir, "different.md")
        with open(file3, 'w', encoding='utf-8') as f:
            f.write(different_content)
        test_files.append(file3)

        print(f"ğŸ“ åˆ›å»ºäº† {len(test_files)} ä¸ªæ–‡æ¡£ç”¨äºç›¸ä¼¼åº¦æµ‹è¯•")

        # æµ‹è¯•ç›¸ä¼¼åº¦æ£€æµ‹
        start_time = time.time()
        similarity_results = docgate.detect_document_similarity(test_files)
        similarity_time = time.time() - start_time

        print(f"âœ… ç›¸ä¼¼åº¦æ£€æµ‹å®Œæˆ:")
        print(f"   å¤„ç†æ—¶é—´: {similarity_time:.3f}s")
        print(f"   æ¯”è¾ƒå¯¹æ•°: {len(similarity_results)}")

        for i, result in enumerate(similarity_results, 1):
            doc_a = os.path.basename(result.document_a)
            doc_b = os.path.basename(result.document_b)
            print(f"   {i}. {doc_a} vs {doc_b}: {result.similarity_ratio:.1%} ({result.similarity_type})")

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for file_path in test_files:
            if os.path.exists(file_path):
                os.unlink(file_path)
        os.rmdir(temp_dir)

def performance_test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    print("\nğŸ’¾ å†…å­˜ä½¿ç”¨æµ‹è¯•")
    print("-" * 40)

    try:
        import psutil
        process = psutil.Process()

        # è®°å½•åˆå§‹å†…å­˜
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        print(f"ğŸ“Š åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory:.1f} MB")

        docgate = DocGateAgent()

        # åˆ›å»ºå¤§æ–‡æ¡£æµ‹è¯•å†…å­˜ä½¿ç”¨
        large_content = create_test_document(10000, "Large Document")

        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8') as f:
            f.write(large_content)
            temp_file = f.name

        try:
            # åˆ†æå¤§æ–‡æ¡£
            memory_before = process.memory_info().rss / 1024 / 1024
            result = docgate.analyze_document_quality(temp_file)
            memory_after = process.memory_info().rss / 1024 / 1024

            print(f"ğŸ“Š åˆ†æå‰å†…å­˜: {memory_before:.1f} MB")
            print(f"ğŸ“Š åˆ†æåå†…å­˜: {memory_after:.1f} MB")
            print(f"ğŸ“Š å†…å­˜å¢é•¿: {memory_after - memory_before:.1f} MB")

            if 'error' not in result:
                print(f"âœ… å¤§æ–‡æ¡£åˆ†ææˆåŠŸ (è¯„åˆ†: {result['overall_score']:.1f})")
            else:
                print(f"âŒ å¤§æ–‡æ¡£åˆ†æå¤±è´¥")

        finally:
            os.unlink(temp_file)

    except ImportError:
        print("âš ï¸ psutilæœªå®‰è£…ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
    except Exception as e:
        print(f"âŒ å†…å­˜æµ‹è¯•å¤±è´¥: {str(e)}")

def main():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("ğŸš€ DocGate Agent æ€§èƒ½æµ‹è¯•")
    print("=" * 50)

    try:
        # å•æ–‡æ¡£æ€§èƒ½æµ‹è¯•
        single_results = performance_test_single_document()

        # æ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•
        performance_test_batch_processing()

        # ç›¸ä¼¼åº¦æ£€æµ‹æ€§èƒ½æµ‹è¯•
        performance_test_similarity_detection()

        # å†…å­˜ä½¿ç”¨æµ‹è¯•
        performance_test_memory_usage()

        print(f"\nğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆ!")

        # æ€»ç»“
        if single_results:
            total_words = sum(r['word_count'] for r in single_results)
            total_time = sum(r['total_time'] for r in single_results)
            avg_quality = sum(r['quality_score'] for r in single_results) / len(single_results)

            print(f"\nğŸ“ˆ æµ‹è¯•æ€»ç»“:")
            print(f"   æ€»å¤„ç†å­—æ•°: {total_words:,}")
            print(f"   æ€»å¤„ç†æ—¶é—´: {total_time:.3f}s")
            print(f"   æ•´ä½“å¤„ç†é€Ÿåº¦: {total_words/total_time:.0f} å­—/ç§’")
            print(f"   å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality:.1f}/100")

        print(f"\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        print(f"   - å¯¹äºå¤§å‹é¡¹ç›®ï¼Œå»ºè®®ä½¿ç”¨æ–‡ä»¶æ¨¡å¼è¿‡æ»¤")
        print(f"   - æ‰¹é‡å¤„ç†æ¯”å•ä¸ªå¤„ç†æ›´é«˜æ•ˆ")
        print(f"   - å®šæœŸæ¸…ç†ç¼“å­˜ä»¥èŠ‚çœå†…å­˜")
        print(f"   - è€ƒè™‘å¼‚æ­¥å¤„ç†å¤§é‡æ–‡æ¡£")

    except KeyboardInterrupt:
        print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()