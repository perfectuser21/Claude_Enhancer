#!/usr/bin/env python3
"""
Agent Output Summarizer - æ™ºèƒ½æ”¶é›†å’Œæ±‡æ€»å¤šAgentå¹¶è¡Œæ‰§è¡Œç»“æœ
ç”¨äºè§£å†³8ä¸ªagentså¹¶è¡Œæ‰§è¡Œæ—¶è¾“å‡ºè¿‡å¤šå¯¼è‡´çš„é—®é¢˜
"""

import json
import sys
import os
import time
from datetime import datetime
from pathlib import Path
import hashlib
import re
from typing import Dict, List, Any, Optional
from collections import defaultdict


class AgentOutputSummarizer:
    """Agentè¾“å‡ºæ”¶é›†å’Œæ±‡æ€»å™¨"""

    def __init__(self):
        self.project_root = os.environ.get(
            "CLAUDE_PROJECT_DIR", "/home/xx/dev/Claude Enhancer 5.0"
        )
        self.cache_dir = Path(self.project_root) / ".claude" / "agent_outputs"
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # è¾“å‡ºé™åˆ¶
        self.MAX_OUTPUT_SIZE = 10 * 1024 * 1024  # 10MB per agent
        self.MAX_TOTAL_SIZE = 50 * 1024 * 1024  # 50MB total

        # æ”¶é›†çš„æ•°æ®
        self.agents_data = defaultdict(dict)
        self.execution_stats = {
            "start_time": None,
            "end_time": None,
            "total_agents": 0,
            "completed_agents": 0,
            "failed_agents": 0,
            "total_output_size": 0,
        }

    def process_agent_output(self, tool_data: Dict[str, Any]) -> None:
        """å¤„ç†å•ä¸ªagentçš„è¾“å‡º"""
        try:
            # æå–agentä¿¡æ¯
            agent_type = tool_data.get("subagent_type", "unknown")
            description = tool_data.get("description", "")
            output = tool_data.get("output", "")

            # æ£€æŸ¥è¾“å‡ºå¤§å°
            output_size = len(output.encode("utf-8"))
            if output_size > self.MAX_OUTPUT_SIZE:
                # å¦‚æœè¾“å‡ºå¤ªå¤§ï¼Œåˆ›å»ºæ‘˜è¦
                output = self._create_summary(output, agent_type)

            # è§£æè¾“å‡ºå†…å®¹
            agent_info = {
                "type": agent_type,
                "description": description,
                "output_size": output_size,
                "status": "completed",
                "timestamp": datetime.now().isoformat(),
                "metrics": self._extract_metrics(output),
                "files_created": self._extract_files(output),
                "key_achievements": self._extract_achievements(output),
            }

            # ä¿å­˜å®Œæ•´è¾“å‡ºåˆ°æ–‡ä»¶ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰
            if output_size > 1024 * 1024:  # >1MBä¿å­˜åˆ°æ–‡ä»¶
                output_file = self._save_output_to_file(agent_type, output)
                agent_info["output_file"] = str(output_file)
                agent_info["output_preview"] = output[:1000] + "..."
            else:
                agent_info["output"] = output

            self.agents_data[agent_type] = agent_info
            self.execution_stats["completed_agents"] += 1
            self.execution_stats["total_output_size"] += output_size

        except Exception as e:
            print(f"âš ï¸ Error processing agent output: {e}", file=sys.stderr)

    def _create_summary(self, output: str, agent_type: str) -> str:
        """åˆ›å»ºè¾“å‡ºæ‘˜è¦"""
        lines = output.split("\n")
        summary_lines = []

        # ä¿ç•™é‡è¦è¡Œï¼ˆæ ‡é¢˜ã€å®Œæˆæ ‡è®°ã€é”™è¯¯ç­‰ï¼‰
        important_patterns = [
            r"^#{1,3}\s+",  # Markdown headers
            r"^âœ…|^âŒ|^âš ï¸",  # Status markers
            r"complete|success|fail|error",  # Status words
            r"created|updated|deleted",  # Action words
            r"\d+\s+files?\s+",  # File counts
            r"\d+\s+lines?\s+",  # Line counts
        ]

        for line in lines[:100]:  # åªçœ‹å‰100è¡Œ
            if any(re.search(p, line, re.IGNORECASE) for p in important_patterns):
                summary_lines.append(line)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        summary_lines.append(f"\n... [Output truncated - {len(lines)} total lines]")

        return "\n".join(summary_lines[:50])  # æœ€å¤š50è¡Œæ‘˜è¦

    def _extract_metrics(self, output: str) -> Dict[str, Any]:
        """ä»è¾“å‡ºä¸­æå–å…³é”®æŒ‡æ ‡"""
        metrics = {
            "lines_of_code": 0,
            "files_created": 0,
            "files_modified": 0,
            "tests_added": 0,
            "performance_improvement": None,
        }

        # æå–ä»£ç è¡Œæ•°
        loc_match = re.search(r"(\d+)\s+lines?\s+of\s+code", output, re.IGNORECASE)
        if loc_match:
            metrics["lines_of_code"] = int(loc_match.group(1))

        # æå–æ–‡ä»¶æ•°é‡
        files_created = re.findall(r"created?\s+(\d+)\s+files?", output, re.IGNORECASE)
        if files_created:
            metrics["files_created"] = sum(int(x) for x in files_created)

        # æå–æ€§èƒ½æ”¹è¿›
        perf_match = re.search(
            r"(\d+)%\s+(?:improvement|faster|reduction)", output, re.IGNORECASE
        )
        if perf_match:
            metrics["performance_improvement"] = f"{perf_match.group(1)}%"

        return metrics

    def _extract_files(self, output: str) -> List[str]:
        """æå–åˆ›å»ºæˆ–ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨"""
        files = []

        # åŒ¹é…æ–‡ä»¶è·¯å¾„æ¨¡å¼
        file_patterns = [
            r"(?:created?|updated?|modified?)\s+([/\w\-\.]+\.\w+)",
            r"([/\w\-\.]+\.\w+)\s+(?:created|updated|modified)",
            r"^\s*[-*]\s+([/\w\-\.]+\.\w+)",  # Markdown list
        ]

        for pattern in file_patterns:
            matches = re.findall(pattern, output, re.MULTILINE | re.IGNORECASE)
            files.extend(matches)

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_files = list(set(files))[:20]
        return unique_files

    def _extract_achievements(self, output: str) -> List[str]:
        """æå–ä¸»è¦æˆå°±"""
        achievements = []

        # æŸ¥æ‰¾æˆå°±æ ‡è®°
        achievement_patterns = [
            r"âœ…\s+(.+?)(?:\n|$)",
            r"(?:completed?|achieved?|implemented?)\s+(.+?)(?:\n|$)",
            r"#{2,3}\s+(?:å®Œæˆ|Completed?|Done)\s*[:ï¼š]\s*(.+?)(?:\n|$)",
        ]

        for pattern in achievement_patterns:
            matches = re.findall(pattern, output, re.IGNORECASE)
            achievements.extend(matches)

        # æ¸…ç†å’Œå»é‡
        achievements = [a.strip() for a in achievements if len(a.strip()) > 10]
        return list(set(achievements))[:10]

    def _save_output_to_file(self, agent_type: str, output: str) -> Path:
        """ä¿å­˜è¾“å‡ºåˆ°æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"agent_output_{agent_type}_{timestamp}.txt"
        filepath = self.cache_dir / filename

        filepath.write_text(output, encoding="utf-8")
        return filepath

    def generate_summary_report(self) -> str:
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        if not self.agents_data:
            return "âš ï¸ No agent outputs collected"

        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = "N/A"
        if self.execution_stats["start_time"] and self.execution_stats["end_time"]:
            duration = (
                self.execution_stats["end_time"] - self.execution_stats["start_time"]
            )
            execution_time = f"{duration:.1f}s"

        # ç”ŸæˆæŠ¥å‘Š
        report = []
        report.append("# ğŸ“Š Agentæ‰§è¡Œæ±‡æ€»æŠ¥å‘Š\n")
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        # æ‰§è¡Œæ¦‚è§ˆ
        report.append("## æ‰§è¡Œæ¦‚è§ˆ\n")
        report.append(f"- **æ€»Agentsæ•°**: {len(self.agents_data)}")
        report.append(f"- **æˆåŠŸå®Œæˆ**: {self.execution_stats['completed_agents']}")
        report.append(f"- **æ‰§è¡Œæ—¶é—´**: {execution_time}")
        report.append(
            f"- **æ€»è¾“å‡ºå¤§å°**: {self._format_size(self.execution_stats['total_output_size'])}"
        )

        # è®¡ç®—å¹¶è¡Œæ•ˆç‡
        if len(self.agents_data) > 1:
            parallel_efficiency = min(100, (len(self.agents_data) * 100) / 8)
            report.append(f"- **å¹¶è¡Œæ•ˆç‡**: {parallel_efficiency:.0f}%")

        report.append("\n## Agentæˆæœè¯¦æƒ…\n")

        # æŒ‰agentç±»å‹æ’åº
        for idx, (agent_type, data) in enumerate(sorted(self.agents_data.items()), 1):
            report.append(f"### {idx}. **{agent_type}** âœ…\n")
            report.append(f"- **ä»»åŠ¡**: {data.get('description', 'N/A')}")
            report.append(
                f"- **è¾“å‡ºå¤§å°**: {self._format_size(data.get('output_size', 0))}"
            )

            # æ˜¾ç¤ºæŒ‡æ ‡
            metrics = data.get("metrics", {})
            if metrics.get("lines_of_code"):
                report.append(f"- **ä»£ç è¡Œæ•°**: {metrics['lines_of_code']}")
            if metrics.get("files_created"):
                report.append(f"- **åˆ›å»ºæ–‡ä»¶**: {metrics['files_created']}ä¸ª")
            if metrics.get("performance_improvement"):
                report.append(f"- **æ€§èƒ½æå‡**: {metrics['performance_improvement']}")

            # æ˜¾ç¤ºä¸»è¦æˆå°±
            achievements = data.get("key_achievements", [])
            if achievements:
                report.append("- **ä¸»è¦æˆå°±**:")
                for achievement in achievements[:3]:
                    report.append(f"  - {achievement}")

            # æ˜¾ç¤ºå…³é”®æ–‡ä»¶
            files = data.get("files_created", [])
            if files:
                report.append("- **å…³é”®æ–‡ä»¶**:")
                for file in files[:5]:
                    report.append(f"  - `{file}`")

            report.append("")

        # æ±‡æ€»ç»Ÿè®¡
        report.append("## ğŸ“ˆ æ±‡æ€»ç»Ÿè®¡\n")

        total_loc = sum(
            d.get("metrics", {}).get("lines_of_code", 0)
            for d in self.agents_data.values()
        )
        total_files = sum(
            d.get("metrics", {}).get("files_created", 0)
            for d in self.agents_data.values()
        )

        if total_loc > 0:
            report.append(f"- **æ€»ä»£ç è¡Œæ•°**: {total_loc:,}")
        if total_files > 0:
            report.append(f"- **æ€»åˆ›å»ºæ–‡ä»¶**: {total_files}")

        # æ€§èƒ½æ”¹è¿›æ±‡æ€»
        perf_improvements = [
            d.get("metrics", {}).get("performance_improvement")
            for d in self.agents_data.values()
            if d.get("metrics", {}).get("performance_improvement")
        ]
        if perf_improvements:
            report.append(f"- **æ€§èƒ½æ”¹è¿›**: {', '.join(perf_improvements)}")

        # å»ºè®®
        report.append("\n## ğŸ’¡ åç»­å»ºè®®\n")

        if len(self.agents_data) >= 6:
            report.append("- âœ… å¤šAgentå¹¶è¡Œæ‰§è¡ŒæˆåŠŸ")
            report.append("- ğŸ” å»ºè®®è¿è¡Œæµ‹è¯•éªŒè¯æ‰€æœ‰å˜æ›´")
            report.append("- ğŸ“Š æ£€æŸ¥æ€§èƒ½åŸºå‡†ç¡®è®¤ä¼˜åŒ–æ•ˆæœ")

        if total_files > 20:
            report.append("- âš ï¸ åˆ›å»ºäº†å¤§é‡æ–‡ä»¶ï¼Œå»ºè®®reviewå…³é”®å˜æ›´")

        if self.execution_stats["total_output_size"] > 20 * 1024 * 1024:
            report.append("- âš ï¸ è¾“å‡ºè¾ƒå¤§ï¼Œéƒ¨åˆ†å†…å®¹å·²ä¿å­˜åˆ°æ–‡ä»¶")

        return "\n".join(report)

    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ["B", "KB", "MB", "GB"]:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f}{unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f}TB"

    def save_summary(self) -> Path:
        """ä¿å­˜æ±‡æ€»æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.cache_dir / f"summary_report_{timestamp}.md"

        report = self.generate_summary_report()
        report_file.write_text(report, encoding="utf-8")

        # åŒæ—¶ä¿å­˜åˆ°å›ºå®šä½ç½®æ–¹ä¾¿æŸ¥çœ‹
        latest_report = Path(self.project_root) / ".claude" / "LATEST_AGENT_SUMMARY.md"
        latest_report.write_text(report, encoding="utf-8")

        return report_file


def main():
    """ä¸»å‡½æ•° - ä½œä¸ºhookè¢«è°ƒç”¨"""
    try:
        # è¯»å–è¾“å…¥
        input_data = sys.stdin.read() if not sys.stdin.isatty() else "{}"

        # è§£æå·¥å…·æ•°æ®
        try:
            tool_data = json.loads(input_data)
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯JSONï¼Œå°è¯•å…¶ä»–æ ¼å¼
            tool_data = {"output": input_data}

        # åªå¤„ç†Taskå·¥å…·çš„è¾“å‡º
        if tool_data.get("tool") == "Task" or "subagent_type" in tool_data:
            summarizer = AgentOutputSummarizer()

            # æ ‡è®°å¼€å§‹æ—¶é—´
            if not summarizer.execution_stats["start_time"]:
                summarizer.execution_stats["start_time"] = time.time()

            # å¤„ç†è¾“å‡º
            summarizer.process_agent_output(tool_data)

            # æ›´æ–°ç»“æŸæ—¶é—´
            summarizer.execution_stats["end_time"] = time.time()

            # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
            report_file = summarizer.save_summary()

            # è¾“å‡ºç®€çŸ­æç¤ºï¼ˆéé˜»å¡ï¼‰
            print(f"âœ… Agent output collected and summarized â†’ {report_file.name}")

    except Exception as e:
        # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
        print(f"âš ï¸ Agent summarizer error: {e}", file=sys.stderr)


if __name__ == "__main__":
    main()
