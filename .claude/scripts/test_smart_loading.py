#!/usr/bin/env python3
"""
Claude Enhanceræ™ºèƒ½æ–‡æ¡£åŠ è½½ç³»ç»Ÿæµ‹è¯•å¥—ä»¶
éªŒè¯å„ç§åœºæ™¯ä¸‹çš„æ–‡æ¡£åŠ è½½ç­–ç•¥æ˜¯å¦æ­£ç¡®
"""

import sys
import os
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

try:
    from smart_document_loader import SmartDocumentLoader, Priority
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥smart_document_loaderæ¨¡å—")
    print("è¯·ç¡®ä¿smart_document_loader.pyåœ¨åŒä¸€ç›®å½•ä¸‹")
    sys.exit(1)


def test_basic_functionality():
    """æµ‹è¯•åŸºç¡€åŠŸèƒ½"""
    print("ğŸ”§ æµ‹è¯•åŸºç¡€åŠŸèƒ½...")

    loader = SmartDocumentLoader()

    # æµ‹è¯•æ–‡æ¡£æ³¨å†Œè¡¨æ„å»º
    assert len(loader.document_registry) > 0, "æ–‡æ¡£æ³¨å†Œè¡¨ä¸ºç©º"

    # æ£€æŸ¥P0æ–‡æ¡£æ˜¯å¦å­˜åœ¨
    p0_docs = [
        doc
        for doc in loader.document_registry.values()
        if doc.priority == Priority.P0_CRITICAL
    ]
    assert len(p0_docs) >= 3, f"P0æ–‡æ¡£æ•°é‡ä¸è¶³: {len(p0_docs)}"

    print("  âœ… åŸºç¡€åŠŸèƒ½æ­£å¸¸")


def test_task_analysis():
    """æµ‹è¯•ä»»åŠ¡åˆ†æåŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•ä»»åŠ¡åˆ†æåŠŸèƒ½...")

    loader = SmartDocumentLoader()

    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "request": "ä¿®å¤ç”¨æˆ·ç™»å½•çš„bug",
            "expected_type": "Bugä¿®å¤",
            "expected_complexity": "ç®€å•",
        },
        {
            "request": "æ·»åŠ Reactç”¨æˆ·ä»ªè¡¨æ¿åŠŸèƒ½",
            "expected_type": "æ–°åŠŸèƒ½å¼€å‘",
            "expected_tech": ["react"],
        },
        {
            "request": "é‡æ„ç³»ç»Ÿæ¶æ„ï¼Œä¼˜åŒ–åˆ†å±‚è®¾è®¡",
            "expected_type": "é‡æ„ä¼˜åŒ–",
            "expected_arch_needs": True,
        },
        {
            "request": "å®ç°ç”¨æˆ·è®¤è¯å’Œæƒé™ç®¡ç†",
            "expected_type": "å®‰å…¨å®¡è®¡",  # å®‰å…¨å…³é”®è¯ä¼šå…ˆåŒ¹é…
            "expected_security": True,
        },
    ]

    for i, case in enumerate(test_cases):
        analysis = loader.analyze_task(case["request"])

        if "expected_type" in case:
            assert (
                analysis["task_type"] == case["expected_type"]
            ), f"ç”¨ä¾‹{i+1}: ä»»åŠ¡ç±»å‹é”™è¯¯ - æœŸæœ›:{case['expected_type']}, å®é™…:{analysis['task_type']}"

        if "expected_complexity" in case:
            assert (
                analysis["complexity"] == case["expected_complexity"]
            ), f"ç”¨ä¾‹{i+1}: å¤æ‚åº¦é”™è¯¯ - æœŸæœ›:{case['expected_complexity']}, å®é™…:{analysis['complexity']}"

        if "expected_tech" in case:
            for tech in case["expected_tech"]:
                assert (
                    tech in analysis["tech_stack"]
                ), f"ç”¨ä¾‹{i+1}: æŠ€æœ¯æ ˆæ£€æµ‹é”™è¯¯ - æœŸæœ›åŒ…å«:{tech}, å®é™…:{analysis['tech_stack']}"

        if "expected_arch_needs" in case:
            assert (
                analysis["architecture_needs"] == case["expected_arch_needs"]
            ), f"ç”¨ä¾‹{i+1}: æ¶æ„éœ€æ±‚æ£€æµ‹é”™è¯¯"

        if "expected_security" in case:
            assert (
                analysis["security_needs"] == case["expected_security"]
            ), f"ç”¨ä¾‹{i+1}: å®‰å…¨éœ€æ±‚æ£€æµ‹é”™è¯¯"

        print(f"  âœ… ç”¨ä¾‹{i+1}: {case['request'][:20]}... - åˆ†ææ­£ç¡®")


def test_document_loading_scenarios():
    """æµ‹è¯•æ–‡æ¡£åŠ è½½åœºæ™¯"""
    print("ğŸ“š æµ‹è¯•æ–‡æ¡£åŠ è½½åœºæ™¯...")

    loader = SmartDocumentLoader()

    scenarios = [
        {
            "name": "ç®€å•Bugä¿®å¤",
            "request": "ä¿®å¤ç™»å½•éªŒè¯é”™è¯¯",
            "phase": 3,
            "max_tokens": 15000,
            "expected_p0": 3,  # è‡³å°‘åŒ…å«3ä¸ªP0æ–‡æ¡£
            "expected_max_docs": 10,  # è°ƒæ•´ä¸ºæ›´åˆç†çš„æ•°å€¼
        },
        {
            "name": "æ ‡å‡†åŠŸèƒ½å¼€å‘",
            "request": "æ·»åŠ Reactç”¨æˆ·ä¸ªäººèµ„æ–™é¡µé¢",
            "phase": 2,
            "max_tokens": 30000,
            "expected_min_docs": 6,
            "should_include": ["ARCHITECTURE/GROWTH-STRATEGY.md"],
        },
        {
            "name": "å¤æ‚æ¶æ„é‡æ„",
            "request": "é‡æ„æ•´ä¸ªç³»ç»Ÿçš„åˆ†å±‚æ¶æ„",
            "phase": 2,
            "max_tokens": 50000,
            "expected_min_docs": 8,
            "should_include": [
                "ARCHITECTURE/v2.0-FOUNDATION.md",
                "ARCHITECTURE/LAYER-DEFINITION.md",
            ],
        },
        {
            "name": "å®‰å…¨å®¡è®¡ä»»åŠ¡",
            "request": "å®¡è®¡ç”¨æˆ·è®¤è¯ç³»ç»Ÿçš„å®‰å…¨æ¼æ´",
            "phase": 3,
            "max_tokens": 25000,
            "should_include": ["SAFETY_RULES.md"],
            "should_include_pattern": "security",
        },
    ]

    for scenario in scenarios:
        try:
            docs, plan = loader.get_documents_for_task(
                scenario["request"],
                current_phase=scenario["phase"],
                max_tokens=scenario["max_tokens"],
            )

            # æ£€æŸ¥åŸºæœ¬çº¦æŸ
            assert (
                plan.estimated_tokens <= scenario["max_tokens"]
            ), f"{scenario['name']}: Tokenè¶…é™ {plan.estimated_tokens} > {scenario['max_tokens']}"

            # æ£€æŸ¥P0æ–‡æ¡£æ•°é‡
            if "expected_p0" in scenario:
                p0_count = sum(
                    1 for doc in plan.documents if doc.priority == Priority.P0_CRITICAL
                )
                assert (
                    p0_count >= scenario["expected_p0"]
                ), f"{scenario['name']}: P0æ–‡æ¡£æ•°é‡ä¸è¶³ {p0_count} < {scenario['expected_p0']}"

            # æ£€æŸ¥æ–‡æ¡£æ•°é‡èŒƒå›´
            if "expected_min_docs" in scenario:
                assert (
                    len(plan.documents) >= scenario["expected_min_docs"]
                ), f"{scenario['name']}: æ–‡æ¡£æ•°é‡ä¸è¶³ {len(plan.documents)} < {scenario['expected_min_docs']}"

            if "expected_max_docs" in scenario:
                assert (
                    len(plan.documents) <= scenario["expected_max_docs"]
                ), f"{scenario['name']}: æ–‡æ¡£æ•°é‡è¿‡å¤š {len(plan.documents)} > {scenario['expected_max_docs']}"

            # æ£€æŸ¥å¿…é¡»åŒ…å«çš„æ–‡æ¡£
            if "should_include" in scenario:
                doc_paths = [doc.path for doc in plan.documents]
                for required_doc in scenario["should_include"]:
                    assert (
                        required_doc in doc_paths
                    ), f"{scenario['name']}: ç¼ºå°‘å¿…éœ€æ–‡æ¡£ {required_doc}"

            # æ£€æŸ¥æ¨¡å¼åŒ¹é…
            if "should_include_pattern" in scenario:
                pattern = scenario["should_include_pattern"]
                found = any(
                    pattern in doc.path.lower()
                    or pattern in str(doc.categories).lower()
                    for doc in plan.documents
                )
                assert found, f"{scenario['name']}: æœªæ‰¾åˆ°åŒ…å«'{pattern}'çš„æ–‡æ¡£"

            print(
                f"  âœ… {scenario['name']}: {len(plan.documents)}ä¸ªæ–‡æ¡£, {plan.estimated_tokens} tokens"
            )

        except Exception as e:
            print(f"  âŒ {scenario['name']}: {str(e)}")
            raise


def test_token_optimization():
    """æµ‹è¯•Tokenä¼˜åŒ–åŠŸèƒ½"""
    print("âš¡ æµ‹è¯•Tokenä¼˜åŒ–åŠŸèƒ½...")

    loader = SmartDocumentLoader()

    # æµ‹è¯•ä½Tokené™åˆ¶ä¸‹çš„ä¼˜åŒ–
    docs, plan = loader.get_documents_for_task(
        "é‡æ„ç³»ç»Ÿæ¶æ„ï¼Œæ·»åŠ æ–°çš„å¾®æœåŠ¡æ¨¡å—ï¼Œä½¿ç”¨Reactå‰ç«¯å’ŒPythonåç«¯",
        current_phase=2,
        max_tokens=10000,  # å¾ˆä½çš„é™åˆ¶
    )

    assert plan.estimated_tokens <= 10000, f"Tokenä¼˜åŒ–å¤±è´¥: {plan.estimated_tokens} > 10000"

    # ç¡®ä¿P0æ–‡æ¡£ä»ç„¶è¢«ä¿ç•™
    p0_count = sum(1 for doc in plan.documents if doc.priority == Priority.P0_CRITICAL)
    assert p0_count >= 2, f"Tokenä¼˜åŒ–åP0æ–‡æ¡£ä¸¢å¤±: {p0_count}"

    print(f"  âœ… Tokenä¼˜åŒ–æˆåŠŸ: {len(plan.documents)}ä¸ªæ–‡æ¡£, {plan.estimated_tokens} tokens")


def test_phase_progression():
    """æµ‹è¯•Phaseè¿›å±•å¯¹æ–‡æ¡£åŠ è½½çš„å½±å“"""
    print("ğŸ¯ æµ‹è¯•Phaseè¿›å±•å½±å“...")

    loader = SmartDocumentLoader()
    task = "å¼€å‘æ–°çš„ç”¨æˆ·ç®¡ç†åŠŸèƒ½"

    phase_results = {}
    for phase in range(0, 4):
        docs, plan = loader.get_documents_for_task(task, current_phase=phase)
        phase_results[phase] = {
            "doc_count": len(plan.documents),
            "token_count": plan.estimated_tokens,
            "doc_paths": [doc.path for doc in plan.documents],
        }

    # Phase 0åº”è¯¥æ–‡æ¡£æœ€å°‘
    assert (
        phase_results[0]["doc_count"] <= phase_results[1]["doc_count"]
    ), "Phase 0æ–‡æ¡£æ•°é‡åº”è¯¥æœ€å°‘"

    # Phase 2åº”è¯¥åŒ…å«æ¶æ„æ–‡æ¡£ï¼ˆå¦‚æœæ˜¯æ–°åŠŸèƒ½ï¼‰
    # æ³¨æ„ï¼šåªæœ‰å½“ä»»åŠ¡åŒ…å«æ¶æ„å…³é”®è¯æ—¶æ‰ä¼šåŠ è½½æ¶æ„æ–‡æ¡£
    task_with_arch = "å¼€å‘æ–°çš„ç”¨æˆ·ç®¡ç†åŠŸèƒ½æ¨¡å—"  # åŒ…å«"æ¨¡å—"å…³é”®è¯
    docs_arch, plan_arch = loader.get_documents_for_task(
        task_with_arch, current_phase=2
    )
    arch_docs = [doc.path for doc in plan_arch.documents]
    has_arch_doc = any("ARCHITECTURE" in path for path in arch_docs)
    assert has_arch_doc, f"Phase 2åº”è¯¥åŒ…å«æ¶æ„æ–‡æ¡£ï¼Œå®é™…åŠ è½½: {arch_docs}"

    print(f"  âœ… Phaseè¿›å±•æµ‹è¯•é€šè¿‡:")
    for phase, result in phase_results.items():
        print(
            f"    Phase {phase}: {result['doc_count']}ä¸ªæ–‡æ¡£, {result['token_count']} tokens"
        )


def test_caching_behavior():
    """æµ‹è¯•ç¼“å­˜è¡Œä¸º"""
    print("ğŸ’¾ æµ‹è¯•ç¼“å­˜è¡Œä¸º...")

    loader = SmartDocumentLoader()

    # ç¬¬ä¸€æ¬¡åŠ è½½
    docs1, plan1 = loader.get_documents_for_task("ä¿®å¤Python API bug", current_phase=3)
    initial_cache_size = len(loader.cache)
    initial_session_size = len(loader.session_cache)

    # ç¬¬äºŒæ¬¡åŠ è½½ç›¸ä¼¼ä»»åŠ¡
    docs2, plan2 = loader.get_documents_for_task("ä¿®å¤å¦ä¸€ä¸ªPython API bug", current_phase=3)

    # ç¼“å­˜åº”è¯¥å¢é•¿ï¼ˆP0æ–‡æ¡£è¿›å…¥æ°¸ä¹…ç¼“å­˜ï¼‰
    assert len(loader.cache) >= initial_cache_size, "æ°¸ä¹…ç¼“å­˜åº”è¯¥å¢é•¿"

    # æ¸…ç†ä¼šè¯ç¼“å­˜
    loader.clear_session_cache()
    assert len(loader.session_cache) == 0, "ä¼šè¯ç¼“å­˜æ¸…ç†å¤±è´¥"
    assert len(loader.cache) > 0, "æ°¸ä¹…ç¼“å­˜ä¸åº”è¯¥è¢«æ¸…ç†"

    print(f"  âœ… ç¼“å­˜è¡Œä¸ºæ­£å¸¸: æ°¸ä¹…ç¼“å­˜{len(loader.cache)}, ä¼šè¯ç¼“å­˜{len(loader.session_cache)}")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹Claude Enhanceræ™ºèƒ½æ–‡æ¡£åŠ è½½ç³»ç»Ÿæµ‹è¯•\n")

    tests = [
        test_basic_functionality,
        test_task_analysis,
        test_document_loading_scenarios,
        test_token_optimization,
        test_phase_progression,
        test_caching_behavior,
    ]

    passed = 0
    failed = 0

    for test_func in tests:
        try:
            test_func()
            passed += 1
        except Exception as e:
            print(f"âŒ {test_func.__name__} å¤±è´¥: {str(e)}")
            failed += 1
        print()

    # æ€»ç»“
    print("=" * 50)
    print(f"æµ‹è¯•å®Œæˆ: {passed} é€šè¿‡, {failed} å¤±è´¥")

    if failed == 0:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ™ºèƒ½æ–‡æ¡£åŠ è½½ç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
        return True
    else:
        print("âš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿå®ç°ã€‚")
        return False


def demo_usage():
    """æ¼”ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸ¬ æ™ºèƒ½æ–‡æ¡£åŠ è½½æ¼”ç¤º\n")

    loader = SmartDocumentLoader()

    demo_tasks = [
        "ä¿®å¤ç”¨æˆ·ç™»å½•é¡µé¢çš„éªŒè¯bug",
        "æ·»åŠ Reactè´­ç‰©è½¦åŠŸèƒ½ï¼Œéœ€è¦åç«¯APIæ”¯æŒ",
        "é‡æ„æ•´ä¸ªç³»ç»Ÿæ¶æ„ï¼Œå®ç°å¾®æœåŠ¡åŒ–",
        "å®¡è®¡è®¤è¯ç³»ç»Ÿçš„å®‰å…¨æ¼æ´",
    ]

    for i, task in enumerate(demo_tasks, 1):
        print(f"ğŸ“‹ ç¤ºä¾‹{i}: {task}")

        docs, plan = loader.get_documents_for_task(task, current_phase=2)

        print(f"  ğŸ¯ ä»»åŠ¡ç±»å‹: {plan.task_type}")
        print(f"  âš¡ å¤æ‚åº¦: {plan.complexity}")
        print(f"  ğŸ› ï¸  æŠ€æœ¯æ ˆ: {', '.join(plan.tech_stack) if plan.tech_stack else 'æœªæ£€æµ‹åˆ°'}")
        print(f"  ğŸ“Š æ–‡æ¡£æ•°é‡: {len(plan.documents)}")
        print(f"  ğŸ« é¢„ä¼°Token: {plan.estimated_tokens}")
        print(f"  ğŸ“š ä¸»è¦æ–‡æ¡£:")

        for doc in plan.documents[:5]:  # æ˜¾ç¤ºå‰5ä¸ªæ–‡æ¡£
            priority_symbol = {
                Priority.P0_CRITICAL: "ğŸ”´",
                Priority.P1_HIGH: "ğŸŸ¡",
                Priority.P2_CONDITIONAL: "ğŸŸ¢",
                Priority.P3_RARE: "âšª",
            }.get(doc.priority, "â“")
            print(f"    {priority_symbol} {doc.path}")

        if len(plan.documents) > 5:
            print(f"    ... åŠå…¶ä»–{len(plan.documents) - 5}ä¸ªæ–‡æ¡£")

        print()


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "--demo":
        demo_usage()
    else:
        success = run_all_tests()
        sys.exit(0 if success else 1)
