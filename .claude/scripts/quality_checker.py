#!/usr/bin/env python3
"""
Claude Enhancer 5.0 è´¨é‡æ£€æŸ¥å·¥å…·
=================================

è‡ªåŠ¨åŒ–ä»£ç è´¨é‡æ£€æŸ¥å·¥å…·ï¼Œå®ç°ä»£ç å®¡æŸ¥æŒ‡å—ä¸­å®šä¹‰çš„è´¨é‡æ ‡å‡†ã€‚
æä¾›å…¨é¢çš„ä»£ç è´¨é‡è¯„ä¼°ã€å®‰å…¨æ£€æŸ¥å’Œæ€§èƒ½åˆ†æã€‚

Features:
- ä»£ç è§„èŒƒæ£€æŸ¥
- å®‰å…¨æ¼æ´æ‰«æ
- æ€§èƒ½åŸºå‡†æµ‹è¯•
- å¯ç»´æŠ¤æ€§åˆ†æ
- è´¨é‡æŠ¥å‘Šç”Ÿæˆ

Author: Claude Code Review Expert
Version: 1.0.0
"""

import os
import sys
import json
import yaml
import subprocess
import argparse
import logging
import time
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import hashlib

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class QualityScore:
    """è´¨é‡è¯„åˆ†æ•°æ®ç±»"""

    readability: int = 0  # å¯è¯»æ€§ (0-25)
    security: int = 0  # å®‰å…¨æ€§ (0-30)
    performance: int = 0  # æ€§èƒ½ (0-20)
    maintainability: int = 0  # å¯ç»´æŠ¤æ€§ (0-25)

    @property
    def total(self) -> int:
        """æ€»åˆ†"""
        return (
            self.readability + self.security + self.performance + self.maintainability
        )

    @property
    def grade(self) -> str:
        """è¯„çº§"""
        if self.total >= 90:
            return "ä¼˜ç§€"
        elif self.total >= 80:
            return "è‰¯å¥½"
        elif self.total >= 70:
            return "åŠæ ¼"
        else:
            return "éœ€æ”¹è¿›"


@dataclass
class QualityIssue:
    """è´¨é‡é—®é¢˜æ•°æ®ç±»"""

    file_path: str
    line_number: int
    severity: str  # critical, major, minor, info
    category: str  # readability, security, performance, maintainability
    message: str
    rule_id: str
    suggestion: Optional[str] = None


@dataclass
class QualityReport:
    """è´¨é‡æŠ¥å‘Šæ•°æ®ç±»"""

    timestamp: str
    project_path: str
    total_files: int
    score: QualityScore
    issues: List[QualityIssue]
    recommendations: List[str]
    execution_time: float


class QualityChecker:
    """ä»£ç è´¨é‡æ£€æŸ¥å™¨"""

    def __init__(self, project_path: str = "."):
        """
        åˆå§‹åŒ–è´¨é‡æ£€æŸ¥å™¨

        Args:
            project_path: é¡¹ç›®æ ¹è·¯å¾„
        """
        self.project_path = Path(project_path).resolve()
        self.claude_dir = self.project_path / ".claude"
        self.temp_dir = Path("/tmp/claude_quality_check")
        self.temp_dir.mkdir(exist_ok=True)

        # æ£€æŸ¥å·¥å…·
        self.tools = self._check_available_tools()

        # è´¨é‡è§„åˆ™é…ç½®
        self.rules = self._load_quality_rules()

    def _check_available_tools(self) -> Dict[str, bool]:
        """æ£€æŸ¥å¯ç”¨çš„è´¨é‡æ£€æŸ¥å·¥å…·"""
        tools = {
            "flake8": self._command_exists("flake8"),
            "black": self._command_exists("black"),
            "mypy": self._command_exists("mypy"),
            "bandit": self._command_exists("bandit"),
            "shellcheck": self._command_exists("shellcheck"),
            "yamllint": self._command_exists("yamllint"),
            "pytest": self._command_exists("pytest"),
        }

        logger.info(f"å¯ç”¨å·¥å…·: {[k for k, v in tools.items() if v]}")
        return tools

    def _command_exists(self, command: str) -> bool:
        """æ£€æŸ¥å‘½ä»¤æ˜¯å¦å­˜åœ¨"""
        try:
            subprocess.run(["which", command], check=True, capture_output=True)
            return True
        except subprocess.CalledProcessError:
            return False

    def _load_quality_rules(self) -> Dict[str, Any]:
        """åŠ è½½è´¨é‡è§„åˆ™é…ç½®"""
        rules_file = self.claude_dir / "config" / "quality_rules.yaml"

        # é»˜è®¤è§„åˆ™
        default_rules = {
            "readability": {
                "max_line_length": 88,
                "max_function_lines": 50,
                "max_file_lines": 500,
                "max_complexity": 10,
                "require_docstrings": True,
            },
            "security": {
                "check_hardcoded_secrets": True,
                "check_sql_injection": True,
                "check_command_injection": True,
                "check_path_traversal": True,
            },
            "performance": {
                "max_response_time_ms": 100,
                "max_memory_mb": 100,
                "check_n_plus_one": True,
                "check_inefficient_loops": True,
            },
            "maintainability": {
                "min_test_coverage": 80,
                "max_dependency_depth": 5,
                "check_code_duplication": True,
                "require_type_hints": True,
            },
        }

        if rules_file.exists():
            try:
                with open(rules_file, "r", encoding="utf-8") as f:
                    custom_rules = yaml.safe_load(f)
                    # åˆå¹¶è‡ªå®šä¹‰è§„åˆ™
                    default_rules.update(custom_rules)
            except Exception as e:
                logger.warning(f"åŠ è½½è‡ªå®šä¹‰è§„åˆ™å¤±è´¥: {e}")

        return default_rules

    def check_project(
        self, include_patterns: List[str] = None, exclude_patterns: List[str] = None
    ) -> QualityReport:
        """
        æ£€æŸ¥æ•´ä¸ªé¡¹ç›®

        Args:
            include_patterns: åŒ…å«çš„æ–‡ä»¶æ¨¡å¼
            exclude_patterns: æ’é™¤çš„æ–‡ä»¶æ¨¡å¼

        Returns:
            è´¨é‡æŠ¥å‘Š
        """
        start_time = time.time()
        logger.info(f"å¼€å§‹æ£€æŸ¥é¡¹ç›®: {self.project_path}")

        # é»˜è®¤æ¨¡å¼
        if include_patterns is None:
            include_patterns = ["**/*.py", "**/*.sh", "**/*.yaml", "**/*.yml"]

        if exclude_patterns is None:
            exclude_patterns = [
                "**/venv/**",
                "**/.venv/**",
                "**/node_modules/**",
                "**/__pycache__/**",
                "**/.git/**",
                "**/.*",
            ]

        # è·å–è¦æ£€æŸ¥çš„æ–‡ä»¶
        files_to_check = self._get_files_to_check(include_patterns, exclude_patterns)
        logger.info(f"å‘ç° {len(files_to_check)} ä¸ªæ–‡ä»¶éœ€è¦æ£€æŸ¥")

        # åˆå§‹åŒ–é—®é¢˜åˆ—è¡¨
        all_issues = []

        # åˆ†ç±»æ£€æŸ¥
        all_issues.extend(self._check_readability(files_to_check))
        all_issues.extend(self._check_security(files_to_check))
        all_issues.extend(self._check_performance(files_to_check))
        all_issues.extend(self._check_maintainability(files_to_check))

        # è®¡ç®—åˆ†æ•°
        score = self._calculate_score(all_issues, len(files_to_check))

        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(all_issues, score)

        execution_time = time.time() - start_time

        # åˆ›å»ºæŠ¥å‘Š
        report = QualityReport(
            timestamp=datetime.now().isoformat(),
            project_path=str(self.project_path),
            total_files=len(files_to_check),
            score=score,
            issues=all_issues,
            recommendations=recommendations,
            execution_time=execution_time,
        )

        logger.info(f"è´¨é‡æ£€æŸ¥å®Œæˆï¼Œæ€»åˆ†: {score.total}/100 ({score.grade})")
        return report

    def _get_files_to_check(
        self, include_patterns: List[str], exclude_patterns: List[str]
    ) -> List[Path]:
        """è·å–éœ€è¦æ£€æŸ¥çš„æ–‡ä»¶åˆ—è¡¨"""
        files = []

        for pattern in include_patterns:
            for file_path in self.project_path.glob(pattern):
                if file_path.is_file():
                    pass  # Auto-fixed empty block
                    # æ£€æŸ¥æ˜¯å¦è¢«æ’é™¤
                    should_exclude = False
                    for exclude_pattern in exclude_patterns:
                        if file_path.match(exclude_pattern):
                            should_exclude = True
                            break

                    if not should_exclude:
                        files.append(file_path)

        return sorted(list(set(files)))

    def _check_readability(self, files: List[Path]) -> List[QualityIssue]:
        """æ£€æŸ¥ä»£ç å¯è¯»æ€§"""
        issues = []
        logger.info("æ£€æŸ¥ä»£ç å¯è¯»æ€§...")

        for file_path in files:
            try:
                pass  # Auto-fixed empty block
                # Pythonæ–‡ä»¶æ£€æŸ¥
                if file_path.suffix == ".py":
                    issues.extend(self._check_python_readability(file_path))

                # Shellè„šæœ¬æ£€æŸ¥
                elif file_path.suffix == ".sh":
                    issues.extend(self._check_shell_readability(file_path))

                # YAMLæ–‡ä»¶æ£€æŸ¥
                elif file_path.suffix in [".yaml", ".yml"]:
                    issues.extend(self._check_yaml_readability(file_path))

            except Exception as e:
                logger.error(f"æ£€æŸ¥æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

        logger.info(f"å¯è¯»æ€§æ£€æŸ¥å®Œæˆï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")
        return issues

    def _check_python_readability(self, file_path: Path) -> List[QualityIssue]:
        """æ£€æŸ¥Pythonæ–‡ä»¶å¯è¯»æ€§"""
        issues = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            # æ£€æŸ¥è¡Œé•¿åº¦
            max_length = self.rules["readability"]["max_line_length"]
            for i, line in enumerate(lines, 1):
                if len(line) > max_length:
                    issues.append(
                        QualityIssue(
                            file_path=str(file_path),
                            line_number=i,
                            severity="minor",
                            category="readability",
                            message=f"è¡Œé•¿åº¦è¶…è¿‡é™åˆ¶ ({len(line)} > {max_length})",
                            rule_id="R001",
                            suggestion=f"å»ºè®®å°†é•¿è¡Œæ‹†åˆ†ä¸ºå¤šè¡Œ",
                        )
                    )

            # æ£€æŸ¥æ–‡ä»¶é•¿åº¦
            max_file_lines = self.rules["readability"]["max_file_lines"]
            if len(lines) > max_file_lines:
                issues.append(
                    QualityIssue(
                        file_path=str(file_path),
                        line_number=1,
                        severity="major",
                        category="readability",
                        message=f"æ–‡ä»¶è¿‡é•¿ ({len(lines)} > {max_file_lines})",
                        rule_id="R002",
                        suggestion="è€ƒè™‘å°†æ–‡ä»¶æ‹†åˆ†ä¸ºæ›´å°çš„æ¨¡å—",
                    )
                )

            # ä½¿ç”¨flake8æ£€æŸ¥ä»£ç è§„èŒƒ
            if self.tools["flake8"]:
                issues.extend(self._run_flake8(file_path))

            # ä½¿ç”¨blackæ£€æŸ¥æ ¼å¼
            if self.tools["black"]:
                issues.extend(self._run_black_check(file_path))

        except Exception as e:
            logger.error(f"æ£€æŸ¥Pythonæ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

        return issues

    def _check_shell_readability(self, file_path: Path) -> List[QualityIssue]:
        """æ£€æŸ¥Shellè„šæœ¬å¯è¯»æ€§"""
        issues = []

        try:
            pass  # Auto-fixed empty block
            # ä½¿ç”¨shellcheckæ£€æŸ¥
            if self.tools["shellcheck"]:
                issues.extend(self._run_shellcheck(file_path))

            # åŸºæœ¬æ ¼å¼æ£€æŸ¥
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            # æ£€æŸ¥shebang
            if not lines[0].startswith("#!"):
                issues.append(
                    QualityIssue(
                        file_path=str(file_path),
                        line_number=1,
                        severity="major",
                        category="readability",
                        message="ç¼ºå°‘shebangå£°æ˜",
                        rule_id="R101",
                        suggestion="æ·»åŠ  #!/bin/bash æˆ–é€‚å½“çš„shebang",
                    )
                )

            # æ£€æŸ¥setå‘½ä»¤
            has_set_e = any("set -e" in line for line in lines[:10])
            if not has_set_e:
                issues.append(
                    QualityIssue(
                        file_path=str(file_path),
                        line_number=2,
                        severity="major",
                        category="readability",
                        message="å»ºè®®æ·»åŠ  set -e å¯ç”¨ä¸¥æ ¼æ¨¡å¼",
                        rule_id="R102",
                        suggestion="åœ¨è„šæœ¬å¼€å¤´æ·»åŠ  set -e",
                    )
                )

        except Exception as e:
            logger.error(f"æ£€æŸ¥Shellæ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

        return issues

    def _check_yaml_readability(self, file_path: Path) -> List[QualityIssue]:
        """æ£€æŸ¥YAMLæ–‡ä»¶å¯è¯»æ€§"""
        issues = []

        try:
            pass  # Auto-fixed empty block
            # ä½¿ç”¨yamllintæ£€æŸ¥
            if self.tools["yamllint"]:
                issues.extend(self._run_yamllint(file_path))

            # éªŒè¯YAMLè¯­æ³•
            with open(file_path, "r", encoding="utf-8") as f:
                try:
                    yaml.safe_load(f)
                except yaml.YAMLError as e:
                    issues.append(
                        QualityIssue(
                            file_path=str(file_path),
                            line_number=getattr(e, "problem_mark", {}).get("line", 1),
                            severity="critical",
                            category="readability",
                            message=f"YAMLè¯­æ³•é”™è¯¯: {e}",
                            rule_id="R201",
                            suggestion="ä¿®å¤YAMLè¯­æ³•é”™è¯¯",
                        )
                    )

        except Exception as e:
            logger.error(f"æ£€æŸ¥YAMLæ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

        return issues

    def _check_security(self, files: List[Path]) -> List[QualityIssue]:
        """æ£€æŸ¥å®‰å…¨æ€§"""
        issues = []
        logger.info("æ£€æŸ¥å®‰å…¨æ€§...")

        # ä½¿ç”¨banditæ£€æŸ¥Pythonå®‰å…¨æ€§
        python_files = [f for f in files if f.suffix == ".py"]
        if python_files and self.tools["bandit"]:
            issues.extend(self._run_bandit(python_files))

        # è‡ªå®šä¹‰å®‰å…¨æ£€æŸ¥
        for file_path in files:
            try:
                issues.extend(self._check_custom_security(file_path))
            except Exception as e:
                logger.error(f"å®‰å…¨æ£€æŸ¥æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

        logger.info(f"å®‰å…¨æ£€æŸ¥å®Œæˆï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")
        return issues

    def _check_custom_security(self, file_path: Path) -> List[QualityIssue]:
        """è‡ªå®šä¹‰å®‰å…¨æ£€æŸ¥"""
        issues = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            # æ£€æŸ¥ç¡¬ç¼–ç å¯†ç /å¯†é’¥
            sensitive_patterns = [
                r'password\s*=\s*["\'][^"\']+["\']',
                r'api_key\s*=\s*["\'][^"\']+["\']',
                r'secret\s*=\s*["\'][^"\']+["\']',
                r'token\s*=\s*["\'][^"\']+["\']',
            ]

            import re

            for i, line in enumerate(lines, 1):
                for pattern in sensitive_patterns:
                    if re.search(pattern, line, re.IGNORECASE):
                        issues.append(
                            QualityIssue(
                                file_path=str(file_path),
                                line_number=i,
                                severity="critical",
                                category="security",
                                message="æ£€æµ‹åˆ°å¯èƒ½çš„ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯",
                                rule_id="S001",
                                suggestion="ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶å­˜å‚¨æ•æ„Ÿä¿¡æ¯",
                            )
                        )

            # æ£€æŸ¥å‘½ä»¤æ³¨å…¥é£é™© (Shellè„šæœ¬)
            if file_path.suffix == ".sh":
                dangerous_patterns = [r"eval\s+", r"\$\([^)]*\$", r"`[^`]*\$"]

                for i, line in enumerate(lines, 1):
                    for pattern in dangerous_patterns:
                        if re.search(pattern, line):
                            issues.append(
                                QualityIssue(
                                    file_path=str(file_path),
                                    line_number=i,
                                    severity="major",
                                    category="security",
                                    message="æ£€æµ‹åˆ°æ½œåœ¨çš„å‘½ä»¤æ³¨å…¥é£é™©",
                                    rule_id="S101",
                                    suggestion="é¿å…åŠ¨æ€å‘½ä»¤æ‰§è¡Œï¼Œä½¿ç”¨å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
                                )
                            )

        except Exception as e:
            logger.error(f"è‡ªå®šä¹‰å®‰å…¨æ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _check_performance(self, files: List[Path]) -> List[QualityIssue]:
        """æ£€æŸ¥æ€§èƒ½"""
        issues = []
        logger.info("æ£€æŸ¥æ€§èƒ½...")

        for file_path in files:
            try:
                if file_path.suffix == ".py":
                    issues.extend(self._check_python_performance(file_path))
                elif file_path.suffix == ".sh":
                    issues.extend(self._check_shell_performance(file_path))
            except Exception as e:
                logger.error(f"æ€§èƒ½æ£€æŸ¥æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

        logger.info(f"æ€§èƒ½æ£€æŸ¥å®Œæˆï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")
        return issues

    def _check_python_performance(self, file_path: Path) -> List[QualityIssue]:
        """æ£€æŸ¥Pythonæ€§èƒ½"""
        issues = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            import re

            # æ£€æŸ¥ä½æ•ˆçš„å­—ç¬¦ä¸²æ‹¼æ¥
            for i, line in enumerate(lines, 1):
                if re.search(r'\+\s*=\s*["\']', line):
                    issues.append(
                        QualityIssue(
                            file_path=str(file_path),
                            line_number=i,
                            severity="minor",
                            category="performance",
                            message="æ£€æµ‹åˆ°ä½æ•ˆçš„å­—ç¬¦ä¸²æ‹¼æ¥",
                            rule_id="P001",
                            suggestion="è€ƒè™‘ä½¿ç”¨join()æˆ–f-string",
                        )
                    )

            # æ£€æŸ¥å¾ªç¯ä¸­çš„é‡å¤è®¡ç®—
            in_loop = False
            for i, line in enumerate(lines, 1):
                if re.search(r"for\s+\w+\s+in", line):
                    in_loop = True
                elif line.strip() == "" or not line.startswith(" "):
                    in_loop = False

                if in_loop and re.search(r"len\(", line):
                    issues.append(
                        QualityIssue(
                            file_path=str(file_path),
                            line_number=i,
                            severity="minor",
                            category="performance",
                            message="å¾ªç¯ä¸­é‡å¤è®¡ç®—len()",
                            rule_id="P002",
                            suggestion="å°†len()è®¡ç®—ç§»åˆ°å¾ªç¯å¤–",
                        )
                    )

        except Exception as e:
            logger.error(f"Pythonæ€§èƒ½æ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _check_shell_performance(self, file_path: Path) -> List[QualityIssue]:
        """æ£€æŸ¥Shellè„šæœ¬æ€§èƒ½"""
        issues = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            import re

            # æ£€æŸ¥é¢‘ç¹çš„å¤–éƒ¨å‘½ä»¤è°ƒç”¨
            for i, line in enumerate(lines, 1):
                pass  # Auto-fixed empty block
                # æ£€æŸ¥åœ¨å¾ªç¯ä¸­ä½¿ç”¨å¤–éƒ¨å‘½ä»¤
                if "while" in line or "for" in line:
                    pass  # Auto-fixed empty block
                    # ç®€å•æ£€æŸ¥ä¸‹å‡ è¡Œæ˜¯å¦æœ‰å¤–éƒ¨å‘½ä»¤
                    for j in range(i, min(i + 10, len(lines))):
                        if re.search(r"(grep|sed|awk|cut)\s", lines[j]):
                            issues.append(
                                QualityIssue(
                                    file_path=str(file_path),
                                    line_number=j + 1,
                                    severity="minor",
                                    category="performance",
                                    message="å¾ªç¯ä¸­ä½¿ç”¨å¤–éƒ¨å‘½ä»¤å¯èƒ½å½±å“æ€§èƒ½",
                                    rule_id="P101",
                                    suggestion="è€ƒè™‘ä½¿ç”¨å†…ç½®çš„bashåŠŸèƒ½",
                                )
                            )
                            break

        except Exception as e:
            logger.error(f"Shellæ€§èƒ½æ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _check_maintainability(self, files: List[Path]) -> List[QualityIssue]:
        """æ£€æŸ¥å¯ç»´æŠ¤æ€§"""
        issues = []
        logger.info("æ£€æŸ¥å¯ç»´æŠ¤æ€§...")

        # æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡
        if self.tools["pytest"]:
            issues.extend(self._check_test_coverage())

        # æ£€æŸ¥ä»£ç é‡å¤
        issues.extend(self._check_code_duplication(files))

        # æ£€æŸ¥ç±»å‹æç¤º (Python)
        python_files = [f for f in files if f.suffix == ".py"]
        for file_path in python_files:
            issues.extend(self._check_type_hints(file_path))

        logger.info(f"å¯ç»´æŠ¤æ€§æ£€æŸ¥å®Œæˆï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜")
        return issues

    def _check_test_coverage(self) -> List[QualityIssue]:
        """æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡"""
        issues = []

        try:
            pass  # Auto-fixed empty block
            # è¿è¡Œpytestè·å–è¦†ç›–ç‡
            result = subprocess.run(
                [
                    "pytest",
                    "--cov=.claude",
                    "--cov-report=json",
                    "--cov-report=term-missing",
                    "--quiet",
                ],
                capture_output=True,
                text=True,
                cwd=self.project_path,
            )

            # æŸ¥æ‰¾coverage.jsonæ–‡ä»¶
            coverage_file = self.project_path / "coverage.json"
            if coverage_file.exists():
                with open(coverage_file, "r") as f:
                    coverage_data = json.load(f)

                total_coverage = coverage_data.get("totals", {}).get(
                    "percent_covered", 0
                )
                min_coverage = self.rules["maintainability"]["min_test_coverage"]

                if total_coverage < min_coverage:
                    issues.append(
                        QualityIssue(
                            file_path="é¡¹ç›®æ•´ä½“",
                            line_number=1,
                            severity="major",
                            category="maintainability",
                            message=f"æµ‹è¯•è¦†ç›–ç‡ä¸è¶³ ({total_coverage:.1f}% < {min_coverage}%)",
                            rule_id="M001",
                            suggestion="å¢åŠ å•å…ƒæµ‹è¯•æé«˜è¦†ç›–ç‡",
                        )
                    )

        except Exception as e:
            logger.warning(f"æµ‹è¯•è¦†ç›–ç‡æ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _check_code_duplication(self, files: List[Path]) -> List[QualityIssue]:
        """æ£€æŸ¥ä»£ç é‡å¤"""
        issues = []

        try:
            pass  # Auto-fixed empty block
            # ç®€å•çš„ä»£ç é‡å¤æ£€æŸ¥ - è®¡ç®—æ–‡ä»¶å†…å®¹å“ˆå¸Œ
            file_hashes = {}

            for file_path in files:
                if file_path.suffix in [".py", ".sh"]:
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        # å»é™¤ç©ºç™½å’Œæ³¨é‡Šåè®¡ç®—å“ˆå¸Œ
                        normalized = re.sub(r"#.*$", "", content, flags=re.MULTILINE)
                        normalized = re.sub(r"\s+", " ", normalized).strip()

                        if len(normalized) > 100:  # åªæ£€æŸ¥è¶³å¤Ÿé•¿çš„æ–‡ä»¶
                            content_hash = hashlib.md5(normalized.encode()).hexdigest()

                            if content_hash in file_hashes:
                                issues.append(
                                    QualityIssue(
                                        file_path=str(file_path),
                                        line_number=1,
                                        severity="major",
                                        category="maintainability",
                                        message=f"æ£€æµ‹åˆ°é‡å¤ä»£ç ï¼Œä¸ {file_hashes[content_hash]} ç›¸ä¼¼",
                                        rule_id="M002",
                                        suggestion="è€ƒè™‘æå–å…¬å…±ä»£ç åˆ°å…±äº«æ¨¡å—",
                                    )
                                )
                            else:
                                file_hashes[content_hash] = str(file_path)

        except Exception as e:
            logger.error(f"ä»£ç é‡å¤æ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _check_type_hints(self, file_path: Path) -> List[QualityIssue]:
        """æ£€æŸ¥Pythonç±»å‹æç¤º"""
        issues = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            import ast

            try:
                tree = ast.parse(content)

                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        pass  # Auto-fixed empty block
                        # æ£€æŸ¥å‡½æ•°å‚æ•°ç±»å‹æç¤º
                        for arg in node.args.args:
                            if arg.annotation is None and arg.arg != "self":
                                issues.append(
                                    QualityIssue(
                                        file_path=str(file_path),
                                        line_number=node.lineno,
                                        severity="minor",
                                        category="maintainability",
                                        message=f"å‡½æ•° {node.name} çš„å‚æ•° {arg.arg} ç¼ºå°‘ç±»å‹æç¤º",
                                        rule_id="M003",
                                        suggestion="æ·»åŠ ç±»å‹æç¤ºæé«˜ä»£ç å¯è¯»æ€§",
                                    )
                                )

                        # æ£€æŸ¥è¿”å›å€¼ç±»å‹æç¤º
                        if node.returns is None and node.name != "__init__":
                            issues.append(
                                QualityIssue(
                                    file_path=str(file_path),
                                    line_number=node.lineno,
                                    severity="minor",
                                    category="maintainability",
                                    message=f"å‡½æ•° {node.name} ç¼ºå°‘è¿”å›å€¼ç±»å‹æç¤º",
                                    rule_id="M004",
                                    suggestion="æ·»åŠ è¿”å›å€¼ç±»å‹æç¤º",
                                )
                            )

            except SyntaxError:
                pass  # Auto-fixed empty block
                # è¯­æ³•é”™è¯¯ï¼Œè·³è¿‡ç±»å‹æ£€æŸ¥
                pass

        except Exception as e:
            logger.error(f"ç±»å‹æç¤ºæ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _run_flake8(self, file_path: Path) -> List[QualityIssue]:
        """è¿è¡Œflake8æ£€æŸ¥"""
        issues = []

        try:
            result = subprocess.run(
                ["flake8", "--format=json", str(file_path)],
                capture_output=True,
                text=True,
            )

            if result.stdout:
                flake8_issues = json.loads(result.stdout)
                for issue in flake8_issues:
                    issues.append(
                        QualityIssue(
                            file_path=issue["filename"],
                            line_number=issue["line_number"],
                            severity="minor",
                            category="readability",
                            message=f"Flake8: {issue['text']}",
                            rule_id=issue["code"],
                            suggestion="ä¿®å¤ä»£ç è§„èŒƒé—®é¢˜",
                        )
                    )

        except Exception as e:
            logger.debug(f"flake8æ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _run_black_check(self, file_path: Path) -> List[QualityIssue]:
        """è¿è¡Œblackæ ¼å¼æ£€æŸ¥"""
        issues = []

        try:
            result = subprocess.run(
                ["black", "--check", "--diff", str(file_path)],
                capture_output=True,
                text=True,
            )

            if result.returncode != 0 and result.stdout:
                issues.append(
                    QualityIssue(
                        file_path=str(file_path),
                        line_number=1,
                        severity="minor",
                        category="readability",
                        message="ä»£ç æ ¼å¼ä¸ç¬¦åˆblackæ ‡å‡†",
                        rule_id="BLACK001",
                        suggestion="è¿è¡Œ black å‘½ä»¤æ ¼å¼åŒ–ä»£ç ",
                    )
                )

        except Exception as e:
            logger.debug(f"blackæ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _run_shellcheck(self, file_path: Path) -> List[QualityIssue]:
        """è¿è¡Œshellcheckæ£€æŸ¥"""
        issues = []

        try:
            result = subprocess.run(
                ["shellcheck", "-f", "json", str(file_path)],
                capture_output=True,
                text=True,
            )

            if result.stdout:
                shellcheck_issues = json.loads(result.stdout)
                for issue in shellcheck_issues:
                    severity_map = {
                        "error": "critical",
                        "warning": "major",
                        "info": "minor",
                        "style": "minor",
                    }

                    issues.append(
                        QualityIssue(
                            file_path=str(file_path),
                            line_number=issue["line"],
                            severity=severity_map.get(issue["level"], "minor"),
                            category="readability",
                            message=f"ShellCheck: {issue['message']}",
                            rule_id=f"SC{issue['code']}",
                            suggestion="ä¿®å¤shellè„šæœ¬é—®é¢˜",
                        )
                    )

        except Exception as e:
            logger.debug(f"shellcheckæ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _run_yamllint(self, file_path: Path) -> List[QualityIssue]:
        """è¿è¡Œyamllintæ£€æŸ¥"""
        issues = []

        try:
            result = subprocess.run(
                ["yamllint", "-f", "parsable", str(file_path)],
                capture_output=True,
                text=True,
            )

            if result.stdout:
                for line in result.stdout.strip().split("\n"):
                    if ":" in line:
                        parts = line.split(":")
                        if len(parts) >= 4:
                            issues.append(
                                QualityIssue(
                                    file_path=parts[0],
                                    line_number=int(parts[1]),
                                    severity="minor",
                                    category="readability",
                                    message=f"YAML: {':'.join(parts[3:])}",
                                    rule_id="YAML001",
                                    suggestion="ä¿®å¤YAMLæ ¼å¼é—®é¢˜",
                                )
                            )

        except Exception as e:
            logger.debug(f"yamllintæ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _run_bandit(self, files: List[Path]) -> List[QualityIssue]:
        """è¿è¡Œbanditå®‰å…¨æ£€æŸ¥"""
        issues = []

        try:
            pass  # Auto-fixed empty block
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
            files_list = self.temp_dir / "bandit_files.txt"
            with open(files_list, "w") as f:
                for file_path in files:
                    f.write(f"{file_path}\n")

            result = subprocess.run(
                ["bandit", "-f", "json", "-r", str(self.project_path / ".claude")],
                capture_output=True,
                text=True,
            )

            if result.stdout:
                bandit_report = json.loads(result.stdout)
                for issue in bandit_report.get("results", []):
                    severity_map = {
                        "HIGH": "critical",
                        "MEDIUM": "major",
                        "LOW": "minor",
                    }

                    issues.append(
                        QualityIssue(
                            file_path=issue["filename"],
                            line_number=issue["line_number"],
                            severity=severity_map.get(issue["issue_severity"], "minor"),
                            category="security",
                            message=f"Bandit: {issue['issue_text']}",
                            rule_id=issue["test_id"],
                            suggestion="ä¿®å¤å®‰å…¨é—®é¢˜",
                        )
                    )

        except Exception as e:
            logger.debug(f"banditæ£€æŸ¥å¤±è´¥: {e}")

        return issues

    def _calculate_score(
        self, issues: List[QualityIssue], total_files: int
    ) -> QualityScore:
        """è®¡ç®—è´¨é‡åˆ†æ•°"""
        score = QualityScore()

        # æŒ‰ç±»åˆ«åˆ†ç»„é—®é¢˜
        category_issues = {}
        for issue in issues:
            if issue.category not in category_issues:
                category_issues[issue.category] = []
            category_issues[issue.category].append(issue)

        # è®¡ç®—å„é¡¹åˆ†æ•°
        score.readability = self._calculate_category_score(
            category_issues.get("readability", []), 25, total_files
        )

        score.security = self._calculate_category_score(
            category_issues.get("security", []), 30, total_files
        )

        score.performance = self._calculate_category_score(
            category_issues.get("performance", []), 20, total_files
        )

        score.maintainability = self._calculate_category_score(
            category_issues.get("maintainability", []), 25, total_files
        )

        return score

    def _calculate_category_score(
        self, issues: List[QualityIssue], max_score: int, total_files: int
    ) -> int:
        """è®¡ç®—å•ä¸ªç±»åˆ«åˆ†æ•°"""
        if not issues:
            return max_score

        # æŒ‰ä¸¥é‡æ€§åˆ†é…æƒé‡
        severity_weights = {"critical": 10, "major": 5, "minor": 2, "info": 1}

        total_penalty = sum(severity_weights.get(issue.severity, 1) for issue in issues)

        # æ ¹æ®æ–‡ä»¶æ•°é‡è°ƒæ•´æƒ©ç½š
        normalized_penalty = total_penalty / max(total_files, 1)

        # è®¡ç®—åˆ†æ•°ï¼ˆç¡®ä¿ä¸ä½äº0ï¼‰
        score = max(0, max_score - int(normalized_penalty))

        return score

    def _generate_recommendations(
        self, issues: List[QualityIssue], score: QualityScore
    ) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # æŒ‰ä¸¥é‡æ€§åˆ†ç±»é—®é¢˜
        critical_issues = [i for i in issues if i.severity == "critical"]
        major_issues = [i for i in issues if i.severity == "major"]

        if critical_issues:
            recommendations.append(f"ğŸš¨ é«˜ä¼˜å…ˆçº§ï¼šä¿®å¤ {len(critical_issues)} ä¸ªä¸¥é‡å®‰å…¨é—®é¢˜")

        if major_issues:
            recommendations.append(f"âš ï¸ ä¸­ä¼˜å…ˆçº§ï¼šè§£å†³ {len(major_issues)} ä¸ªé‡è¦è´¨é‡é—®é¢˜")

        # æŒ‰ç±»åˆ«æä¾›å…·ä½“å»ºè®®
        if score.readability < 20:
            recommendations.append("ğŸ“– æ”¹è¿›ä»£ç å¯è¯»æ€§ï¼šç»Ÿä¸€ä»£ç æ ¼å¼ï¼Œå¢åŠ æ³¨é‡Š")

        if score.security < 25:
            recommendations.append("ğŸ”’ åŠ å¼ºå®‰å…¨æ€§ï¼šä¿®å¤å®‰å…¨æ¼æ´ï¼Œæ·»åŠ è¾“å…¥éªŒè¯")

        if score.performance < 15:
            recommendations.append("âš¡ ä¼˜åŒ–æ€§èƒ½ï¼šä¼˜åŒ–ç®—æ³•ï¼Œå‡å°‘èµ„æºæ¶ˆè€—")

        if score.maintainability < 20:
            recommendations.append("ğŸ”§ æé«˜å¯ç»´æŠ¤æ€§ï¼šå¢åŠ æµ‹è¯•ï¼Œæ·»åŠ ç±»å‹æç¤º")

        # å·¥å…·ä½¿ç”¨å»ºè®®
        if not self.tools["black"]:
            recommendations.append("ğŸ› ï¸ å®‰è£…å¹¶ä½¿ç”¨ black è¿›è¡Œä»£ç æ ¼å¼åŒ–")

        if not self.tools["flake8"]:
            recommendations.append("ğŸ› ï¸ å®‰è£…å¹¶ä½¿ç”¨ flake8 è¿›è¡Œä»£ç è§„èŒƒæ£€æŸ¥")

        return recommendations

    def generate_report(self, report: QualityReport, output_file: str = None) -> str:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        if output_file is None:
            output_file = (
                f"quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            )

        output_path = self.project_path / output_file

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        content = f"""# ä»£ç è´¨é‡å®¡æŸ¥æŠ¥å‘Š

## ğŸ“Š æ€»ä½“è¯„åˆ†: {report.score.total}/100 ({report.score.grade})

**æ£€æŸ¥æ—¶é—´**: {report.timestamp}
**é¡¹ç›®è·¯å¾„**: {report.project_path}
**æ£€æŸ¥æ–‡ä»¶æ•°**: {report.total_files}
**æ‰§è¡Œæ—¶é—´**: {report.execution_time:.2f}ç§’

### ğŸ¯ åˆ†é¡¹å¾—åˆ†
- **å¯è¯»æ€§**: {report.score.readability}/25
- **å®‰å…¨æ€§**: {report.score.security}/30
- **æ€§èƒ½**: {report.score.performance}/20
- **å¯ç»´æŠ¤æ€§**: {report.score.maintainability}/25

### ğŸ“‹ é—®é¢˜ç»Ÿè®¡
"""

        # ç»Ÿè®¡é—®é¢˜
        issue_stats = {}
        severity_stats = {}

        for issue in report.issues:
            pass  # Auto-fixed empty block
            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            if issue.category not in issue_stats:
                issue_stats[issue.category] = 0
            issue_stats[issue.category] += 1

            # æŒ‰ä¸¥é‡æ€§ç»Ÿè®¡
            if issue.severity not in severity_stats:
                severity_stats[issue.severity] = 0
            severity_stats[issue.severity] += 1

        content += "\n#### æŒ‰ç±»åˆ«åˆ†å¸ƒ\n"
        for category, count in issue_stats.items():
            content += f"- {category}: {count}ä¸ª\n"

        content += "\n#### æŒ‰ä¸¥é‡æ€§åˆ†å¸ƒ\n"
        for severity, count in severity_stats.items():
            icon = {"critical": "ğŸš¨", "major": "âš ï¸", "minor": "ğŸ’¡", "info": "â„¹ï¸"}.get(
                severity, "â€¢"
            )
            content += f"- {icon} {severity}: {count}ä¸ª\n"

        # è¯¦ç»†é—®é¢˜åˆ—è¡¨
        if report.issues:
            content += "\n### ğŸ” è¯¦ç»†é—®é¢˜åˆ—è¡¨\n\n"

            # æŒ‰æ–‡ä»¶åˆ†ç»„
            issues_by_file = {}
            for issue in report.issues:
                if issue.file_path not in issues_by_file:
                    issues_by_file[issue.file_path] = []
                issues_by_file[issue.file_path].append(issue)

            for file_path, file_issues in issues_by_file.items():
                rel_path = (
                    Path(file_path).relative_to(self.project_path)
                    if Path(file_path).is_absolute()
                    else file_path
                )
                content += f"#### ğŸ“„ {rel_path}\n\n"

                for issue in sorted(file_issues, key=lambda x: x.line_number):
                    severity_icon = {
                        "critical": "ğŸš¨",
                        "major": "âš ï¸",
                        "minor": "ğŸ’¡",
                        "info": "â„¹ï¸",
                    }.get(issue.severity, "â€¢")

                    content += f"**{severity_icon} ç¬¬{issue.line_number}è¡Œ** [{issue.rule_id}] {issue.message}\n"
                    if issue.suggestion:
                        content += f"  ğŸ’¡ å»ºè®®: {issue.suggestion}\n"
                    content += "\n"

        # æ”¹è¿›å»ºè®®
        if report.recommendations:
            content += "\n### ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
            for rec in report.recommendations:
                content += f"- {rec}\n"

        # è´¨é‡æ”¹è¿›è¡ŒåŠ¨è®¡åˆ’
        content += "\n### ğŸ“‹ è¡ŒåŠ¨è®¡åˆ’\n\n"

        critical_count = len([i for i in report.issues if i.severity == "critical"])
        major_count = len([i for i in report.issues if i.severity == "major"])
        minor_count = len([i for i in report.issues if i.severity == "minor"])

        if critical_count > 0:
            content += f"- [ ] **ç«‹å³å¤„ç†**: ä¿®å¤ {critical_count} ä¸ªä¸¥é‡é—®é¢˜\n"

        if major_count > 0:
            content += f"- [ ] **æœ¬å‘¨å†…**: è§£å†³ {major_count} ä¸ªé‡è¦é—®é¢˜\n"

        if minor_count > 0:
            content += f"- [ ] **é€æ­¥æ”¹è¿›**: ä¼˜åŒ– {minor_count} ä¸ªæ¬¡è¦é—®é¢˜\n"

        content += "\n### ğŸ† è´¨é‡æ”¹è¿›ç›®æ ‡\n\n"
        if report.score.total < 70:
            content += "- ğŸ¯ çŸ­æœŸç›®æ ‡: è¾¾åˆ°70åˆ†ï¼ˆåŠæ ¼çº¿ï¼‰\n"
            content += "- ğŸ¯ ä¸­æœŸç›®æ ‡: è¾¾åˆ°80åˆ†ï¼ˆè‰¯å¥½ï¼‰\n"
            content += "- ğŸ¯ é•¿æœŸç›®æ ‡: è¾¾åˆ°90åˆ†ï¼ˆä¼˜ç§€ï¼‰\n"
        elif report.score.total < 80:
            content += "- ğŸ¯ çŸ­æœŸç›®æ ‡: è¾¾åˆ°80åˆ†ï¼ˆè‰¯å¥½ï¼‰\n"
            content += "- ğŸ¯ é•¿æœŸç›®æ ‡: è¾¾åˆ°90åˆ†ï¼ˆä¼˜ç§€ï¼‰\n"
        elif report.score.total < 90:
            content += "- ğŸ¯ ç›®æ ‡: è¾¾åˆ°90åˆ†ï¼ˆä¼˜ç§€ï¼‰\n"
        else:
            content += "- ğŸ† æ­å–œï¼å·²è¾¾åˆ°ä¼˜ç§€æ°´å¹³ï¼Œç»§ç»­ä¿æŒï¼\n"

        content += f"\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        content += f"*è´¨é‡æ£€æŸ¥å·¥å…·: Claude Enhancer Quality Checker v1.0.0*\n"

        # å†™å…¥æ–‡ä»¶
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(content)

        logger.info(f"è´¨é‡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        return str(output_path)

    def save_json_report(self, report: QualityReport, output_file: str = None) -> str:
        """ä¿å­˜JSONæ ¼å¼æŠ¥å‘Š"""
        if output_file is None:
            output_file = (
                f"quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )

        output_path = self.project_path / output_file

        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
        report_dict = {
            "timestamp": report.timestamp,
            "project_path": report.project_path,
            "total_files": report.total_files,
            "score": asdict(report.score),
            "issues": [asdict(issue) for issue in report.issues],
            "recommendations": report.recommendations,
            "execution_time": report.execution_time,
        }

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(report_dict, f, indent=2, ensure_ascii=False)

        logger.info(f"JSONæŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        return str(output_path)


def main():
    """CLIå…¥å£"""
    parser = argparse.ArgumentParser(
        description="Claude Enhancer 5.0 ä»£ç è´¨é‡æ£€æŸ¥å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python quality_checker.py --project /path/to/project
  python quality_checker.py --include "**/*.py" --exclude "**/test_*"
  python quality_checker.py --output-format both --report-name my_report
        """,
    )

    parser.add_argument("--project", "-p", default=".", help="é¡¹ç›®è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)")

    parser.add_argument(
        "--include",
        nargs="+",
        default=["**/*.py", "**/*.sh", "**/*.yaml", "**/*.yml"],
        help="åŒ…å«çš„æ–‡ä»¶æ¨¡å¼ (é»˜è®¤: Python, Shell, YAMLæ–‡ä»¶)",
    )

    parser.add_argument(
        "--exclude",
        nargs="+",
        default=[
            "**/venv/**",
            "**/.venv/**",
            "**/node_modules/**",
            "**/.__pycache__/**",
            "**/.git/**",
        ],
        help="æ’é™¤çš„æ–‡ä»¶æ¨¡å¼",
    )

    parser.add_argument(
        "--output-format",
        choices=["markdown", "json", "both"],
        default="markdown",
        help="è¾“å‡ºæ ¼å¼ (é»˜è®¤: markdown)",
    )

    parser.add_argument("--report-name", help="æŠ¥å‘Šæ–‡ä»¶åå‰ç¼€")

    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")

    parser.add_argument("--config", help="è‡ªå®šä¹‰é…ç½®æ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    try:
        pass  # Auto-fixed empty block
        # åˆ›å»ºè´¨é‡æ£€æŸ¥å™¨
        checker = QualityChecker(args.project)

        # æ‰§è¡Œæ£€æŸ¥
        report = checker.check_project(args.include, args.exclude)

        # ç”ŸæˆæŠ¥å‘Š
        if args.output_format in ["markdown", "both"]:
            md_file = args.report_name + ".md" if args.report_name else None
            md_path = checker.generate_report(report, md_file)
            print(f"ğŸ“„ MarkdownæŠ¥å‘Š: {md_path}")

        if args.output_format in ["json", "both"]:
            json_file = args.report_name + ".json" if args.report_name else None
            json_path = checker.save_json_report(report, json_file)
            print(f"ğŸ“Š JSONæŠ¥å‘Š: {json_path}")

        # è¾“å‡ºæ‘˜è¦
        print(f"\nğŸ¯ è´¨é‡æ£€æŸ¥å®Œæˆ")
        print(f"æ€»åˆ†: {report.score.total}/100 ({report.score.grade})")
        print(f"é—®é¢˜æ€»æ•°: {len(report.issues)}")

        # æ ¹æ®è´¨é‡åˆ†æ•°è®¾ç½®é€€å‡ºç 
        if report.score.total >= 80:
            sys.exit(0)  # è‰¯å¥½åŠä»¥ä¸Š
        elif report.score.total >= 70:
            sys.exit(1)  # åŠæ ¼ä½†éœ€æ”¹è¿›
        else:
            sys.exit(2)  # ä¸åŠæ ¼

    except KeyboardInterrupt:
        print("\nâŒ æ£€æŸ¥è¢«ä¸­æ–­")
        sys.exit(130)

    except Exception as e:
        logger.error(f"è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
