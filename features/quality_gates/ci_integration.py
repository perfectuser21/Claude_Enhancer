#!/usr/bin/env python3
"""
Perfect21 CI/CD è´¨é‡é—¨é›†æˆ
=========================

ä¸CI/CDç®¡é“é›†æˆï¼Œè‡ªåŠ¨æ‰§è¡Œè´¨é‡æ£€æŸ¥
"""

import asyncio
import json
import os
import subprocess
import yaml
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

from .quality_gate_engine import QualityGateEngine, QualityGateConfig


class CIIntegration:
    """CI/CDé›†æˆç®¡ç†å™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.config = QualityGateConfig()

    async def setup_pre_commit_hooks(self) -> Dict[str, Any]:
        """è®¾ç½®é¢„æäº¤é’©å­"""
        try:
            # åˆ›å»ºGit hooksç›®å½•
            hooks_dir = self.project_root / ".git" / "hooks"
            hooks_dir.mkdir(exist_ok=True)

            # åˆ›å»ºpre-commité’©å­
            pre_commit_hook = hooks_dir / "pre-commit"
            hook_content = self._generate_pre_commit_hook()

            with open(pre_commit_hook, 'w', encoding='utf-8') as f:
                f.write(hook_content)

            # è®¾ç½®æ‰§è¡Œæƒé™
            pre_commit_hook.chmod(0o755)

            # åˆ›å»ºpre-pushé’©å­
            pre_push_hook = hooks_dir / "pre-push"
            push_hook_content = self._generate_pre_push_hook()

            with open(pre_push_hook, 'w', encoding='utf-8') as f:
                f.write(push_hook_content)

            pre_push_hook.chmod(0o755)

            return {
                "status": "success",
                "message": "Git hookså®‰è£…æˆåŠŸ",
                "hooks_installed": ["pre-commit", "pre-push"],
                "hooks_dir": str(hooks_dir)
            }

        except Exception as e:
            return {
                "status": "error",
                "message": f"Git hookså®‰è£…å¤±è´¥: {str(e)}",
                "error": str(e)
            }

    def _generate_pre_commit_hook(self) -> str:
        """ç”Ÿæˆpre-commité’©å­è„šæœ¬"""
        return '''#!/bin/bash
# Perfect21 Pre-commit Quality Gate

set -e

echo "ğŸ” è¿è¡ŒPerfect21è´¨é‡é—¨æ£€æŸ¥..."

# è¿è¡Œå¿«é€Ÿè´¨é‡æ£€æŸ¥
python3 -c "
import asyncio
import sys
sys.path.append('.')
from features.quality_gates.quality_gate_engine import QualityGateEngine, QualityGateConfig

async def run_quick_check():
    config = QualityGateConfig()
    config.fail_fast = True
    config.parallel_execution = True

    engine = QualityGateEngine('.', config)
    results = await engine.run_quick_check()

    if results['status'] != 'passed':
        print(f'\\nâŒ è´¨é‡é—¨æ£€æŸ¥å¤±è´¥: {results[\"message\"]}')
        print('\\nè¯¦ç»†ä¿¡æ¯:')
        for gate_name, result in results['details'].items():
            if hasattr(result, 'status') and result.status.value != 'passed':
                print(f'  - {gate_name}: {result.message}')
                for violation in result.violations[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªè¿è§„
                    print(f'    â€¢ {violation.get(\"message\", str(violation))}')

        print('\\nğŸ’¡ å»ºè®®:')
        suggestions = set()
        for gate_name, result in results['details'].items():
            if hasattr(result, 'suggestions'):
                suggestions.update(result.suggestions[:2])
        for suggestion in list(suggestions)[:5]:
            print(f'  - {suggestion}')

        sys.exit(1)
    else:
        print(f'âœ… è´¨é‡é—¨æ£€æŸ¥é€šè¿‡ (åˆ†æ•°: {results[\"score\"]:.1f})')

asyncio.run(run_quick_check())
"

echo "âœ… è´¨é‡é—¨æ£€æŸ¥å®Œæˆ"
'''

    def _generate_pre_push_hook(self) -> str:
        """ç”Ÿæˆpre-pushé’©å­è„šæœ¬"""
        return '''#!/bin/bash
# Perfect21 Pre-push Quality Gate

set -e

echo "ğŸš€ è¿è¡Œå®Œæ•´è´¨é‡é—¨æ£€æŸ¥..."

# è¿è¡Œå®Œæ•´è´¨é‡æ£€æŸ¥
python3 -c "
import asyncio
import sys
sys.path.append('.')
from features.quality_gates.quality_gate_engine import QualityGateEngine, QualityGateConfig

async def run_full_check():
    config = QualityGateConfig()
    config.fail_fast = False
    config.parallel_execution = True

    engine = QualityGateEngine('.', config)
    results = await engine.run_all_gates('push')

    overall = results.get('overall')
    if not overall or overall.status.value == 'failed':
        print(f'\\nâŒ è´¨é‡é—¨æ£€æŸ¥å¤±è´¥')
        print(engine.generate_report(results))
        sys.exit(1)
    elif overall.status.value == 'warning':
        print(f'\\nâš ï¸  è´¨é‡é—¨æ£€æŸ¥æœ‰è­¦å‘Š')
        print(engine.generate_report(results))
        print('\\nç»§ç»­æ¨é€ï¼Œä½†è¯·æ³¨æ„ä¿®å¤è­¦å‘Š...')
    else:
        print(f'\\nâœ… æ‰€æœ‰è´¨é‡é—¨æ£€æŸ¥é€šè¿‡ (åˆ†æ•°: {overall.score:.1f})')

asyncio.run(run_full_check())
"

echo "âœ… å®Œæ•´è´¨é‡æ£€æŸ¥å®Œæˆ"
'''

    async def generate_github_actions_workflow(self) -> Dict[str, Any]:
        """ç”ŸæˆGitHub Actionså·¥ä½œæµ"""
        try:
            workflow_content = {
                "name": "Perfect21 Quality Gates",
                "on": {
                    "push": {
                        "branches": ["main", "develop", "feature/*"]
                    },
                    "pull_request": {
                        "branches": ["main", "develop"]
                    }
                },
                "jobs": {
                    "quality-gates": {
                        "runs-on": "ubuntu-latest",
                        "strategy": {
                            "matrix": {
                                "python-version": ["3.8", "3.9", "3.10", "3.11"]
                            }
                        },
                        "steps": [
                            {
                                "uses": "actions/checkout@v3"
                            },
                            {
                                "name": "Set up Python ${{ matrix.python-version }}",
                                "uses": "actions/setup-python@v4",
                                "with": {
                                    "python-version": "${{ matrix.python-version }}"
                                }
                            },
                            {
                                "name": "Install dependencies",
                                "run": self._get_install_dependencies_script()
                            },
                            {
                                "name": "Run Code Quality Gate",
                                "run": "python3 -m pytest tests/ --cov=. --cov-report=xml --cov-report=json"
                            },
                            {
                                "name": "Run Security Gate",
                                "run": "python3 -m bandit -r . -f json -o bandit-report.json || true"
                            },
                            {
                                "name": "Run Performance Gate",
                                "run": self._get_performance_test_script()
                            },
                            {
                                "name": "Run Architecture Gate",
                                "run": self._get_architecture_test_script()
                            },
                            {
                                "name": "Run All Quality Gates",
                                "run": self._get_quality_gates_script()
                            },
                            {
                                "name": "Upload Coverage Reports",
                                "uses": "codecov/codecov-action@v3",
                                "with": {
                                    "file": "./coverage.xml",
                                    "flags": "unittests",
                                    "name": "codecov-umbrella"
                                }
                            },
                            {
                                "name": "Upload Quality Gate Results",
                                "uses": "actions/upload-artifact@v3",
                                "with": {
                                    "name": "quality-gate-results",
                                    "path": ".perfect21/quality_gate_history.json"
                                }
                            }
                        ]
                    }
                }
            }

            # ä¿å­˜å·¥ä½œæµæ–‡ä»¶
            workflows_dir = self.project_root / ".github" / "workflows"
            workflows_dir.mkdir(parents=True, exist_ok=True)

            workflow_file = workflows_dir / "quality-gates.yml"
            with open(workflow_file, 'w', encoding='utf-8') as f:
                yaml.dump(workflow_content, f, default_flow_style=False, sort_keys=False)

            return {
                "status": "success",
                "message": "GitHub Actionså·¥ä½œæµå·²ç”Ÿæˆ",
                "file": str(workflow_file),
                "workflow": workflow_content
            }

        except Exception as e:
            return {
                "status": "error",
                "message": f"ç”Ÿæˆå·¥ä½œæµå¤±è´¥: {str(e)}",
                "error": str(e)
            }

    def _get_install_dependencies_script(self) -> str:
        """è·å–ä¾èµ–å®‰è£…è„šæœ¬"""
        return """
pip install --upgrade pip
pip install -r requirements.txt
pip install pytest pytest-cov bandit safety radon flake8 mypy
"""

    def _get_performance_test_script(self) -> str:
        """è·å–æ€§èƒ½æµ‹è¯•è„šæœ¬"""
        return """
python3 -c "
import asyncio
import sys
sys.path.append('.')
from features.quality_gates.performance_gate import PerformanceGate
from features.quality_gates.quality_gate_engine import QualityGateConfig

async def test_performance():
    config = QualityGateConfig()
    gate = PerformanceGate('.', config)
    result = await gate.check('ci')

    if result.status.value == 'failed':
        print(f'Performance gate failed: {result.message}')
        sys.exit(1)
    else:
        print(f'Performance gate passed: {result.score:.1f}')

asyncio.run(test_performance())
"
"""

    def _get_architecture_test_script(self) -> str:
        """è·å–æ¶æ„æµ‹è¯•è„šæœ¬"""
        return """
python3 -c "
import asyncio
import sys
sys.path.append('.')
from features.quality_gates.architecture_gate import ArchitectureGate
from features.quality_gates.quality_gate_engine import QualityGateConfig

async def test_architecture():
    config = QualityGateConfig()
    gate = ArchitectureGate('.', config)
    result = await gate.check('ci')

    if result.status.value == 'failed':
        print(f'Architecture gate failed: {result.message}')
        sys.exit(1)
    else:
        print(f'Architecture gate passed: {result.score:.1f}')

asyncio.run(test_architecture())
"
"""

    def _get_quality_gates_script(self) -> str:
        """è·å–å®Œæ•´è´¨é‡é—¨æµ‹è¯•è„šæœ¬"""
        return """
python3 -c "
import asyncio
import sys
sys.path.append('.')
from features.quality_gates.quality_gate_engine import QualityGateEngine, QualityGateConfig

async def run_all_gates():
    config = QualityGateConfig()
    config.fail_fast = False
    config.parallel_execution = True

    engine = QualityGateEngine('.', config)
    results = await engine.run_all_gates('ci')

    print(engine.generate_report(results))

    overall = results.get('overall')
    if overall and overall.status.value == 'failed':
        sys.exit(1)

asyncio.run(run_all_gates())
"
"""

    async def generate_gitlab_ci_config(self) -> Dict[str, Any]:
        """ç”ŸæˆGitLab CIé…ç½®"""
        try:
            config_content = {
                "stages": ["test", "quality", "deploy"],
                "variables": {
                    "PIP_CACHE_DIR": "$CI_PROJECT_DIR/.cache/pip"
                },
                "cache": {
                    "paths": [".cache/pip", "venv/"]
                },
                "before_script": [
                    "python --version",
                    "pip install virtualenv",
                    "virtualenv venv",
                    "source venv/bin/activate",
                    "pip install --upgrade pip",
                    "pip install -r requirements.txt",
                    "pip install pytest pytest-cov bandit safety radon flake8"
                ],
                "test": {
                    "stage": "test",
                    "script": [
                        "pytest tests/ --cov=. --cov-report=xml --cov-report=json"
                    ],
                    "coverage": "/^TOTAL.+?(\\d+\\%)$/",
                    "artifacts": {
                        "reports": {
                            "coverage_report": {
                                "coverage_format": "cobertura",
                                "path": "coverage.xml"
                            }
                        }
                    }
                },
                "quality-gates": {
                    "stage": "quality",
                    "script": [
                        self._get_quality_gates_script()
                    ],
                    "artifacts": {
                        "paths": [".perfect21/quality_gate_history.json"],
                        "reports": {
                            "junit": "junit-*.xml"
                        }
                    },
                    "only": ["main", "develop", "merge_requests"]
                },
                "security-scan": {
                    "stage": "quality",
                    "script": [
                        "bandit -r . -f json -o bandit-report.json",
                        "safety check --json --output safety-report.json"
                    ],
                    "artifacts": {
                        "paths": ["bandit-report.json", "safety-report.json"]
                    },
                    "allow_failure": True
                }
            }

            # ä¿å­˜é…ç½®æ–‡ä»¶
            config_file = self.project_root / ".gitlab-ci.yml"
            with open(config_file, 'w', encoding='utf-8') as f:
                yaml.dump(config_content, f, default_flow_style=False, sort_keys=False)

            return {
                "status": "success",
                "message": "GitLab CIé…ç½®å·²ç”Ÿæˆ",
                "file": str(config_file),
                "config": config_content
            }

        except Exception as e:
            return {
                "status": "error",
                "message": f"ç”ŸæˆGitLab CIé…ç½®å¤±è´¥: {str(e)}",
                "error": str(e)
            }

    async def setup_continuous_monitoring(self) -> Dict[str, Any]:
        """è®¾ç½®æŒç»­ç›‘æ§"""
        try:
            # åˆ›å»ºç›‘æ§è„šæœ¬
            monitoring_script = self.project_root / "scripts" / "quality_monitor.py"
            monitoring_script.parent.mkdir(exist_ok=True)

            script_content = '''#!/usr/bin/env python3
"""
Perfect21 è´¨é‡æŒç»­ç›‘æ§
====================

å®šæœŸè¿è¡Œè´¨é‡æ£€æŸ¥å¹¶æŠ¥å‘Šç»“æœ
"""

import asyncio
import sys
import os
from datetime import datetime, timedelta
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))

from features.quality_gates.quality_gate_engine import QualityGateEngine, QualityGateConfig

async def run_monitoring():
    """è¿è¡Œè´¨é‡ç›‘æ§"""
    print(f"ğŸ” å¼€å§‹è´¨é‡ç›‘æ§ - {datetime.now().isoformat()}")

    config = QualityGateConfig()
    config.parallel_execution = True
    config.fail_fast = False

    engine = QualityGateEngine('.', config)

    # è¿è¡Œæ‰€æœ‰è´¨é‡é—¨
    results = await engine.run_all_gates('monitoring')

    # ç”ŸæˆæŠ¥å‘Š
    report = engine.generate_report(results)
    print(report)

    # ä¿å­˜ç›‘æ§ç»“æœ
    monitoring_dir = Path('.perfect21/monitoring')
    monitoring_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_file = monitoring_dir / f'quality_report_{timestamp}.txt'

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)

    # æ£€æŸ¥è´¨é‡è¶‹åŠ¿
    trends = engine.get_quality_trends(days=7)
    print("\\nğŸ“Š è´¨é‡è¶‹åŠ¿:")
    print(f"  æ€»æ‰§è¡Œæ¬¡æ•°: {trends.get('total_executions', 0)}")

    if trends.get('average_score_trend'):
        latest_score = trends['average_score_trend'][-1]['score']
        print(f"  æœ€æ–°å¹³å‡åˆ†æ•°: {latest_score}")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦
    overall = results.get('overall')
    if overall and overall.status.value == 'failed':
        print("\\nğŸš¨ è´¨é‡å‘Šè­¦: æ£€æµ‹åˆ°ä¸¥é‡è´¨é‡é—®é¢˜!")
        return 1
    elif overall and overall.status.value == 'warning':
        print("\\nâš ï¸  è´¨é‡è­¦å‘Š: å‘ç°è´¨é‡é—®é¢˜ï¼Œè¯·å…³æ³¨")
        return 0
    else:
        print("\\nâœ… è´¨é‡çŠ¶æ€è‰¯å¥½")
        return 0

if __name__ == "__main__":
    exit_code = asyncio.run(run_monitoring())
    sys.exit(exit_code)
'''

            with open(monitoring_script, 'w', encoding='utf-8') as f:
                f.write(script_content)

            monitoring_script.chmod(0o755)

            # åˆ›å»ºcronä»»åŠ¡é…ç½®
            cron_config = '''# Perfect21 è´¨é‡ç›‘æ§ Cron ä»»åŠ¡
# æ¯å¤©8ç‚¹è¿è¡Œè´¨é‡æ£€æŸ¥
0 8 * * * cd /path/to/Perfect21 && python3 scripts/quality_monitor.py >> logs/quality_monitor.log 2>&1

# æ¯å‘¨ä¸€æ—©ä¸Šç”Ÿæˆè´¨é‡è¶‹åŠ¿æŠ¥å‘Š
0 9 * * 1 cd /path/to/Perfect21 && python3 -c "
import asyncio
import sys
sys.path.append('.')
from features.quality_gates.quality_gate_engine import QualityGateEngine
engine = QualityGateEngine('.')
trends = engine.get_quality_trends(days=30)
print('Weekly Quality Trends:', trends)
" >> logs/weekly_trends.log 2>&1
'''

            cron_file = self.project_root / "scripts" / "quality_cron.txt"
            with open(cron_file, 'w', encoding='utf-8') as f:
                f.write(cron_config)

            return {
                "status": "success",
                "message": "æŒç»­ç›‘æ§å·²è®¾ç½®",
                "monitoring_script": str(monitoring_script),
                "cron_config": str(cron_file),
                "instructions": [
                    "1. å°†ç›‘æ§è„šæœ¬è®¾ç½®ä¸ºå¯æ‰§è¡Œ: chmod +x scripts/quality_monitor.py",
                    "2. æ·»åŠ cronä»»åŠ¡: crontab -eï¼Œç„¶åæ·»åŠ scripts/quality_cron.txtä¸­çš„å†…å®¹",
                    "3. ä¿®æ”¹cronä»»åŠ¡ä¸­çš„è·¯å¾„ä¸ºå®é™…é¡¹ç›®è·¯å¾„",
                    "4. ç¡®ä¿logsç›®å½•å­˜åœ¨: mkdir -p logs"
                ]
            }

        except Exception as e:
            return {
                "status": "error",
                "message": f"è®¾ç½®æŒç»­ç›‘æ§å¤±è´¥: {str(e)}",
                "error": str(e)
            }

    async def create_quality_dashboard(self) -> Dict[str, Any]:
        """åˆ›å»ºè´¨é‡ä»ªè¡¨æ¿"""
        try:
            dashboard_script = self.project_root / "scripts" / "quality_dashboard.py"
            dashboard_script.parent.mkdir(exist_ok=True)

            script_content = '''#!/usr/bin/env python3
"""
Perfect21 è´¨é‡ä»ªè¡¨æ¿
==================

ç”Ÿæˆè´¨é‡ç›‘æ§ä»ªè¡¨æ¿
"""

import asyncio
import json
import sys
from datetime import datetime, timedelta
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))

from features.quality_gates.quality_gate_engine import QualityGateEngine

async def generate_dashboard():
    """ç”Ÿæˆè´¨é‡ä»ªè¡¨æ¿"""
    engine = QualityGateEngine('.')

    # è·å–è´¨é‡è¶‹åŠ¿
    trends = engine.get_quality_trends(days=30)

    # è·å–æ‰§è¡Œå†å²
    history = engine.get_execution_history(limit=20)

    # ç”ŸæˆHTMLä»ªè¡¨æ¿
    html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Perfect21 è´¨é‡ä»ªè¡¨æ¿</title>
    <meta charset="utf-8">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        .header {{ background: #2196F3; color: white; padding: 20px; border-radius: 8px; }}
        .metric {{ background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 5px; }}
        .trend {{ display: flex; gap: 20px; flex-wrap: wrap; }}
        .chart {{ background: white; padding: 20px; border: 1px solid #ddd; border-radius: 5px; }}
        .violation {{ background: #ffebee; padding: 10px; margin: 5px 0; border-left: 4px solid #f44336; }}
        .success {{ background: #e8f5e8; padding: 10px; margin: 5px 0; border-left: 4px solid #4caf50; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ¯ Perfect21 è´¨é‡ä»ªè¡¨æ¿</h1>
        <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    </div>

    <div class="trend">
        <div class="metric">
            <h3>ğŸ“Š è´¨é‡æ¦‚è§ˆ</h3>
            <p>æ€»æ‰§è¡Œæ¬¡æ•°: {trends.get('total_executions', 0)}</p>
            <p>ç›‘æ§å¤©æ•°: 30å¤©</p>
        </div>

        <div class="metric">
            <h3>ğŸ† è´¨é‡é—¨æ€§èƒ½</h3>
            <ul>
    """

    for gate_name, performance in trends.get('gate_performance', {}).items():
        html_content += f"<li>{gate_name}: {performance['average_score']:.1f}åˆ† ({performance['executions']}æ¬¡æ‰§è¡Œ)</li>"

    html_content += """
            </ul>
        </div>
    </div>

    <div class="chart">
        <h3>ğŸ“ˆ æœ€è¿‘æ‰§è¡Œå†å²</h3>
    """

    for entry in history[-10:]:  # æœ€è¿‘10æ¬¡æ‰§è¡Œ
        timestamp = entry['timestamp'][:19].replace('T', ' ')
        summary = entry['summary']
        status_class = 'success' if summary['failed'] == 0 else 'violation'

        html_content += f"""
        <div class="{status_class}">
            <strong>{timestamp}</strong> -
            é€šè¿‡: {summary['passed']}, å¤±è´¥: {summary['failed']},
            å¹³å‡åˆ†æ•°: {summary['average_score']:.1f}
        </div>
        """

    html_content += """
    </div>

    <div class="chart">
        <h3>ğŸ” å¸¸è§è¿è§„ç±»å‹</h3>
        <ul>
    """

    for violation_type, count in trends.get('common_violations', {}).items():
        html_content += f"<li>{violation_type}: {count}æ¬¡</li>"

    html_content += """
        </ul>
    </div>

    <div class="chart">
        <h3>ğŸ’¡ æ”¹è¿›å»ºè®®</h3>
        <ul>
    """

    for suggestion in trends.get('improvement_suggestions', []):
        html_content += f"<li>{suggestion}</li>"

    html_content += """
        </ul>
    </div>

</body>
</html>
    """

    # ä¿å­˜ä»ªè¡¨æ¿
    dashboard_file = Path('.perfect21/quality_dashboard.html')
    dashboard_file.parent.mkdir(exist_ok=True)

    with open(dashboard_file, 'w', encoding='utf-8') as f:
        f.write(html_content)

    print(f"âœ… è´¨é‡ä»ªè¡¨æ¿å·²ç”Ÿæˆ: {dashboard_file}")
    print(f"ğŸŒ åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: file://{dashboard_file.absolute()}")

if __name__ == "__main__":
    asyncio.run(generate_dashboard())
'''

            with open(dashboard_script, 'w', encoding='utf-8') as f:
                f.write(script_content)

            dashboard_script.chmod(0o755)

            return {
                "status": "success",
                "message": "è´¨é‡ä»ªè¡¨æ¿è„šæœ¬å·²åˆ›å»º",
                "script": str(dashboard_script),
                "usage": "è¿è¡Œ python3 scripts/quality_dashboard.py ç”Ÿæˆä»ªè¡¨æ¿"
            }

        except Exception as e:
            return {
                "status": "error",
                "message": f"åˆ›å»ºè´¨é‡ä»ªè¡¨æ¿å¤±è´¥: {str(e)}",
                "error": str(e)
            }

    async def setup_all_integrations(self) -> Dict[str, Any]:
        """è®¾ç½®æ‰€æœ‰CI/CDé›†æˆ"""
        results = {}

        # è®¾ç½®Git hooks
        results["git_hooks"] = await self.setup_pre_commit_hooks()

        # ç”ŸæˆGitHub Actions
        results["github_actions"] = await self.generate_github_actions_workflow()

        # ç”ŸæˆGitLab CI
        results["gitlab_ci"] = await self.generate_gitlab_ci_config()

        # è®¾ç½®æŒç»­ç›‘æ§
        results["monitoring"] = await self.setup_continuous_monitoring()

        # åˆ›å»ºè´¨é‡ä»ªè¡¨æ¿
        results["dashboard"] = await self.create_quality_dashboard()

        # ç»Ÿè®¡æˆåŠŸæ•°é‡
        successful = len([r for r in results.values() if r.get("status") == "success"])
        total = len(results)

        return {
            "status": "success" if successful == total else "partial",
            "message": f"CI/CDé›†æˆå®Œæˆ: {successful}/{total} ä¸ªç»„ä»¶æˆåŠŸ",
            "results": results,
            "next_steps": [
                "1. æäº¤Git hooksåˆ°ç‰ˆæœ¬æ§åˆ¶",
                "2. åœ¨CI/CDå¹³å°ä¸­å¯ç”¨å·¥ä½œæµ",
                "3. é…ç½®cronä»»åŠ¡è¿›è¡ŒæŒç»­ç›‘æ§",
                "4. å®šæœŸæŸ¥çœ‹è´¨é‡ä»ªè¡¨æ¿",
                "5. æ ¹æ®è´¨é‡æŠ¥å‘Šè°ƒæ•´å¼€å‘æµç¨‹"
            ]
        }