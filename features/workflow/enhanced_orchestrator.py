#!/usr/bin/env python3
"""
å¢å¼ºå‹å·¥ä½œæµç¼–æ’å™¨
==================

é›†æˆåé¦ˆå¾ªç¯ç³»ç»Ÿçš„æ ¸å¿ƒç¼–æ’å™¨ï¼Œè§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
1. æµ‹è¯•å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°å®ç°å±‚ä¿®å¤
2. ç¡®ä¿åŒä¸€ä¸ªagentè´Ÿè´£ä¿®å¤è‡ªå·±çš„ä»£ç 
3. æ™ºèƒ½å†³ç­–ä½•æ—¶é‡è¯•ã€å‡çº§æˆ–ä¸­æ­¢
4. ä¸ç°æœ‰è´¨é‡é—¨å’ŒåŒæ­¥ç‚¹ç³»ç»Ÿå®Œå…¨é›†æˆ
"""

import json
import logging
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from dataclasses import dataclass
from enum import Enum

from .feedback_loop_engine import (
    FeedbackLoopEngine, ValidationStage, FeedbackAction,
    FeedbackContext, FeedbackDecision, get_feedback_engine
)
from .engine import WorkflowEngine, WorkflowResult, TaskStatus
from ..quality.quality_gate_engine import QualityGateEngine
from ..quality.sync_manager import SyncPointManager

logger = logging.getLogger("EnhancedOrchestrator")


class WorkflowStage(Enum):
    """å·¥ä½œæµé˜¶æ®µ"""
    ANALYSIS = "analysis"
    IMPLEMENTATION = "implementation"
    TESTING = "testing"
    QUALITY_VALIDATION = "quality_validation"
    INTEGRATION = "integration"
    DEPLOYMENT = "deployment"


@dataclass
class StageResult:
    """é˜¶æ®µæ‰§è¡Œç»“æœ"""
    stage: WorkflowStage
    status: TaskStatus
    agent_results: Dict[str, Any]
    validation_result: Optional[Dict[str, Any]] = None
    feedback_loops: List[str] = None
    retry_count: int = 0

    def __post_init__(self):
        if self.feedback_loops is None:
            self.feedback_loops = []


class EnhancedOrchestrator:
    """å¢å¼ºå‹å·¥ä½œæµç¼–æ’å™¨"""

    def __init__(self, project_root: str):
        self.project_root = project_root
        self.workflow_engine = WorkflowEngine(max_workers=10)
        self.feedback_engine = get_feedback_engine(project_root)
        self.quality_engine = QualityGateEngine(project_root)
        self.sync_manager = SyncPointManager()

        # å·¥ä½œæµçŠ¶æ€è·Ÿè¸ª
        self.active_workflows: Dict[str, Dict[str, Any]] = {}
        self.stage_dependencies: Dict[WorkflowStage, List[WorkflowStage]] = {
            WorkflowStage.TESTING: [WorkflowStage.IMPLEMENTATION],
            WorkflowStage.QUALITY_VALIDATION: [WorkflowStage.TESTING],
            WorkflowStage.INTEGRATION: [WorkflowStage.QUALITY_VALIDATION],
            WorkflowStage.DEPLOYMENT: [WorkflowStage.INTEGRATION]
        }

    def execute_enhanced_workflow(self, workflow_request: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¢å¼ºçš„å·¥ä½œæµï¼ŒåŒ…å«å®Œæ•´çš„åé¦ˆå¾ªç¯

        Args:
            workflow_request: å·¥ä½œæµè¯·æ±‚ï¼ŒåŒ…å«ä»»åŠ¡æè¿°ã€agentåˆ†é…ç­‰

        Returns:
            Dict: å®Œæ•´çš„æ‰§è¡Œç»“æœï¼ŒåŒ…å«æ‰€æœ‰é˜¶æ®µå’Œåé¦ˆå¾ªç¯ä¿¡æ¯
        """
        workflow_id = f"enhanced_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        logger.info(f"å¼€å§‹å¢å¼ºå·¥ä½œæµ: {workflow_id}")

        # åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
        workflow_state = {
            "workflow_id": workflow_id,
            "request": workflow_request,
            "stages": {},
            "current_stage": None,
            "status": "running",
            "start_time": datetime.now(),
            "total_retries": 0,
            "feedback_loops": [],
            "quality_gates_passed": [],
            "sync_points_validated": []
        }

        self.active_workflows[workflow_id] = workflow_state

        try:
            # æ‰§è¡Œå·¥ä½œæµé˜¶æ®µ
            result = self._execute_workflow_stages(workflow_id, workflow_request)
            workflow_state["status"] = "completed"
            workflow_state["end_time"] = datetime.now()

            return result

        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {workflow_id} - {e}")
            workflow_state["status"] = "failed"
            workflow_state["error"] = str(e)
            workflow_state["end_time"] = datetime.now()

            return {
                "workflow_id": workflow_id,
                "status": "failed",
                "error": str(e),
                "partial_results": workflow_state.get("stages", {})
            }

    def _execute_workflow_stages(self, workflow_id: str,
                               workflow_request: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥ä½œæµé˜¶æ®µ"""

        workflow_state = self.active_workflows[workflow_id]
        task_description = workflow_request.get("task_description", "")
        agent_assignments = workflow_request.get("agent_assignments", [])

        # ç¡®å®šæ‰§è¡Œé˜¶æ®µ
        stages_to_execute = self._determine_execution_stages(workflow_request)

        logger.info(f"å·¥ä½œæµ {workflow_id} å°†æ‰§è¡Œ {len(stages_to_execute)} ä¸ªé˜¶æ®µ")

        stage_results = {}

        for stage in stages_to_execute:
            logger.info(f"æ‰§è¡Œé˜¶æ®µ: {stage.value}")
            workflow_state["current_stage"] = stage.value

            try:
                # æ£€æŸ¥ä¾èµ–å…³ç³»
                if not self._check_stage_dependencies(stage, stage_results):
                    raise Exception(f"é˜¶æ®µ {stage.value} çš„ä¾èµ–æ¡ä»¶æœªæ»¡è¶³")

                # æ‰§è¡Œé˜¶æ®µ
                stage_result = self._execute_single_stage(
                    workflow_id, stage, task_description, agent_assignments
                )

                stage_results[stage.value] = stage_result
                workflow_state["stages"][stage.value] = stage_result

                # å¦‚æœé˜¶æ®µå¤±è´¥ä¸”æ— æ³•æ¢å¤ï¼Œåœæ­¢æ‰§è¡Œ
                if stage_result.status == TaskStatus.FAILED and not stage_result.feedback_loops:
                    logger.error(f"é˜¶æ®µ {stage.value} å¤±è´¥ä¸”æ— æ³•æ¢å¤")
                    break

            except Exception as e:
                logger.error(f"é˜¶æ®µ {stage.value} æ‰§è¡Œå¼‚å¸¸: {e}")
                stage_results[stage.value] = StageResult(
                    stage=stage,
                    status=TaskStatus.FAILED,
                    agent_results={"error": str(e)},
                    validation_result={"success": False, "error": str(e)}
                )
                break

        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        return self._generate_workflow_result(workflow_id, stage_results)

    def _execute_single_stage(self, workflow_id: str, stage: WorkflowStage,
                            task_description: str,
                            agent_assignments: List[Dict[str, str]]) -> StageResult:
        """æ‰§è¡Œå•ä¸ªå·¥ä½œæµé˜¶æ®µ"""

        max_stage_retries = 3
        retry_count = 0

        while retry_count < max_stage_retries:
            try:
                # æ ¹æ®é˜¶æ®µç±»å‹é€‰æ‹©æ‰§è¡Œæ–¹å¼
                if stage == WorkflowStage.IMPLEMENTATION:
                    return self._execute_implementation_stage(
                        workflow_id, task_description, agent_assignments, retry_count
                    )
                elif stage == WorkflowStage.TESTING:
                    return self._execute_testing_stage(
                        workflow_id, task_description, agent_assignments, retry_count
                    )
                elif stage == WorkflowStage.QUALITY_VALIDATION:
                    return self._execute_quality_validation_stage(
                        workflow_id, task_description, retry_count
                    )
                else:
                    # å…¶ä»–é˜¶æ®µçš„é»˜è®¤å®ç°
                    return self._execute_default_stage(
                        workflow_id, stage, task_description, agent_assignments, retry_count
                    )

            except Exception as e:
                retry_count += 1
                logger.warning(f"é˜¶æ®µ {stage.value} ç¬¬ {retry_count} æ¬¡é‡è¯•: {e}")

                if retry_count >= max_stage_retries:
                    return StageResult(
                        stage=stage,
                        status=TaskStatus.FAILED,
                        agent_results={"error": str(e)},
                        retry_count=retry_count
                    )

    def _execute_implementation_stage(self, workflow_id: str, task_description: str,
                                    agent_assignments: List[Dict[str, str]],
                                    retry_count: int) -> StageResult:
        """æ‰§è¡Œå®ç°é˜¶æ®µ"""

        logger.info(f"æ‰§è¡Œå®ç°é˜¶æ®µ: {workflow_id}")

        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = []
        for assignment in agent_assignments:
            if assignment.get('stage', 'implementation') == 'implementation':
                tasks.append({
                    'agent_name': assignment.get('agent'),
                    'description': assignment.get('task'),
                    'prompt': assignment.get('prompt')
                })

        if not tasks:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„å®ç°ä»»åŠ¡ï¼Œåˆ›å»ºé»˜è®¤ä»»åŠ¡
            tasks = [{
                'agent_name': 'backend-architect',
                'description': 'å®ç°æ ¸å¿ƒåŠŸèƒ½',
                'prompt': task_description
            }]

        # æ³¨å†Œåé¦ˆå¾ªç¯
        feedback_loops = []
        for i, task in enumerate(tasks):
            feedback_id = self.feedback_engine.register_feedback_loop(
                workflow_id=workflow_id,
                stage=ValidationStage.IMPLEMENTATION,
                agent_name=task['agent_name'],
                task_id=f"impl_task_{i+1}",
                original_prompt=task['prompt']
            )
            feedback_loops.append(feedback_id)

        # æ‰§è¡Œä»»åŠ¡
        workflow_result = self.workflow_engine.execute_parallel_tasks(
            tasks, workflow_id=f"{workflow_id}_implementation"
        )

        # éªŒè¯å®ç°ç»“æœ
        validation_result = self._validate_implementation_result(workflow_result)

        # å¤„ç†éªŒè¯ç»“æœ
        if not validation_result.get("success", False):
            return self._handle_implementation_failure(
                workflow_id, feedback_loops, validation_result, tasks
            )
        else:
            # éªŒè¯æˆåŠŸï¼Œå…³é—­åé¦ˆå¾ªç¯
            for feedback_id in feedback_loops:
                self.feedback_engine.process_validation_success(feedback_id, validation_result)

        return StageResult(
            stage=WorkflowStage.IMPLEMENTATION,
            status=TaskStatus.COMPLETED,
            agent_results={"workflow_result": workflow_result},
            validation_result=validation_result,
            feedback_loops=feedback_loops,
            retry_count=retry_count
        )

    def _execute_testing_stage(self, workflow_id: str, task_description: str,
                             agent_assignments: List[Dict[str, str]],
                             retry_count: int) -> StageResult:
        """æ‰§è¡Œæµ‹è¯•é˜¶æ®µ"""

        logger.info(f"æ‰§è¡Œæµ‹è¯•é˜¶æ®µ: {workflow_id}")

        # è·å–å®ç°é˜¶æ®µçš„ç»“æœä½œä¸ºä¸Šä¸‹æ–‡
        workflow_state = self.active_workflows[workflow_id]
        impl_result = workflow_state.get("stages", {}).get("implementation")

        # å‡†å¤‡æµ‹è¯•ä»»åŠ¡
        test_tasks = []
        for assignment in agent_assignments:
            if assignment.get('stage', 'testing') == 'testing':
                # å¢å¼ºæµ‹è¯•ä»»åŠ¡çš„promptï¼ŒåŒ…å«å®ç°ä¸Šä¸‹æ–‡
                enhanced_prompt = assignment.get('prompt', '')
                if impl_result:
                    enhanced_prompt += f"\n\n## å®ç°é˜¶æ®µç»“æœ:\n{json.dumps(impl_result.agent_results, indent=2, ensure_ascii=False)}"

                test_tasks.append({
                    'agent_name': assignment.get('agent'),
                    'description': assignment.get('task'),
                    'prompt': enhanced_prompt
                })

        if not test_tasks:
            # é»˜è®¤æµ‹è¯•ä»»åŠ¡
            test_tasks = [{
                'agent_name': 'test-engineer',
                'description': 'ç¼–å†™å’Œæ‰§è¡Œæµ‹è¯•',
                'prompt': f"ä¸ºä»¥ä¸‹åŠŸèƒ½ç¼–å†™æµ‹è¯•:\n{task_description}"
            }]

        # æ³¨å†Œåé¦ˆå¾ªç¯
        feedback_loops = []
        for i, task in enumerate(test_tasks):
            feedback_id = self.feedback_engine.register_feedback_loop(
                workflow_id=workflow_id,
                stage=ValidationStage.TESTING,
                agent_name=task['agent_name'],
                task_id=f"test_task_{i+1}",
                original_prompt=task['prompt']
            )
            feedback_loops.append(feedback_id)

        # æ‰§è¡Œæµ‹è¯•ä»»åŠ¡
        workflow_result = self.workflow_engine.execute_parallel_tasks(
            test_tasks, workflow_id=f"{workflow_id}_testing"
        )

        # éªŒè¯æµ‹è¯•ç»“æœ
        validation_result = self._validate_testing_result(workflow_result)

        # å¤„ç†éªŒè¯ç»“æœ
        if not validation_result.get("success", False):
            # æµ‹è¯•å¤±è´¥ - è¿™æ˜¯å…³é”®ç‚¹ï¼
            # éœ€è¦å›é€€åˆ°å®ç°é˜¶æ®µè¿›è¡Œä¿®å¤
            return self._handle_testing_failure(
                workflow_id, feedback_loops, validation_result, workflow_result
            )
        else:
            # æµ‹è¯•æˆåŠŸ
            for feedback_id in feedback_loops:
                self.feedback_engine.process_validation_success(feedback_id, validation_result)

        return StageResult(
            stage=WorkflowStage.TESTING,
            status=TaskStatus.COMPLETED,
            agent_results={"workflow_result": workflow_result},
            validation_result=validation_result,
            feedback_loops=feedback_loops,
            retry_count=retry_count
        )

    def _execute_quality_validation_stage(self, workflow_id: str,
                                        task_description: str,
                                        retry_count: int) -> StageResult:
        """æ‰§è¡Œè´¨é‡éªŒè¯é˜¶æ®µ"""

        logger.info(f"æ‰§è¡Œè´¨é‡éªŒè¯é˜¶æ®µ: {workflow_id}")

        try:
            # è¿è¡Œè´¨é‡é—¨æ£€æŸ¥
            quality_results = await self.quality_engine.run_all_gates("workflow_validation")

            # æ£€æŸ¥è´¨é‡é—¨æ˜¯å¦é€šè¿‡
            overall_result = quality_results.get("overall")
            if overall_result and overall_result.status.value in ["failed", "blocked"]:
                # è´¨é‡é—¨å¤±è´¥ï¼Œéœ€è¦åé¦ˆä¿®å¤
                return self._handle_quality_gate_failure(
                    workflow_id, quality_results, retry_count
                )

            return StageResult(
                stage=WorkflowStage.QUALITY_VALIDATION,
                status=TaskStatus.COMPLETED,
                agent_results={"quality_results": quality_results},
                validation_result={"success": True, "quality_gates": quality_results},
                retry_count=retry_count
            )

        except Exception as e:
            return StageResult(
                stage=WorkflowStage.QUALITY_VALIDATION,
                status=TaskStatus.FAILED,
                agent_results={"error": str(e)},
                validation_result={"success": False, "error": str(e)},
                retry_count=retry_count
            )

    def _execute_default_stage(self, workflow_id: str, stage: WorkflowStage,
                             task_description: str,
                             agent_assignments: List[Dict[str, str]],
                             retry_count: int) -> StageResult:
        """æ‰§è¡Œé»˜è®¤é˜¶æ®µ"""

        # ç®€åŒ–çš„é»˜è®¤å®ç°
        return StageResult(
            stage=stage,
            status=TaskStatus.COMPLETED,
            agent_results={"message": f"é˜¶æ®µ {stage.value} æ‰§è¡Œå®Œæˆ"},
            validation_result={"success": True},
            retry_count=retry_count
        )

    def _handle_implementation_failure(self, workflow_id: str,
                                     feedback_loops: List[str],
                                     validation_result: Dict[str, Any],
                                     original_tasks: List[Dict[str, str]]) -> StageResult:
        """å¤„ç†å®ç°é˜¶æ®µå¤±è´¥"""

        logger.warning(f"å®ç°é˜¶æ®µå¤±è´¥: {workflow_id}")

        retry_decisions = []

        for i, feedback_id in enumerate(feedback_loops):
            # è·å–å¤±è´¥åŸå› 
            failure_reason = validation_result.get("errors", [{}])[i] if i < len(validation_result.get("errors", [])) else {"message": "å®ç°éªŒè¯å¤±è´¥"}

            # å¤„ç†éªŒè¯å¤±è´¥
            decision = self.feedback_engine.process_validation_failure(
                feedback_id=feedback_id,
                validation_result=validation_result,
                failure_reason=failure_reason.get("message", "Unknown implementation error")
            )

            retry_decisions.append(decision)

        # ç”Ÿæˆé‡è¯•æŒ‡ä»¤
        retry_instructions = []
        for decision in retry_decisions:
            if decision.action == FeedbackAction.RETRY:
                instruction = self.feedback_engine.get_retry_instruction(decision)
                retry_instructions.append(instruction)
            elif decision.action == FeedbackAction.ESCALATE:
                instruction = self.feedback_engine.get_escalation_instruction(decision)
                retry_instructions.append(instruction)

        return StageResult(
            stage=WorkflowStage.IMPLEMENTATION,
            status=TaskStatus.FAILED,
            agent_results={
                "validation_result": validation_result,
                "retry_decisions": retry_decisions,
                "retry_instructions": retry_instructions
            },
            validation_result=validation_result,
            feedback_loops=feedback_loops
        )

    def _handle_testing_failure(self, workflow_id: str,
                              feedback_loops: List[str],
                              validation_result: Dict[str, Any],
                              workflow_result: WorkflowResult) -> StageResult:
        """
        å¤„ç†æµ‹è¯•é˜¶æ®µå¤±è´¥ - å…³é”®åŠŸèƒ½

        å½“æµ‹è¯•å¤±è´¥æ—¶ï¼Œéœ€è¦ï¼š
        1. åˆ†æå¤±è´¥åŸå› 
        2. å†³å®šæ˜¯ä¿®å¤æµ‹è¯•è¿˜æ˜¯ä¿®å¤å®ç°
        3. å›é€€åˆ°ç›¸åº”çš„agentè¿›è¡Œä¿®å¤
        """

        logger.warning(f"æµ‹è¯•é˜¶æ®µå¤±è´¥: {workflow_id}")

        # åˆ†ææµ‹è¯•å¤±è´¥çš„ç±»å‹
        test_failures = validation_result.get("test_failures", [])

        retry_decisions = []
        implementation_fixes_needed = []

        for i, feedback_id in enumerate(feedback_loops):
            test_failure = test_failures[i] if i < len(test_failures) else {}
            failure_type = test_failure.get("type", "unknown")
            failure_message = test_failure.get("message", "æµ‹è¯•å¤±è´¥")

            # åˆ¤æ–­æ˜¯æµ‹è¯•é—®é¢˜è¿˜æ˜¯å®ç°é—®é¢˜
            if self._is_implementation_issue(failure_type, failure_message):
                # è¿™æ˜¯å®ç°é—®é¢˜ï¼Œéœ€è¦å›é€€åˆ°å®ç°å±‚ä¿®å¤
                implementation_fixes_needed.append({
                    "test_failure": test_failure,
                    "feedback_id": feedback_id
                })
            else:
                # è¿™æ˜¯æµ‹è¯•æœ¬èº«çš„é—®é¢˜
                decision = self.feedback_engine.process_validation_failure(
                    feedback_id=feedback_id,
                    validation_result=validation_result,
                    failure_reason=failure_message
                )
                retry_decisions.append(decision)

        # å¤„ç†éœ€è¦ä¿®å¤å®ç°çš„æƒ…å†µ
        implementation_fix_instructions = []
        if implementation_fixes_needed:
            implementation_fix_instructions = self._create_implementation_fix_instructions(
                workflow_id, implementation_fixes_needed
            )

        # ç”Ÿæˆé‡è¯•æŒ‡ä»¤
        retry_instructions = []
        for decision in retry_decisions:
            if decision.action == FeedbackAction.RETRY:
                instruction = self.feedback_engine.get_retry_instruction(decision)
                retry_instructions.append(instruction)
            elif decision.action == FeedbackAction.ESCALATE:
                instruction = self.feedback_engine.get_escalation_instruction(decision)
                retry_instructions.append(instruction)

        return StageResult(
            stage=WorkflowStage.TESTING,
            status=TaskStatus.FAILED,
            agent_results={
                "validation_result": validation_result,
                "retry_decisions": retry_decisions,
                "retry_instructions": retry_instructions,
                "implementation_fix_instructions": implementation_fix_instructions,
                "requires_implementation_fix": len(implementation_fixes_needed) > 0
            },
            validation_result=validation_result,
            feedback_loops=feedback_loops
        )

    def _handle_quality_gate_failure(self, workflow_id: str,
                                   quality_results: Dict[str, Any],
                                   retry_count: int) -> StageResult:
        """å¤„ç†è´¨é‡é—¨å¤±è´¥"""

        logger.warning(f"è´¨é‡é—¨å¤±è´¥: {workflow_id}")

        # åˆ†æè´¨é‡é—¨å¤±è´¥çš„åŸå› 
        failed_gates = {
            name: result for name, result in quality_results.items()
            if hasattr(result, 'status') and result.status.value in ["failed", "blocked"]
        }

        # ä¸ºæ¯ä¸ªå¤±è´¥çš„è´¨é‡é—¨åˆ›å»ºä¿®å¤æŒ‡ä»¤
        fix_instructions = []

        for gate_name, gate_result in failed_gates.items():
            # ç¡®å®šè´Ÿè´£ä¿®å¤çš„agent
            responsible_agent = self._get_responsible_agent_for_quality_gate(gate_name)

            # åˆ›å»ºä¿®å¤ä»»åŠ¡
            fix_prompt = self._create_quality_gate_fix_prompt(gate_name, gate_result)

            fix_instruction = f"""
## ğŸ”§ è´¨é‡é—¨ä¿®å¤æŒ‡ä»¤ - {gate_name}

**è´Ÿè´£Agent**: {responsible_agent}
**é—®é¢˜æè¿°**: {gate_result.message}
**ä¿®å¤è¦æ±‚**: {fix_prompt}

### æ‰§è¡ŒæŒ‡ä»¤:
```xml
<function_calls>
  <invoke name="Task">
    <parameter name="subagent_type">{responsible_agent}</parameter>
    <parameter name="prompt">{fix_prompt}</parameter>
  </invoke>
</function_calls>
```

### éªŒè¯è¦æ±‚:
ä¿®å¤å®Œæˆåå¿…é¡»é‡æ–°è¿è¡Œè´¨é‡é—¨: {gate_name}
"""
            fix_instructions.append(fix_instruction)

        return StageResult(
            stage=WorkflowStage.QUALITY_VALIDATION,
            status=TaskStatus.FAILED,
            agent_results={
                "quality_results": quality_results,
                "failed_gates": list(failed_gates.keys()),
                "fix_instructions": fix_instructions
            },
            validation_result={"success": False, "quality_gates": quality_results},
            retry_count=retry_count
        )

    def _is_implementation_issue(self, failure_type: str, failure_message: str) -> bool:
        """åˆ¤æ–­æµ‹è¯•å¤±è´¥æ˜¯å¦ä¸ºå®ç°é—®é¢˜"""

        # æ˜ç¡®çš„å®ç°é—®é¢˜æŒ‡æ ‡
        implementation_indicators = [
            "assertion_error",
            "logic_error",
            "return_value_error",
            "behavior_mismatch",
            "expected_vs_actual",
            "function_not_working",
            "incorrect_result"
        ]

        # æµ‹è¯•è‡ªèº«é—®é¢˜æŒ‡æ ‡
        test_indicators = [
            "test_setup_error",
            "test_framework_error",
            "invalid_test_case",
            "test_configuration_error",
            "mock_error"
        ]

        failure_lower = failure_message.lower()

        # æ£€æŸ¥æ˜¯å¦ä¸ºå®ç°é—®é¢˜
        for indicator in implementation_indicators:
            if indicator in failure_type.lower() or indicator in failure_lower:
                return True

        # æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•é—®é¢˜
        for indicator in test_indicators:
            if indicator in failure_type.lower() or indicator in failure_lower:
                return False

        # é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœåŒ…å«"expected"å’Œ"actual"ï¼Œé€šå¸¸æ˜¯å®ç°é—®é¢˜
        if "expected" in failure_lower and "actual" in failure_lower:
            return True

        # å…¶ä»–æƒ…å†µé»˜è®¤ä¸ºæµ‹è¯•é—®é¢˜
        return False

    def _create_implementation_fix_instructions(self, workflow_id: str,
                                              implementation_fixes: List[Dict[str, Any]]) -> List[str]:
        """åˆ›å»ºå®ç°ä¿®å¤æŒ‡ä»¤"""

        instructions = []

        # è·å–åŸå§‹å®ç°é˜¶æ®µçš„agentä¿¡æ¯
        workflow_state = self.active_workflows[workflow_id]
        impl_stage = workflow_state.get("stages", {}).get("implementation")

        for fix_needed in implementation_fixes:
            test_failure = fix_needed["test_failure"]

            # ç¡®å®šè´Ÿè´£ä¿®å¤çš„åŸå§‹å®ç°agent
            # è¿™é‡Œåº”è¯¥ä»å®ç°é˜¶æ®µçš„ç»“æœä¸­è·å–çœŸå®çš„agent
            original_agent = "backend-architect"  # é»˜è®¤å€¼ï¼Œå®é™…åº”è¯¥ä»å·¥ä½œæµçŠ¶æ€è·å–

            if impl_stage and "workflow_result" in impl_stage.agent_results:
                workflow_result = impl_stage.agent_results["workflow_result"]
                if hasattr(workflow_result, 'tasks') and workflow_result.tasks:
                    # è·å–ç¬¬ä¸€ä¸ªå®ç°ä»»åŠ¡çš„agentï¼ˆç®€åŒ–å¤„ç†ï¼‰
                    original_agent = workflow_result.tasks[0].agent_name

            fix_prompt = f"""
## ğŸ”´ å®ç°ä¿®å¤è¯·æ±‚ï¼ˆåŸºäºæµ‹è¯•å¤±è´¥ï¼‰

**æµ‹è¯•å¤±è´¥ä¿¡æ¯**:
- ç±»å‹: {test_failure.get('type', 'unknown')}
- æ¶ˆæ¯: {test_failure.get('message', 'æœªçŸ¥é”™è¯¯')}
- è¯¦ç»†ä¿¡æ¯: {json.dumps(test_failure.get('details', {}), indent=2, ensure_ascii=False)}

## ğŸ¯ ä¿®å¤è¦æ±‚

ä½ ä¹‹å‰ç¼–å†™çš„å®ç°ä»£ç å­˜åœ¨é—®é¢˜ï¼Œå¯¼è‡´æµ‹è¯•å¤±è´¥ã€‚è¯·åˆ†ææµ‹è¯•å¤±è´¥çš„åŸå› ï¼Œå¹¶ä¿®æ­£ä½ çš„å®ç°ä»£ç ã€‚

**å…³é”®ç‚¹**:
1. ä»”ç»†åˆ†ææµ‹è¯•æœŸæœ›çš„è¡Œä¸º
2. ä¿®æ­£å®ç°é€»è¾‘ä»¥æ»¡è¶³æµ‹è¯•è¦æ±‚
3. ç¡®ä¿ä¿®å¤ä¸ä¼šç ´åå…¶ä»–åŠŸèƒ½
4. æ·»åŠ å¿…è¦çš„é”™è¯¯å¤„ç†

**éªŒè¯è¦æ±‚**:
ä¿®å¤åçš„ä»£ç å¿…é¡»èƒ½å¤Ÿé€šè¿‡ç›¸å…³æµ‹è¯•ã€‚
"""

            instruction = f"""
## ğŸ”§ å®ç°ä¿®å¤æŒ‡ä»¤

**åŸå§‹è´Ÿè´£Agent**: {original_agent}
**ä¿®å¤åŸå› **: æµ‹è¯•å¤±è´¥åé¦ˆ

### æ‰§è¡ŒæŒ‡ä»¤:
```xml
<function_calls>
  <invoke name="Task">
    <parameter name="subagent_type">{original_agent}</parameter>
    <parameter name="prompt">{fix_prompt}</parameter>
  </invoke>
</function_calls>
```

âš ï¸ **é‡è¦**: ä¿®å¤å®Œæˆåå¿…é¡»é‡æ–°è¿è¡Œæµ‹è¯•éªŒè¯
"""

            instructions.append(instruction)

        return instructions

    def _get_responsible_agent_for_quality_gate(self, gate_name: str) -> str:
        """è·å–è´Ÿè´£ç‰¹å®šè´¨é‡é—¨çš„agent"""

        gate_agent_map = {
            "code_quality": "code-reviewer",
            "security": "security-auditor",
            "performance": "performance-engineer",
            "architecture": "backend-architect",
            "coverage": "test-engineer"
        }

        return gate_agent_map.get(gate_name, "code-reviewer")

    def _create_quality_gate_fix_prompt(self, gate_name: str, gate_result) -> str:
        """åˆ›å»ºè´¨é‡é—¨ä¿®å¤æç¤ºè¯"""

        violations = gate_result.violations if hasattr(gate_result, 'violations') else []
        suggestions = gate_result.suggestions if hasattr(gate_result, 'suggestions') else []

        prompt = f"""
## ğŸ”§ è´¨é‡é—¨ä¿®å¤ä»»åŠ¡ - {gate_name}

**å¤±è´¥åŸå› **: {gate_result.message}
**å½“å‰åˆ†æ•°**: {gate_result.score}/100

### è¿è§„é¡¹ç›®:
"""
        for violation in violations[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªè¿è§„
            prompt += f"- {violation.get('message', str(violation))}\n"

        prompt += "\n### ä¿®å¤å»ºè®®:\n"
        for suggestion in suggestions[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªå»ºè®®
            prompt += f"- {suggestion}\n"

        prompt += f"""

### ä¿®å¤è¦æ±‚:
1. é€é¡¹è§£å†³ä¸Šè¿°è¿è§„é—®é¢˜
2. ç¡®ä¿ä¿®å¤åè´¨é‡é—¨åˆ†æ•° >= 8.0
3. ä¸ç ´åç°æœ‰åŠŸèƒ½
4. éµå¾ªæœ€ä½³å®è·µ

è¯·æä¾›å…·ä½“çš„ä¿®å¤æ–¹æ¡ˆå’Œä»£ç æ”¹è¿›ã€‚
"""

        return prompt

    def _validate_implementation_result(self, workflow_result: WorkflowResult) -> Dict[str, Any]:
        """éªŒè¯å®ç°ç»“æœ"""

        # åŸºç¡€éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡å¤±è´¥
        if workflow_result.failure_count > 0:
            failed_tasks = [
                task for task in workflow_result.tasks
                if task.status == TaskStatus.FAILED
            ]

            return {
                "success": False,
                "errors": [
                    {
                        "task_id": task.task_id,
                        "agent": task.agent_name,
                        "message": task.error or "ä»»åŠ¡æ‰§è¡Œå¤±è´¥"
                    }
                    for task in failed_tasks
                ]
            }

        # æ£€æŸ¥æ‰§è¡Œç»“æœçš„è´¨é‡
        quality_issues = []
        for task in workflow_result.tasks:
            if task.result:
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„è´¨é‡æ£€æŸ¥é€»è¾‘
                # æ¯”å¦‚æ£€æŸ¥ä»£ç è¯­æ³•ã€å¯¼å…¥é”™è¯¯ç­‰
                pass

        if quality_issues:
            return {
                "success": False,
                "errors": quality_issues
            }

        return {
            "success": True,
            "task_count": len(workflow_result.tasks),
            "success_rate": workflow_result.success_count / len(workflow_result.tasks)
        }

    def _validate_testing_result(self, workflow_result: WorkflowResult) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•ç»“æœ"""

        # æ£€æŸ¥æµ‹è¯•ä»»åŠ¡æ˜¯å¦æˆåŠŸæ‰§è¡Œ
        if workflow_result.failure_count > 0:
            failed_tasks = [
                task for task in workflow_result.tasks
                if task.status == TaskStatus.FAILED
            ]

            return {
                "success": False,
                "test_failures": [
                    {
                        "task_id": task.task_id,
                        "agent": task.agent_name,
                        "type": "test_execution_failure",
                        "message": task.error or "æµ‹è¯•æ‰§è¡Œå¤±è´¥",
                        "details": {"task_result": task.result}
                    }
                    for task in failed_tasks
                ]
            }

        # åˆ†ææµ‹è¯•ç»“æœå†…å®¹
        test_failures = []
        for task in workflow_result.tasks:
            if task.result:
                # è¿™é‡Œåº”è¯¥è§£æçœŸå®çš„æµ‹è¯•ç»“æœ
                # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•å¤±è´¥ã€æ–­è¨€é”™è¯¯ç­‰
                result_analysis = self._analyze_test_task_result(task)
                if not result_analysis["success"]:
                    test_failures.extend(result_analysis["failures"])

        if test_failures:
            return {
                "success": False,
                "test_failures": test_failures
            }

        return {
            "success": True,
            "tests_passed": True,
            "task_count": len(workflow_result.tasks)
        }

    def _analyze_test_task_result(self, task) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæµ‹è¯•ä»»åŠ¡çš„ç»“æœ"""

        # è¿™é‡Œåº”è¯¥å®ç°çœŸå®çš„æµ‹è¯•ç»“æœåˆ†æ
        # ç›®å‰æ˜¯ç®€åŒ–çš„ç¤ºä¾‹å®ç°

        if task.result and "instruction" in task.result:
            # å¦‚æœä»»åŠ¡åªæ˜¯ç”Ÿæˆäº†æŒ‡ä»¤è€Œæ²¡æœ‰çœŸå®æ‰§è¡Œï¼Œè®¤ä¸ºæ˜¯æˆåŠŸçš„
            return {"success": True, "failures": []}

        # æ¨¡æ‹Ÿæµ‹è¯•ç»“æœåˆ†æ
        # å®é™…åº”è¯¥è§£æçœŸå®çš„æµ‹è¯•è¾“å‡º
        return {"success": True, "failures": []}

    def _determine_execution_stages(self, workflow_request: Dict[str, Any]) -> List[WorkflowStage]:
        """ç¡®å®šéœ€è¦æ‰§è¡Œçš„å·¥ä½œæµé˜¶æ®µ"""

        # é»˜è®¤çš„å®Œæ•´å·¥ä½œæµé˜¶æ®µ
        default_stages = [
            WorkflowStage.IMPLEMENTATION,
            WorkflowStage.TESTING,
            WorkflowStage.QUALITY_VALIDATION
        ]

        # å¯ä»¥æ ¹æ®è¯·æ±‚ç±»å‹å®šåˆ¶é˜¶æ®µ
        request_type = workflow_request.get("type", "full")

        if request_type == "implementation_only":
            return [WorkflowStage.IMPLEMENTATION]
        elif request_type == "testing_only":
            return [WorkflowStage.TESTING]
        elif request_type == "quality_only":
            return [WorkflowStage.QUALITY_VALIDATION]
        else:
            return default_stages

    def _check_stage_dependencies(self, stage: WorkflowStage,
                                stage_results: Dict[str, StageResult]) -> bool:
        """æ£€æŸ¥é˜¶æ®µä¾èµ–å…³ç³»"""

        dependencies = self.stage_dependencies.get(stage, [])

        for dep_stage in dependencies:
            if dep_stage.value not in stage_results:
                return False

            dep_result = stage_results[dep_stage.value]
            if dep_result.status != TaskStatus.COMPLETED:
                return False

        return True

    def _generate_workflow_result(self, workflow_id: str,
                                stage_results: Dict[str, StageResult]) -> Dict[str, Any]:
        """ç”Ÿæˆå·¥ä½œæµç»“æœ"""

        workflow_state = self.active_workflows[workflow_id]

        # è®¡ç®—æ€»ä½“çŠ¶æ€
        overall_status = "completed"
        failed_stages = []

        for stage_name, stage_result in stage_results.items():
            if stage_result.status == TaskStatus.FAILED:
                overall_status = "failed"
                failed_stages.append(stage_name)

        # æ”¶é›†æ‰€æœ‰åé¦ˆå¾ªç¯ä¿¡æ¯
        all_feedback_loops = []
        all_retry_instructions = []

        for stage_result in stage_results.values():
            if stage_result.feedback_loops:
                all_feedback_loops.extend(stage_result.feedback_loops)

            if hasattr(stage_result, 'agent_results') and stage_result.agent_results:
                retry_instructions = stage_result.agent_results.get("retry_instructions", [])
                implementation_fixes = stage_result.agent_results.get("implementation_fix_instructions", [])
                all_retry_instructions.extend(retry_instructions)
                all_retry_instructions.extend(implementation_fixes)

        # è·å–åé¦ˆå¾ªç¯çŠ¶æ€
        feedback_status = self.feedback_engine.get_workflow_feedback_status(workflow_id)

        execution_time = (datetime.now() - workflow_state["start_time"]).total_seconds()

        result = {
            "workflow_id": workflow_id,
            "status": overall_status,
            "execution_time": execution_time,
            "stages": {
                name: {
                    "stage": result.stage.value,
                    "status": result.status.value,
                    "retry_count": result.retry_count,
                    "validation_result": result.validation_result,
                    "feedback_loops": result.feedback_loops
                }
                for name, result in stage_results.items()
            },
            "feedback_summary": {
                "total_feedback_loops": len(all_feedback_loops),
                "active_loops": feedback_status.get("active_feedback_loops", 0),
                "total_retries": feedback_status.get("total_retries", 0),
                "success_rate": feedback_status.get("success_rate", 0)
            },
            "retry_instructions": all_retry_instructions,
            "failed_stages": failed_stages,
            "requires_manual_intervention": len(all_retry_instructions) > 0
        }

        # å¦‚æœæœ‰é‡è¯•æŒ‡ä»¤ï¼Œæ·»åŠ æ‰§è¡ŒæŒ‡å¯¼
        if all_retry_instructions:
            result["next_steps"] = {
                "action": "execute_retry_instructions",
                "message": f"æ£€æµ‹åˆ° {len(all_retry_instructions)} ä¸ªä¿®å¤æŒ‡ä»¤ï¼Œè¯·æŒ‰ç…§æŒ‡ä»¤è¿›è¡Œä¿®å¤",
                "instructions": all_retry_instructions
            }

        return result

    def get_workflow_status(self, workflow_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""

        if workflow_id not in self.active_workflows:
            return None

        workflow_state = self.active_workflows[workflow_id]
        feedback_status = self.feedback_engine.get_workflow_feedback_status(workflow_id)

        return {
            "workflow_id": workflow_id,
            "status": workflow_state["status"],
            "current_stage": workflow_state.get("current_stage"),
            "stages": workflow_state.get("stages", {}),
            "feedback_loops": feedback_status,
            "total_retries": workflow_state.get("total_retries", 0)
        }


# å…¨å±€å®ä¾‹
_enhanced_orchestrator = None

def get_enhanced_orchestrator(project_root: str = "/home/xx/dev/Perfect21") -> EnhancedOrchestrator:
    """è·å–å…¨å±€å¢å¼ºç¼–æ’å™¨å®ä¾‹"""
    global _enhanced_orchestrator
    if _enhanced_orchestrator is None:
        _enhanced_orchestrator = EnhancedOrchestrator(project_root)
    return _enhanced_orchestrator