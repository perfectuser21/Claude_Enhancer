#!/usr/bin/env python3
"""
å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œå™¨ - æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬
ä½¿ç”¨å¼‚æ­¥æ“ä½œã€è¿æ¥æ± ã€æ‰¹é‡å¤„ç†æå‡Perfect21æ€§èƒ½
"""

import asyncio
import logging
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass, asdict
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import aiofiles
import weakref
from functools import wraps

from .smart_decomposer import TaskAnalysis, AgentTask
from .parallel_manager import ParallelManager, ExecutionResult, ParallelExecutionSummary

logger = logging.getLogger("AsyncParallelExecutor")


class ExecutionMode(Enum):
    """æ‰§è¡Œæ¨¡å¼"""
    SEQUENTIAL = "sequential"      # é¡ºåºæ‰§è¡Œ
    PARALLEL = "parallel"          # å¹¶è¡Œæ‰§è¡Œ
    PIPELINE = "pipeline"          # æµæ°´çº¿æ‰§è¡Œ
    ADAPTIVE = "adaptive"          # è‡ªé€‚åº”æ‰§è¡Œ


@dataclass
class AsyncExecutionConfig:
    """å¼‚æ­¥æ‰§è¡Œé…ç½®"""
    max_concurrent_tasks: int = 8
    task_timeout: int = 300  # 5åˆ†é’Ÿ
    batch_size: int = 4
    retry_count: int = 3
    circuit_breaker_threshold: int = 5
    connection_pool_size: int = 10
    prefetch_enabled: bool = True
    resource_monitoring: bool = True


@dataclass
class ResourceMetrics:
    """èµ„æºæŒ‡æ ‡"""
    cpu_usage: float
    memory_usage: float
    active_tasks: int
    queue_size: int
    response_time: float
    error_rate: float
    timestamp: datetime


class CircuitBreaker:
    """ç†”æ–­å™¨"""

    def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN

    def call(self, func: Callable):
        """åŒ…è£…å‡½æ•°è°ƒç”¨"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            if self.state == 'OPEN':
                if time.time() - self.last_failure_time > self.recovery_timeout:
                    self.state = 'HALF_OPEN'
                else:
                    raise Exception("Circuit breaker is OPEN")

            try:
                result = await func(*args, **kwargs)
                if self.state == 'HALF_OPEN':
                    self.state = 'CLOSED'
                    self.failure_count = 0
                return result
            except Exception as e:
                self.failure_count += 1
                self.last_failure_time = time.time()

                if self.failure_count >= self.failure_threshold:
                    self.state = 'OPEN'

                raise e

        return wrapper


class AsyncTaskQueue:
    """å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—"""

    def __init__(self, max_size: int = 1000):
        self.queue = asyncio.Queue(maxsize=max_size)
        self.priority_queue = asyncio.PriorityQueue(maxsize=max_size)
        self.processing = set()
        self.completed = {}
        self.failed = {}

    async def put(self, task: AgentTask, priority: int = 5):
        """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        await self.priority_queue.put((priority, time.time(), task))

    async def get(self) -> Tuple[int, float, AgentTask]:
        """è·å–ä»»åŠ¡"""
        return await self.priority_queue.get()

    def mark_processing(self, task_id: str):
        """æ ‡è®°ä»»åŠ¡ä¸ºå¤„ç†ä¸­"""
        self.processing.add(task_id)

    def mark_completed(self, task_id: str, result: Any):
        """æ ‡è®°ä»»åŠ¡å®Œæˆ"""
        self.processing.discard(task_id)
        self.completed[task_id] = result

    def mark_failed(self, task_id: str, error: Exception):
        """æ ‡è®°ä»»åŠ¡å¤±è´¥"""
        self.processing.discard(task_id)
        self.failed[task_id] = error

    @property
    def size(self) -> int:
        """é˜Ÿåˆ—å¤§å°"""
        return self.priority_queue.qsize()

    @property
    def stats(self) -> Dict[str, int]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'queue_size': self.size,
            'processing': len(self.processing),
            'completed': len(self.completed),
            'failed': len(self.failed)
        }


class AsyncConnectionPool:
    """å¼‚æ­¥è¿æ¥æ± """

    def __init__(self, max_connections: int = 10):
        self.max_connections = max_connections
        self.pool = asyncio.Queue(maxsize=max_connections)
        self.active_connections = 0
        self.total_connections = 0
        self._lock = asyncio.Lock()

        # é¢„åˆ›å»ºè¿æ¥
        asyncio.create_task(self._populate_pool())

    async def _populate_pool(self):
        """é¢„å¡«å……è¿æ¥æ± """
        for _ in range(self.max_connections):
            connection = await self._create_connection()
            await self.pool.put(connection)

    async def _create_connection(self) -> Dict[str, Any]:
        """åˆ›å»ºæ–°è¿æ¥"""
        self.total_connections += 1
        return {
            'id': self.total_connections,
            'created_at': datetime.now(),
            'executor': ThreadPoolExecutor(max_workers=2, thread_name_prefix=f"conn-{self.total_connections}"),
            'process_executor': ProcessPoolExecutor(max_workers=1)
        }

    async def acquire(self) -> Dict[str, Any]:
        """è·å–è¿æ¥"""
        async with self._lock:
            self.active_connections += 1

        try:
            # ç­‰å¾…å¯ç”¨è¿æ¥ï¼Œæœ€å¤šç­‰å¾…10ç§’
            connection = await asyncio.wait_for(self.pool.get(), timeout=10.0)
            return connection
        except asyncio.TimeoutError:
            # å¦‚æœæ²¡æœ‰å¯ç”¨è¿æ¥ï¼Œåˆ›å»ºæ–°çš„ä¸´æ—¶è¿æ¥
            logger.warning("è¿æ¥æ± è€—å°½ï¼Œåˆ›å»ºä¸´æ—¶è¿æ¥")
            return await self._create_connection()

    async def release(self, connection: Dict[str, Any]):
        """é‡Šæ”¾è¿æ¥"""
        async with self._lock:
            self.active_connections -= 1

        try:
            # å¦‚æœé˜Ÿåˆ—æœªæ»¡ï¼Œæ”¾å›è¿æ¥æ± 
            self.pool.put_nowait(connection)
        except asyncio.QueueFull:
            # é˜Ÿåˆ—å·²æ»¡ï¼Œå…³é—­è¿æ¥
            await self._close_connection(connection)

    async def _close_connection(self, connection: Dict[str, Any]):
        """å…³é—­è¿æ¥"""
        try:
            connection['executor'].shutdown(wait=False)
            connection['process_executor'].shutdown(wait=False)
        except Exception as e:
            logger.error(f"å…³é—­è¿æ¥å¤±è´¥: {e}")

    async def close_all(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        while not self.pool.empty():
            try:
                connection = self.pool.get_nowait()
                await self._close_connection(connection)
            except asyncio.QueueEmpty:
                break

    @property
    def stats(self) -> Dict[str, Any]:
        """è·å–è¿æ¥æ± ç»Ÿè®¡"""
        return {
            'max_connections': self.max_connections,
            'active_connections': self.active_connections,
            'available_connections': self.pool.qsize(),
            'total_created': self.total_connections
        }


class AsyncPerformanceMonitor:
    """å¼‚æ­¥æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self, monitoring_interval: float = 1.0):
        self.monitoring_interval = monitoring_interval
        self.metrics_history: List[ResourceMetrics] = []
        self.max_history_size = 1000
        self._monitoring_task = None
        self._stop_event = asyncio.Event()

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self._monitoring_task is None or self._monitoring_task.done():
            self._stop_event.clear()
            self._monitoring_task = asyncio.create_task(self._monitor_loop())

    async def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while not self._stop_event.is_set():
            try:
                metrics = await self._collect_metrics()
                self.metrics_history.append(metrics)

                # é™åˆ¶å†å²è®°å½•å¤§å°
                if len(self.metrics_history) > self.max_history_size:
                    self.metrics_history = self.metrics_history[-self.max_history_size:]

                await asyncio.sleep(self.monitoring_interval)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æ€§èƒ½ç›‘æ§é”™è¯¯: {e}")

    async def _collect_metrics(self) -> ResourceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        try:
            import psutil
            cpu_usage = psutil.cpu_percent(interval=None)
            memory_usage = psutil.virtual_memory().percent
        except ImportError:
            cpu_usage = 0.0
            memory_usage = 0.0

        return ResourceMetrics(
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            active_tasks=len(asyncio.all_tasks()),
            queue_size=0,  # ç”±è°ƒç”¨è€…è®¾ç½®
            response_time=0.0,  # ç”±è°ƒç”¨è€…è®¾ç½®
            error_rate=0.0,  # ç”±è°ƒç”¨è€…è®¾ç½®
            timestamp=datetime.now()
        )

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self._stop_event.set()
        if self._monitoring_task and not self._monitoring_task.done():
            self._monitoring_task.cancel()

    def get_latest_metrics(self) -> Optional[ResourceMetrics]:
        """è·å–æœ€æ–°æŒ‡æ ‡"""
        return self.metrics_history[-1] if self.metrics_history else None

    def get_average_metrics(self, window_size: int = 60) -> Optional[ResourceMetrics]:
        """è·å–å¹³å‡æŒ‡æ ‡"""
        if not self.metrics_history:
            return None

        recent_metrics = self.metrics_history[-window_size:]
        if not recent_metrics:
            return None

        avg_cpu = sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics)
        avg_memory = sum(m.memory_usage for m in recent_metrics) / len(recent_metrics)
        avg_response_time = sum(m.response_time for m in recent_metrics) / len(recent_metrics)

        return ResourceMetrics(
            cpu_usage=avg_cpu,
            memory_usage=avg_memory,
            active_tasks=recent_metrics[-1].active_tasks,
            queue_size=recent_metrics[-1].queue_size,
            response_time=avg_response_time,
            error_rate=sum(m.error_rate for m in recent_metrics) / len(recent_metrics),
            timestamp=datetime.now()
        )


class AsyncParallelExecutor:
    """å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œå™¨"""

    def __init__(self, config: AsyncExecutionConfig = None):
        self.config = config or AsyncExecutionConfig()
        self.task_queue = AsyncTaskQueue()
        self.connection_pool = AsyncConnectionPool(self.config.connection_pool_size)
        self.performance_monitor = AsyncPerformanceMonitor()
        self.circuit_breaker = CircuitBreaker(self.config.circuit_breaker_threshold)

        # æ‰§è¡Œç»Ÿè®¡
        self.execution_stats = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'total_execution_time': 0.0,
            'average_response_time': 0.0,
            'throughput': 0.0,
            'error_rate': 0.0
        }

        # æ‰§è¡Œæ—¥å¿—
        self.execution_log = []

        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        self.performance_monitor.start_monitoring()

    async def execute_parallel_task(self, task_description: str, analysis: TaskAnalysis) -> Dict[str, Any]:
        """
        å¼‚æ­¥æ‰§è¡Œå¹¶è¡Œä»»åŠ¡

        Args:
            task_description: ä»»åŠ¡æè¿°
            analysis: ä»»åŠ¡åˆ†æç»“æœ

        Returns:
            æ‰§è¡Œç»“æœ
        """
        logger.info(f"å¼€å§‹å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œ: {task_description}")
        start_time = time.time()

        try:
            # æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’
            await self._display_execution_plan_async(analysis)

            # é€‰æ‹©æ‰§è¡Œæ¨¡å¼
            execution_mode = await self._determine_execution_mode(analysis)

            # æ ¹æ®æ¨¡å¼æ‰§è¡Œä»»åŠ¡
            if execution_mode == ExecutionMode.PARALLEL:
                results = await self._execute_parallel_mode(analysis)
            elif execution_mode == ExecutionMode.PIPELINE:
                results = await self._execute_pipeline_mode(analysis)
            elif execution_mode == ExecutionMode.ADAPTIVE:
                results = await self._execute_adaptive_mode(analysis)
            else:
                results = await self._execute_sequential_mode(analysis)

            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            execution_time = time.time() - start_time

            # æ›´æ–°ç»Ÿè®¡
            await self._update_execution_stats(execution_time, results)

            # åˆ›å»ºæ‰§è¡Œè®°å½•
            execution_record = {
                "task_description": task_description,
                "timestamp": datetime.now().isoformat(),
                "execution_mode": execution_mode.value,
                "execution_time": execution_time,
                "results": results,
                "stats": self.execution_stats.copy()
            }

            self.execution_log.append(execution_record)

            return {
                "success": True,
                "execution_mode": execution_mode.value,
                "execution_time": execution_time,
                "results": results,
                "performance_metrics": await self._get_performance_summary()
            }

        except Exception as e:
            logger.error(f"å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "execution_time": time.time() - start_time,
                "performance_metrics": await self._get_performance_summary()
            }

    async def _display_execution_plan_async(self, analysis: TaskAnalysis):
        """å¼‚æ­¥æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’"""
        plan_text = f"""
ğŸš€ Perfect21 å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œè®¡åˆ’
{"=" * 60}
ğŸ“‹ åŸå§‹ä»»åŠ¡: {analysis.original_task}
ğŸ¯ é¡¹ç›®ç±»å‹: {analysis.project_type}
ğŸ“Š å¤æ‚åº¦ç­‰çº§: {analysis.complexity.value}
âš¡ æ‰§è¡Œæ¨¡å¼: å¼‚æ­¥å¹¶è¡Œä¼˜åŒ–
â±ï¸ é¢„ä¼°æ€»æ—¶é—´: {analysis.estimated_total_time}åˆ†é’Ÿ
ğŸ¤– æ¶‰åŠagents: {len(analysis.agent_tasks)}ä¸ª
{"=" * 60}

ğŸ‘¥ Agentæ‰§è¡Œæ¸…å•:
"""

        for i, task in enumerate(analysis.agent_tasks, 1):
            priority_emoji = "ğŸ”¥" if task.priority <= 2 else "ğŸ“‹"
            plan_text += f"""  {priority_emoji} {i}. @{task.agent_name}
      ä»»åŠ¡: {task.task_description}
      é¢„ä¼°: {task.estimated_time}åˆ†é’Ÿ
      ä¼˜å…ˆçº§: P{task.priority}
"""
            if task.dependencies:
                deps = ", ".join([f"@{dep}" for dep in task.dependencies])
                plan_text += f"      ä¾èµ–: {deps}\n"

        plan_text += f"""
âš¡ **æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§**:
- å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œï¼Œé¿å…é˜»å¡
- æ™ºèƒ½ä»»åŠ¡é˜Ÿåˆ—å’Œä¼˜å…ˆçº§è°ƒåº¦
- è¿æ¥æ± å¤ç”¨ï¼Œå‡å°‘å¼€é”€
- ç†”æ–­å™¨ä¿æŠ¤ï¼Œæé«˜ç¨³å®šæ€§
- å®æ—¶æ€§èƒ½ç›‘æ§å’Œè‡ªé€‚åº”è°ƒæ•´
{"=" * 60}
"""

        # å¼‚æ­¥å†™å…¥æ—¥å¿—ï¼ˆå¦‚æœéœ€è¦ï¼‰
        logger.info(plan_text)
        print(plan_text)

    async def _determine_execution_mode(self, analysis: TaskAnalysis) -> ExecutionMode:
        """ç¡®å®šæ‰§è¡Œæ¨¡å¼"""
        # è·å–å½“å‰ç³»ç»Ÿèµ„æºçŠ¶æ€
        metrics = self.performance_monitor.get_latest_metrics()

        # æ ¹æ®ä»»åŠ¡å¤æ‚åº¦å’Œç³»ç»Ÿèµ„æºå†³å®šæ‰§è¡Œæ¨¡å¼
        if len(analysis.agent_tasks) <= 2:
            return ExecutionMode.SEQUENTIAL

        if metrics and metrics.cpu_usage > 80:
            # CPUä½¿ç”¨ç‡é«˜ï¼Œä½¿ç”¨æµæ°´çº¿æ¨¡å¼
            return ExecutionMode.PIPELINE

        if len(analysis.agent_tasks) >= 6:
            # å¤§é‡ä»»åŠ¡ï¼Œä½¿ç”¨è‡ªé€‚åº”æ¨¡å¼
            return ExecutionMode.ADAPTIVE

        # é»˜è®¤å¹¶è¡Œæ¨¡å¼
        return ExecutionMode.PARALLEL

    async def _execute_parallel_mode(self, analysis: TaskAnalysis) -> List[Dict[str, Any]]:
        """å¹¶è¡Œæ‰§è¡Œæ¨¡å¼"""
        logger.info(f"ä½¿ç”¨å¹¶è¡Œæ‰§è¡Œæ¨¡å¼å¤„ç† {len(analysis.agent_tasks)} ä¸ªä»»åŠ¡")

        # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(self.config.max_concurrent_tasks)

        # åŒ…è£…ä»»åŠ¡æ‰§è¡Œ
        async def execute_with_semaphore(task: AgentTask):
            async with semaphore:
                return await self._execute_single_task(task)

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        tasks = [execute_with_semaphore(task) for task in analysis.agent_tasks]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "task_id": analysis.agent_tasks[i].agent_name,
                    "success": False,
                    "error": str(result),
                    "execution_time": 0.0
                })
            else:
                processed_results.append(result)

        return processed_results

    async def _execute_pipeline_mode(self, analysis: TaskAnalysis) -> List[Dict[str, Any]]:
        """æµæ°´çº¿æ‰§è¡Œæ¨¡å¼"""
        logger.info(f"ä½¿ç”¨æµæ°´çº¿æ‰§è¡Œæ¨¡å¼å¤„ç† {len(analysis.agent_tasks)} ä¸ªä»»åŠ¡")

        # æŒ‰ä¾èµ–å…³ç³»æ’åºä»»åŠ¡
        sorted_tasks = self._sort_tasks_by_dependencies(analysis.agent_tasks)

        # åˆ†æ‰¹æ‰§è¡Œ
        results = []
        batch_size = self.config.batch_size

        for i in range(0, len(sorted_tasks), batch_size):
            batch = sorted_tasks[i:i + batch_size]
            logger.info(f"æ‰§è¡Œæ‰¹æ¬¡ {i//batch_size + 1}: {len(batch)} ä¸ªä»»åŠ¡")

            # å¹¶è¡Œæ‰§è¡Œæ‰¹æ¬¡å†…çš„ä»»åŠ¡
            batch_tasks = [self._execute_single_task(task) for task in batch]
            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)

            # å¤„ç†æ‰¹æ¬¡ç»“æœ
            for j, result in enumerate(batch_results):
                if isinstance(result, Exception):
                    results.append({
                        "task_id": batch[j].agent_name,
                        "success": False,
                        "error": str(result),
                        "execution_time": 0.0
                    })
                else:
                    results.append(result)

            # çŸ­æš‚ä¼‘æ¯ï¼Œé˜²æ­¢ç³»ç»Ÿè¿‡è½½
            await asyncio.sleep(0.1)

        return results

    async def _execute_adaptive_mode(self, analysis: TaskAnalysis) -> List[Dict[str, Any]]:
        """è‡ªé€‚åº”æ‰§è¡Œæ¨¡å¼"""
        logger.info(f"ä½¿ç”¨è‡ªé€‚åº”æ‰§è¡Œæ¨¡å¼å¤„ç† {len(analysis.agent_tasks)} ä¸ªä»»åŠ¡")

        # å°†ä»»åŠ¡æ·»åŠ åˆ°é˜Ÿåˆ—
        for task in analysis.agent_tasks:
            await self.task_queue.put(task, task.priority)

        # åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
        results = []
        workers = []

        # å¯åŠ¨åˆå§‹å·¥ä½œè€…
        initial_workers = min(self.config.max_concurrent_tasks, len(analysis.agent_tasks))
        for i in range(initial_workers):
            worker = asyncio.create_task(self._adaptive_worker(f"worker-{i}"))
            workers.append(worker)

        # ç›‘æ§æ‰§è¡Œè¿›åº¦å¹¶åŠ¨æ€è°ƒæ•´
        while self.task_queue.size > 0 or any(not w.done() for w in workers):
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´å·¥ä½œè€…æ•°é‡
            metrics = self.performance_monitor.get_latest_metrics()
            if metrics:
                if metrics.cpu_usage < 50 and self.task_queue.size > len(workers):
                    # CPUä½¿ç”¨ç‡ä½ä¸”æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œå¢åŠ å·¥ä½œè€…
                    if len(workers) < self.config.max_concurrent_tasks:
                        new_worker = asyncio.create_task(self._adaptive_worker(f"worker-{len(workers)}"))
                        workers.append(new_worker)
                        logger.info(f"å¢åŠ å·¥ä½œè€…ï¼Œå½“å‰å·¥ä½œè€…æ•°: {len(workers)}")

                elif metrics.cpu_usage > 90:
                    # CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå‡å°‘å·¥ä½œè€…ï¼ˆé€šè¿‡å®Œæˆä»»åŠ¡è‡ªç„¶å‡å°‘ï¼‰
                    pass

            await asyncio.sleep(1.0)

        # ç­‰å¾…æ‰€æœ‰å·¥ä½œè€…å®Œæˆ
        await asyncio.gather(*workers, return_exceptions=True)

        # æ”¶é›†ç»“æœ
        results.extend(list(self.task_queue.completed.values()))

        # å¤„ç†å¤±è´¥çš„ä»»åŠ¡
        for task_id, error in self.task_queue.failed.items():
            results.append({
                "task_id": task_id,
                "success": False,
                "error": str(error),
                "execution_time": 0.0
            })

        return results

    async def _adaptive_worker(self, worker_id: str):
        """è‡ªé€‚åº”å·¥ä½œè€…"""
        logger.debug(f"å¯åŠ¨è‡ªé€‚åº”å·¥ä½œè€…: {worker_id}")

        while True:
            try:
                # å°è¯•è·å–ä»»åŠ¡ï¼Œè¶…æ—¶5ç§’
                priority, timestamp, task = await asyncio.wait_for(
                    self.task_queue.get(), timeout=5.0
                )

                task_id = task.agent_name
                self.task_queue.mark_processing(task_id)

                try:
                    # æ‰§è¡Œä»»åŠ¡
                    result = await self._execute_single_task(task)
                    self.task_queue.mark_completed(task_id, result)

                except Exception as e:
                    self.task_queue.mark_failed(task_id, e)
                    logger.error(f"å·¥ä½œè€… {worker_id} æ‰§è¡Œä»»åŠ¡ {task_id} å¤±è´¥: {e}")

            except asyncio.TimeoutError:
                # æ²¡æœ‰æ›´å¤šä»»åŠ¡ï¼Œé€€å‡ºå·¥ä½œè€…
                logger.debug(f"å·¥ä½œè€… {worker_id} è¶…æ—¶é€€å‡º")
                break
            except Exception as e:
                logger.error(f"å·¥ä½œè€… {worker_id} å¼‚å¸¸: {e}")
                break

    async def _execute_sequential_mode(self, analysis: TaskAnalysis) -> List[Dict[str, Any]]:
        """é¡ºåºæ‰§è¡Œæ¨¡å¼"""
        logger.info(f"ä½¿ç”¨é¡ºåºæ‰§è¡Œæ¨¡å¼å¤„ç† {len(analysis.agent_tasks)} ä¸ªä»»åŠ¡")

        results = []
        for task in analysis.agent_tasks:
            try:
                result = await self._execute_single_task(task)
                results.append(result)
            except Exception as e:
                results.append({
                    "task_id": task.agent_name,
                    "success": False,
                    "error": str(e),
                    "execution_time": 0.0
                })

        return results

    @CircuitBreaker(failure_threshold=5)
    async def _execute_single_task(self, task: AgentTask) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡ï¼ˆå¸¦ç†”æ–­å™¨ä¿æŠ¤ï¼‰"""
        start_time = time.time()
        task_id = task.agent_name

        try:
            # è·å–è¿æ¥
            connection = await self.connection_pool.acquire()

            try:
                # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œï¼ˆå®é™…åº”è¯¥è°ƒç”¨ç›¸åº”çš„agentï¼‰
                logger.info(f"æ‰§è¡Œä»»åŠ¡: {task_id} - {task.task_description}")

                # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„agentè°ƒç”¨é€»è¾‘
                # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªå¼‚æ­¥æ“ä½œ
                await asyncio.sleep(min(task.estimated_time * 0.1, 2.0))  # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´

                execution_time = time.time() - start_time

                result = {
                    "task_id": task_id,
                    "agent_name": task.agent_name,
                    "task_description": task.task_description,
                    "success": True,
                    "execution_time": execution_time,
                    "result": f"æ¨¡æ‹Ÿæ‰§è¡Œç»“æœ for {task_id}",
                    "timestamp": datetime.now().isoformat()
                }

                logger.info(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶ {execution_time:.2f}s")
                return result

            finally:
                # é‡Šæ”¾è¿æ¥
                await self.connection_pool.release(connection)

        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {e}")

            return {
                "task_id": task_id,
                "agent_name": task.agent_name,
                "task_description": task.task_description,
                "success": False,
                "execution_time": execution_time,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    def _sort_tasks_by_dependencies(self, tasks: List[AgentTask]) -> List[AgentTask]:
        """æŒ‰ä¾èµ–å…³ç³»æ’åºä»»åŠ¡"""
        # ç®€å•çš„æ‹“æ‰‘æ’åºå®ç°
        sorted_tasks = []
        remaining_tasks = tasks.copy()

        while remaining_tasks:
            # æ‰¾åˆ°æ²¡æœ‰ä¾èµ–æˆ–ä¾èµ–å·²æ»¡è¶³çš„ä»»åŠ¡
            ready_tasks = []
            for task in remaining_tasks:
                if not task.dependencies:
                    ready_tasks.append(task)
                else:
                    completed_agents = {t.agent_name for t in sorted_tasks}
                    if set(task.dependencies).issubset(completed_agents):
                        ready_tasks.append(task)

            if not ready_tasks:
                # å¦‚æœæ²¡æœ‰å°±ç»ªä»»åŠ¡ï¼Œå¯èƒ½å­˜åœ¨å¾ªç¯ä¾èµ–ï¼Œæ·»åŠ å‰©ä½™ä»»åŠ¡
                logger.warning("æ£€æµ‹åˆ°å¯èƒ½çš„å¾ªç¯ä¾èµ–ï¼Œå¼ºåˆ¶æ·»åŠ å‰©ä½™ä»»åŠ¡")
                ready_tasks = remaining_tasks

            # å°†å°±ç»ªä»»åŠ¡æ·»åŠ åˆ°ç»“æœå¹¶ä»å‰©ä½™ä»»åŠ¡ä¸­ç§»é™¤
            for task in ready_tasks:
                sorted_tasks.append(task)
                remaining_tasks.remove(task)

        return sorted_tasks

    async def _update_execution_stats(self, execution_time: float, results: List[Dict[str, Any]]):
        """æ›´æ–°æ‰§è¡Œç»Ÿè®¡"""
        successful_tasks = sum(1 for r in results if r.get('success', False))
        failed_tasks = len(results) - successful_tasks

        self.execution_stats['total_tasks'] += len(results)
        self.execution_stats['completed_tasks'] += successful_tasks
        self.execution_stats['failed_tasks'] += failed_tasks
        self.execution_stats['total_execution_time'] += execution_time

        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        if self.execution_stats['total_tasks'] > 0:
            self.execution_stats['average_response_time'] = (
                self.execution_stats['total_execution_time'] / self.execution_stats['total_tasks']
            )

        # è®¡ç®—ååé‡ï¼ˆä»»åŠ¡/ç§’ï¼‰
        if execution_time > 0:
            self.execution_stats['throughput'] = len(results) / execution_time

        # è®¡ç®—é”™è¯¯ç‡
        if self.execution_stats['total_tasks'] > 0:
            self.execution_stats['error_rate'] = (
                self.execution_stats['failed_tasks'] / self.execution_stats['total_tasks']
            )

    async def _get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ€»ç»“"""
        latest_metrics = self.performance_monitor.get_latest_metrics()
        avg_metrics = self.performance_monitor.get_average_metrics()

        return {
            "execution_stats": self.execution_stats.copy(),
            "current_metrics": asdict(latest_metrics) if latest_metrics else None,
            "average_metrics": asdict(avg_metrics) if avg_metrics else None,
            "connection_pool_stats": self.connection_pool.stats,
            "task_queue_stats": self.task_queue.stats,
            "circuit_breaker_state": self.circuit_breaker.state
        }

    async def get_real_time_status(self) -> Dict[str, Any]:
        """è·å–å®æ—¶çŠ¶æ€"""
        return {
            "timestamp": datetime.now().isoformat(),
            "active_tasks": len(asyncio.all_tasks()),
            "performance_summary": await self._get_performance_summary(),
            "last_execution": self.execution_log[-1] if self.execution_log else None
        }

    async def save_execution_report(self, filename: Optional[str] = None) -> str:
        """ä¿å­˜æ‰§è¡ŒæŠ¥å‘Š"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"async_execution_report_{timestamp}.json"

        report_data = {
            "report_type": "async_parallel_execution",
            "timestamp": datetime.now().isoformat(),
            "execution_stats": self.execution_stats,
            "performance_summary": await self._get_performance_summary(),
            "execution_log": self.execution_log[-10:],  # æœ€è¿‘10æ¬¡æ‰§è¡Œ
            "config": asdict(self.config)
        }

        async with aiofiles.open(filename, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(report_data, indent=2, ensure_ascii=False))

        logger.info(f"å¼‚æ­¥æ‰§è¡ŒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename

    async def optimize_performance(self):
        """æ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        avg_metrics = self.performance_monitor.get_average_metrics()
        if not avg_metrics:
            return

        optimizations = []

        if avg_metrics.cpu_usage > 80:
            optimizations.append("å»ºè®®å‡å°‘å¹¶å‘ä»»åŠ¡æ•°é‡æˆ–ä½¿ç”¨æµæ°´çº¿æ¨¡å¼")

        if avg_metrics.memory_usage > 85:
            optimizations.append("å»ºè®®å‡å°‘ç¼“å­˜å¤§å°æˆ–å¢åŠ å†…å­˜")

        if self.execution_stats['error_rate'] > 0.1:
            optimizations.append("å»ºè®®æ£€æŸ¥ä»»åŠ¡å¤±è´¥åŸå› ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´è¶…æ—¶è®¾ç½®")

        if avg_metrics.response_time > 30:
            optimizations.append("å»ºè®®ä¼˜åŒ–ä»»åŠ¡æ‰§è¡Œé€»è¾‘æˆ–å¢åŠ è¿æ¥æ± å¤§å°")

        return {
            "optimizations": optimizations,
            "current_config": asdict(self.config),
            "recommended_config": self._generate_optimized_config(avg_metrics)
        }

    def _generate_optimized_config(self, metrics: ResourceMetrics) -> AsyncExecutionConfig:
        """ç”Ÿæˆä¼˜åŒ–é…ç½®"""
        optimized_config = AsyncExecutionConfig()

        if metrics.cpu_usage > 80:
            optimized_config.max_concurrent_tasks = max(2, self.config.max_concurrent_tasks - 2)
            optimized_config.batch_size = max(2, self.config.batch_size - 1)

        if metrics.memory_usage > 85:
            optimized_config.connection_pool_size = max(5, self.config.connection_pool_size - 2)

        if self.execution_stats['error_rate'] > 0.1:
            optimized_config.task_timeout = min(600, self.config.task_timeout + 60)
            optimized_config.retry_count = min(5, self.config.retry_count + 1)

        return optimized_config

    async def close(self):
        """å…³é—­å¼‚æ­¥æ‰§è¡Œå™¨"""
        logger.info("å…³é—­å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œå™¨...")

        # åœæ­¢æ€§èƒ½ç›‘æ§
        self.performance_monitor.stop_monitoring()

        # å…³é—­è¿æ¥æ± 
        await self.connection_pool.close_all()

        # å–æ¶ˆæ‰¹é‡å¤„ç†ä»»åŠ¡
        if hasattr(self.task_queue, '_batch_task'):
            self.task_queue._batch_task.cancel()

        logger.info("å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œå™¨å·²å…³é—­")

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.close()


# å…¨å±€å¼‚æ­¥æ‰§è¡Œå™¨å®ä¾‹
_async_parallel_executor: Optional[AsyncParallelExecutor] = None


async def get_async_parallel_executor(config: AsyncExecutionConfig = None) -> AsyncParallelExecutor:
    """è·å–å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œå™¨å®ä¾‹"""
    global _async_parallel_executor
    if _async_parallel_executor is None:
        _async_parallel_executor = AsyncParallelExecutor(config)
    return _async_parallel_executor


async def reset_async_parallel_executor():
    """é‡ç½®å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œå™¨"""
    global _async_parallel_executor
    if _async_parallel_executor:
        await _async_parallel_executor.close()
    _async_parallel_executor = None