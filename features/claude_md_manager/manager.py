#!/usr/bin/env python3
"""
CLAUDE.md æ™ºèƒ½ç®¡ç†å™¨

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è‡ªåŠ¨åˆ¤æ–­å†…å®¹å›ºå®šæ€§ vs åŠ¨æ€æ€§
2. åŠ¨æ€å†…å®¹ç”Ÿå‘½å‘¨æœŸç®¡ç†
3. æ–‡æ¡£å¥åº·åº¦ç›‘æ§å’Œè‡ªåŠ¨æ¸…ç†
4. ç‰ˆæœ¬åŒ–ç®¡ç†æ–‡æ¡£çŠ¶æ€
"""

import os
import re
import json
import hashlib
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Tuple
from pathlib import Path

@dataclass
class ContentMetadata:
    """å†…å®¹å…ƒæ•°æ®"""
    content_hash: str
    last_modified: str
    modification_count: int
    content_type: str  # 'fixed', 'dynamic', 'volatile'
    importance_score: float
    lifecycle_stage: str  # 'active', 'aging', 'stale', 'obsolete'

@dataclass
class DocumentHealth:
    """æ–‡æ¡£å¥åº·åº¦è¯„ä¼°"""
    total_lines: int
    fixed_ratio: float
    dynamic_ratio: float
    volatile_ratio: float
    staleness_score: float
    redundancy_score: float
    health_grade: str  # A, B, C, D, F

class ClaudeMdManager:
    """CLAUDE.md æ™ºèƒ½ç®¡ç†å™¨"""

    def __init__(self, claude_md_path: str = None):
        self.claude_md_path = claude_md_path or "/home/xx/dev/Perfect21/CLAUDE.md"
        self.metadata_path = self.claude_md_path.replace('.md', '_metadata.json')
        self.history_path = self.claude_md_path.replace('.md', '_history.json')
        self.metadata = self._load_metadata()

    def _load_metadata(self) -> Dict[str, ContentMetadata]:
        """åŠ è½½å†…å®¹å…ƒæ•°æ®"""
        if os.path.exists(self.metadata_path):
            with open(self.metadata_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return {k: ContentMetadata(**v) for k, v in data.items()}
        return {}

    def _save_metadata(self):
        """ä¿å­˜å†…å®¹å…ƒæ•°æ®"""
        with open(self.metadata_path, 'w', encoding='utf-8') as f:
            data = {k: asdict(v) for k, v in self.metadata.items()}
            json.dump(data, f, indent=2, ensure_ascii=False)

    def analyze_content_stability(self, content_lines: List[str]) -> Dict[str, str]:
        """åˆ†æå†…å®¹ç¨³å®šæ€§ï¼Œè‡ªåŠ¨åˆ†ç±»å›ºå®š/åŠ¨æ€å†…å®¹"""

        # å›ºå®šå†…å®¹æ ‡è¯†ç¬¦
        fixed_indicators = [
            r'## ğŸ¯ é¡¹ç›®æœ¬è´¨',
            r'### ğŸ”‘ ä¸å˜çš„æ ¸å¿ƒç†å¿µ',
            r'## ğŸš€ åŸºæœ¬ä½¿ç”¨',
            r'## ğŸ—ï¸.*æ¶æ„',
            r'## ğŸ“ æ‰©å±•è§„åˆ™',
            r'core.*ä¸å¯ä¿®æ”¹',
            r'ä¸é‡å¤é€ è½®å­',
            r'æ™ºèƒ½ç¼–æ’å™¨',
        ]

        # åŠ¨æ€å†…å®¹æ ‡è¯†ç¬¦
        dynamic_indicators = [
            r'## ğŸ“Š å½“å‰çŠ¶æ€',
            r'### ğŸš€ ç‰ˆæœ¬ä¿¡æ¯',
            r'### ğŸ”§.*çŠ¶æ€',
            r'å½“å‰ç‰ˆæœ¬.*v\d+\.\d+\.\d+',
            r'æœ€åæ›´æ–°.*\d{4}-\d{2}-\d{2}',
            r'âœ….*æ­£å¸¸',
            r'ğŸ”.*å¼€å‘é‡ç‚¹',
        ]

        # æ˜“å˜å†…å®¹æ ‡è¯†ç¬¦ (ç»å¸¸å˜åŒ–çš„ä¸´æ—¶ä¿¡æ¯)
        volatile_indicators = [
            r'### ğŸ“‹.*æ›´æ–°',
            r'è¿‘æœŸ.*',
            r'å½“å‰.*é‡ç‚¹',
            r'TODO',
            r'æ­£åœ¨.*',
            r'è®¡åˆ’.*',
        ]

        classification = {}

        for i, line in enumerate(content_lines):
            line_key = f"line_{i}"

            # æ£€æŸ¥å›ºå®šå†…å®¹
            if any(re.search(pattern, line, re.IGNORECASE) for pattern in fixed_indicators):
                classification[line_key] = 'fixed'
            # æ£€æŸ¥æ˜“å˜å†…å®¹
            elif any(re.search(pattern, line, re.IGNORECASE) for pattern in volatile_indicators):
                classification[line_key] = 'volatile'
            # æ£€æŸ¥åŠ¨æ€å†…å®¹
            elif any(re.search(pattern, line, re.IGNORECASE) for pattern in dynamic_indicators):
                classification[line_key] = 'dynamic'
            # åŸºäºHTMLæ³¨é‡Šåˆ¤æ–­
            elif '<!-- =====' in line and 'å›ºå®šæ ¸å¿ƒ' in line:
                classification[line_key] = 'fixed'
            elif '<!-- =====' in line and 'åŠ¨æ€çŠ¶æ€' in line:
                classification[line_key] = 'dynamic'
            else:
                # ç»§æ‰¿ä¸Šä¸‹æ–‡ç±»å‹
                prev_type = 'fixed'  # é»˜è®¤ä¸ºå›ºå®š
                for j in range(max(0, i-5), i):
                    prev_key = f"line_{j}"
                    if prev_key in classification:
                        prev_type = classification[prev_key]
                        break
                classification[line_key] = prev_type

        return classification

    def assess_content_lifecycle(self, content_hash: str) -> str:
        """è¯„ä¼°å†…å®¹ç”Ÿå‘½å‘¨æœŸé˜¶æ®µ"""
        if content_hash not in self.metadata:
            return 'active'

        meta = self.metadata[content_hash]
        last_modified = datetime.fromisoformat(meta.last_modified)
        days_since_modified = (datetime.now() - last_modified).days

        # åŸºäºä¿®æ”¹é¢‘ç‡å’Œæ—¶é—´åˆ¤æ–­ç”Ÿå‘½å‘¨æœŸ
        if days_since_modified <= 7:
            return 'active'
        elif days_since_modified <= 30:
            return 'aging'
        elif days_since_modified <= 90:
            return 'stale'
        else:
            return 'obsolete'

    def calculate_document_health(self) -> DocumentHealth:
        """è®¡ç®—æ–‡æ¡£å¥åº·åº¦"""
        if not os.path.exists(self.claude_md_path):
            return DocumentHealth(0, 0, 0, 0, 0, 0, 'F')

        with open(self.claude_md_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        total_lines = len(lines)
        classification = self.analyze_content_stability(lines)

        # è®¡ç®—å„ç±»å‹å†…å®¹æ¯”ä¾‹
        fixed_count = sum(1 for t in classification.values() if t == 'fixed')
        dynamic_count = sum(1 for t in classification.values() if t == 'dynamic')
        volatile_count = sum(1 for t in classification.values() if t == 'volatile')

        fixed_ratio = fixed_count / total_lines if total_lines > 0 else 0
        dynamic_ratio = dynamic_count / total_lines if total_lines > 0 else 0
        volatile_ratio = volatile_count / total_lines if total_lines > 0 else 0

        # è®¡ç®—é™ˆæ—§åº¦åˆ†æ•° (åŠ¨æ€å†…å®¹è¿‡æœŸç¨‹åº¦)
        staleness_score = 0
        if self.metadata:
            stale_count = sum(1 for meta in self.metadata.values()
                            if meta.lifecycle_stage in ['stale', 'obsolete'])
            staleness_score = stale_count / len(self.metadata)

        # è®¡ç®—å†—ä½™åº¦åˆ†æ•° (å†…å®¹é•¿åº¦ vs ä¿¡æ¯å¯†åº¦)
        redundancy_score = min(1.0, total_lines / 100)  # è¶…è¿‡100è¡Œè®¤ä¸ºå¼€å§‹å†—ä½™

        # ç»¼åˆå¥åº·åº¦è¯„çº§
        health_score = (
            fixed_ratio * 0.3 +           # å›ºå®šå†…å®¹æ¯”ä¾‹ (30%)
            (1 - volatile_ratio) * 0.2 +  # æ˜“å˜å†…å®¹å°‘ (20%)
            (1 - staleness_score) * 0.3 + # å†…å®¹æ–°é²œåº¦ (30%)
            (1 - redundancy_score) * 0.2  # ç®€æ´åº¦ (20%)
        )

        if health_score >= 0.9:
            health_grade = 'A'
        elif health_score >= 0.8:
            health_grade = 'B'
        elif health_score >= 0.7:
            health_grade = 'C'
        elif health_score >= 0.6:
            health_grade = 'D'
        else:
            health_grade = 'F'

        return DocumentHealth(
            total_lines=total_lines,
            fixed_ratio=fixed_ratio,
            dynamic_ratio=dynamic_ratio,
            volatile_ratio=volatile_ratio,
            staleness_score=staleness_score,
            redundancy_score=redundancy_score,
            health_grade=health_grade
        )

    def auto_cleanup_stale_content(self) -> List[str]:
        """è‡ªåŠ¨æ¸…ç†é™ˆæ—§å†…å®¹"""
        cleanup_actions = []

        if not os.path.exists(self.claude_md_path):
            return cleanup_actions

        with open(self.claude_md_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        new_lines = []
        removed_sections = []

        for i, line in enumerate(lines):
            line_hash = hashlib.md5(line.encode()).hexdigest()

            # æ£€æŸ¥æ˜¯å¦ä¸ºé™ˆæ—§çš„åŠ¨æ€å†…å®¹
            if line_hash in self.metadata:
                meta = self.metadata[line_hash]
                if meta.lifecycle_stage == 'obsolete' and meta.content_type in ['dynamic', 'volatile']:
                    removed_sections.append(f"è¡Œ {i+1}: {line.strip()}")
                    cleanup_actions.append(f"åˆ é™¤è¿‡æœŸå†…å®¹: {line.strip()[:50]}...")
                    continue

            # æ£€æŸ¥é‡å¤çš„ç‰ˆæœ¬ä¿¡æ¯
            if re.search(r'v\d+\.\d+\.\d+', line) and any(re.search(r'v\d+\.\d+\.\d+', prev) for prev in new_lines[-3:]):
                cleanup_actions.append(f"åˆ é™¤é‡å¤ç‰ˆæœ¬ä¿¡æ¯: {line.strip()}")
                continue

            new_lines.append(line)

        # å¦‚æœæœ‰æ¸…ç†åŠ¨ä½œï¼Œå†™å›æ–‡ä»¶
        if cleanup_actions:
            with open(self.claude_md_path, 'w', encoding='utf-8') as f:
                f.writelines(new_lines)

            # è®°å½•æ¸…ç†å†å²
            self._record_cleanup_history(cleanup_actions)

        return cleanup_actions

    def _record_cleanup_history(self, actions: List[str]):
        """è®°å½•æ¸…ç†å†å²"""
        history = []
        if os.path.exists(self.history_path):
            with open(self.history_path, 'r', encoding='utf-8') as f:
                history = json.load(f)

        history.append({
            'timestamp': datetime.now().isoformat(),
            'actions': actions,
            'type': 'auto_cleanup'
        })

        # åªä¿ç•™æœ€è¿‘30æ¬¡æ¸…ç†è®°å½•
        history = history[-30:]

        with open(self.history_path, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)

    def generate_health_report(self) -> str:
        """ç”Ÿæˆæ–‡æ¡£å¥åº·åº¦æŠ¥å‘Š"""
        health = self.calculate_document_health()

        report = f"""
# CLAUDE.md å¥åº·åº¦æŠ¥å‘Š

## ğŸ“Š æ•´ä½“è¯„çº§: {health.health_grade}

### ğŸ“ˆ å†…å®¹åˆ†å¸ƒ
- å›ºå®šå†…å®¹: {health.fixed_ratio:.1%} ({health.fixed_ratio * health.total_lines:.0f} è¡Œ)
- åŠ¨æ€å†…å®¹: {health.dynamic_ratio:.1%} ({health.dynamic_ratio * health.total_lines:.0f} è¡Œ)
- æ˜“å˜å†…å®¹: {health.volatile_ratio:.1%} ({health.volatile_ratio * health.total_lines:.0f} è¡Œ)

### ğŸ” è´¨é‡æŒ‡æ ‡
- æ€»è¡Œæ•°: {health.total_lines}
- é™ˆæ—§åº¦: {health.staleness_score:.1%}
- å†—ä½™åº¦: {health.redundancy_score:.1%}

### ğŸ’¡ å»ºè®®
"""

        if health.health_grade in ['D', 'F']:
            report += "- âš ï¸  æ–‡æ¡£éœ€è¦ç´§æ€¥æ•´ç†\n"
            report += "- ğŸ§¹ è¿è¡Œè‡ªåŠ¨æ¸…ç†: `claude_md_manager.auto_cleanup_stale_content()`\n"

        if health.volatile_ratio > 0.3:
            report += "- ğŸ“ æ˜“å˜å†…å®¹è¿‡å¤šï¼Œè€ƒè™‘ç§»è‡³å•ç‹¬çš„çŠ¶æ€æ–‡ä»¶\n"

        if health.redundancy_score > 0.8:
            report += "- âœ‚ï¸  æ–‡æ¡£è¿‡é•¿ï¼Œå»ºè®®ç²¾ç®€é‡å¤å†…å®¹\n"

        return report.strip()

def main():
    """CLIå…¥å£"""
    import sys

    manager = ClaudeMdManager()

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python manager.py [health|cleanup|report]")
        return

    command = sys.argv[1]

    if command == 'health':
        health = manager.calculate_document_health()
        print(f"æ–‡æ¡£å¥åº·åº¦: {health.health_grade}")
        print(f"æ€»è¡Œæ•°: {health.total_lines}")
        print(f"å›ºå®šå†…å®¹: {health.fixed_ratio:.1%}")
        print(f"åŠ¨æ€å†…å®¹: {health.dynamic_ratio:.1%}")

    elif command == 'cleanup':
        actions = manager.auto_cleanup_stale_content()
        if actions:
            print(f"å·²æ¸…ç† {len(actions)} é¡¹é™ˆæ—§å†…å®¹:")
            for action in actions:
                print(f"  - {action}")
        else:
            print("æ— éœ€æ¸…ç†")

    elif command == 'report':
        print(manager.generate_health_report())

    else:
        print(f"æœªçŸ¥å‘½ä»¤: {command}")

if __name__ == '__main__':
    main()