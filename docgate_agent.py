#!/usr/bin/env python3
"""
DocGate Agent - æ–‡æ¡£è´¨é‡åˆ†æä¸“å®¶
ä¸“é—¨è´Ÿè´£æ–‡æ¡£è´¨é‡åˆ†æã€è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦ã€ç›¸ä¼¼åº¦æ£€æµ‹å’Œæ”¹è¿›å»ºè®®

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ–‡æ¡£è´¨é‡åˆ†æ - è¯„ä¼°æ–‡æ¡£çš„å®Œæ•´æ€§ã€å¯è¯»æ€§ã€ç»“æ„
2. è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦ - æå–å…³é”®ä¿¡æ¯ç”Ÿæˆç®€æ´æ‘˜è¦
3. ç›¸ä¼¼åº¦æ£€æµ‹ - æ£€æµ‹é‡å¤å†…å®¹å’Œç›¸ä¼¼æ–‡æ¡£
4. æ”¹è¿›å»ºè®® - æä¾›å…·ä½“çš„ä¼˜åŒ–å»ºè®®

ä½œä¸ºç‹¬ç«‹Agentï¼Œä¸è°ƒç”¨å…¶ä»–Agentï¼Œé¿å…åµŒå¥—è°ƒç”¨é—®é¢˜
"""

import os
import re
import json
import hashlib
import difflib
import statistics
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from collections import Counter, defaultdict
from dataclasses import dataclass
import math


@dataclass
class DocumentMetrics:
    """æ–‡æ¡£æŒ‡æ ‡"""
    word_count: int
    sentence_count: int
    paragraph_count: int
    heading_count: int
    link_count: int
    image_count: int
    code_block_count: int
    table_count: int
    readability_score: float
    structure_score: float
    completeness_score: float
    quality_score: float


@dataclass
class SimilarityResult:
    """ç›¸ä¼¼åº¦æ£€æµ‹ç»“æœ"""
    document_a: str
    document_b: str
    similarity_ratio: float
    common_lines: List[str]
    similarity_type: str  # 'identical', 'high', 'medium', 'low'


@dataclass
class QualityIssue:
    """è´¨é‡é—®é¢˜"""
    type: str
    severity: str  # 'critical', 'major', 'minor'
    location: str
    description: str
    suggestion: str


class DocGateAgent:
    """DocGate Agent - æ–‡æ¡£è´¨é‡åˆ†æä¸“å®¶"""

    def __init__(self, project_root: Optional[str] = None):
        self.project_root = project_root or os.environ.get(
            "CLAUDE_PROJECT_DIR", "/home/xx/dev/Claude Enhancer 5.0"
        )
        self.cache_dir = Path(self.project_root) / ".claude" / "docgate_cache"
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # è´¨é‡æ ‡å‡†é…ç½®
        self.quality_standards = {
            'min_word_count': 100,
            'max_word_count': 5000,
            'min_headings': 2,
            'max_sentence_length': 25,
            'min_paragraph_sentences': 2,
            'max_paragraph_sentences': 6,
            'similarity_threshold': 0.8,
            'readability_target': 70  # Flesch Reading Ease target
        }

        # æ–‡æ¡£ç±»å‹æ¨¡å¼
        self.doc_patterns = {
            'readme': r'readme\.md$',
            'api_doc': r'api\.md$|swagger\.md$',
            'changelog': r'changelog\.md$|changes\.md$',
            'install': r'install\.md$|setup\.md$',
            'config': r'config\.md$|configuration\.md$',
            'guide': r'guide\.md$|tutorial\.md$',
            'reference': r'reference\.md$|ref\.md$'
        }

    def analyze_document_quality(self, file_path: str) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡æ¡£çš„è´¨é‡"""
        try:
            if not os.path.exists(file_path):
                return {'error': f'File not found: {file_path}'}

            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # è®¡ç®—åŸºç¡€æŒ‡æ ‡
            metrics = self._calculate_metrics(content)

            # æ£€æµ‹è´¨é‡é—®é¢˜
            issues = self._detect_quality_issues(content, file_path)

            # ç”Ÿæˆæ”¹è¿›å»ºè®®
            suggestions = self._generate_suggestions(metrics, issues)

            # åˆ†ææ–‡æ¡£ç±»å‹
            doc_type = self._detect_document_type(file_path)

            # è®¡ç®—æ€»ä½“è´¨é‡è¯„åˆ†
            overall_score = self._calculate_overall_score(metrics, issues)

            return {
                'file_path': file_path,
                'document_type': doc_type,
                'metrics': metrics.__dict__,
                'overall_score': overall_score,
                'quality_level': self._get_quality_level(overall_score),
                'issues': [issue.__dict__ for issue in issues],
                'suggestions': suggestions,
                'analysis_timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            return {'error': f'Analysis failed: {str(e)}'}

    def generate_document_summary(self, file_path: str, max_sentences: int = 3) -> Dict[str, Any]:
        """ç”Ÿæˆæ–‡æ¡£æ‘˜è¦"""
        try:
            if not os.path.exists(file_path):
                return {'error': f'File not found: {file_path}'}

            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æå–å…³é”®ä¿¡æ¯
            title = self._extract_title(content)
            key_points = self._extract_key_points(content)
            summary_sentences = self._generate_summary_sentences(content, max_sentences)

            # æå–å…ƒæ•°æ®
            metadata = self._extract_metadata(content)

            return {
                'file_path': file_path,
                'title': title,
                'summary': ' '.join(summary_sentences),
                'key_points': key_points,
                'metadata': metadata,
                'word_count': len(content.split()),
                'estimated_reading_time': self._estimate_reading_time(content),
                'summary_timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            return {'error': f'Summary generation failed: {str(e)}'}

    def detect_document_similarity(self, documents: List[str]) -> List[SimilarityResult]:
        """æ£€æµ‹æ–‡æ¡£é—´çš„ç›¸ä¼¼åº¦"""
        results = []

        try:
            # è¯»å–æ‰€æœ‰æ–‡æ¡£å†…å®¹
            doc_contents = {}
            for doc_path in documents:
                if os.path.exists(doc_path):
                    with open(doc_path, 'r', encoding='utf-8') as f:
                        doc_contents[doc_path] = f.read()

            # è®¡ç®—ä¸¤ä¸¤ç›¸ä¼¼åº¦
            doc_list = list(doc_contents.items())
            for i in range(len(doc_list)):
                for j in range(i + 1, len(doc_list)):
                    path_a, content_a = doc_list[i]
                    path_b, content_b = doc_list[j]

                    similarity = self._calculate_similarity(content_a, content_b)
                    # åˆ›å»ºæ–°çš„SimilarityResultå¯¹è±¡
                    result = SimilarityResult(
                        document_a=path_a,
                        document_b=path_b,
                        similarity_ratio=similarity.similarity_ratio,
                        common_lines=similarity.common_lines,
                        similarity_type=similarity.similarity_type
                    )
                    results.append(result)

            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            results.sort(key=lambda x: x.similarity_ratio, reverse=True)

            return results

        except Exception as e:
            return [SimilarityResult(
                document_a='', document_b='', similarity_ratio=0.0,
                common_lines=[], similarity_type=f'error: {str(e)}'
            )]

    def analyze_documentation_coverage(self, project_path: str) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®æ–‡æ¡£è¦†ç›–åº¦"""
        try:
            project_path = Path(project_path)

            # æŸ¥æ‰¾æ‰€æœ‰ä»£ç æ–‡ä»¶å’Œæ–‡æ¡£æ–‡ä»¶
            code_files = self._find_code_files(project_path)
            doc_files = self._find_documentation_files(project_path)

            # åˆ†ææ–‡æ¡£è¦†ç›–åº¦
            coverage_analysis = self._analyze_coverage(code_files, doc_files)

            # æ£€æŸ¥ç¼ºå¤±çš„æ–‡æ¡£
            missing_docs = self._find_missing_documentation(project_path)

            # ç”Ÿæˆæ–‡æ¡£ç»“æ„å›¾
            doc_structure = self._analyze_doc_structure(doc_files)

            return {
                'project_path': str(project_path),
                'total_code_files': len(code_files),
                'total_doc_files': len(doc_files),
                'coverage_percentage': coverage_analysis['coverage_percentage'],
                'coverage_details': coverage_analysis,
                'missing_documentation': missing_docs,
                'documentation_structure': doc_structure,
                'recommendations': self._generate_coverage_recommendations(coverage_analysis, missing_docs),
                'analysis_timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            return {'error': f'Coverage analysis failed: {str(e)}'}

    def batch_analyze_documents(self, file_patterns: List[str]) -> Dict[str, Any]:
        """æ‰¹é‡åˆ†ææ–‡æ¡£"""
        results = {
            'analyzed_files': [],
            'summary_statistics': {},
            'quality_distribution': {},
            'common_issues': [],
            'global_recommendations': []
        }

        try:
            # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
            all_files = []
            for pattern in file_patterns:
                files = self._find_files_by_pattern(pattern)
                all_files.extend(files)

            # å»é‡
            all_files = list(set(all_files))

            # åˆ†ææ¯ä¸ªæ–‡ä»¶
            quality_scores = []
            all_issues = []

            for file_path in all_files:
                analysis = self.analyze_document_quality(file_path)
                if 'error' not in analysis:
                    results['analyzed_files'].append(analysis)
                    quality_scores.append(analysis['overall_score'])
                    all_issues.extend(analysis['issues'])

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            if quality_scores:
                results['summary_statistics'] = {
                    'total_documents': len(quality_scores),
                    'average_quality': statistics.mean(quality_scores),
                    'median_quality': statistics.median(quality_scores),
                    'quality_std_dev': statistics.stdev(quality_scores) if len(quality_scores) > 1 else 0,
                    'highest_quality': max(quality_scores),
                    'lowest_quality': min(quality_scores)
                }

            # åˆ†æè´¨é‡åˆ†å¸ƒ
            results['quality_distribution'] = self._analyze_quality_distribution(quality_scores)

            # åˆ†æå¸¸è§é—®é¢˜
            results['common_issues'] = self._analyze_common_issues(all_issues)

            # ç”Ÿæˆå…¨å±€å»ºè®®
            results['global_recommendations'] = self._generate_global_recommendations(
                results['summary_statistics'], results['common_issues']
            )

            return results

        except Exception as e:
            return {'error': f'Batch analysis failed: {str(e)}'}

    def _calculate_metrics(self, content: str) -> DocumentMetrics:
        """è®¡ç®—æ–‡æ¡£æŒ‡æ ‡"""
        # åŸºç¡€è®¡æ•°
        words = re.findall(r'\b\w+\b', content)
        sentences = re.split(r'[.!?]+', content)
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]

        # Markdownå…ƒç´ è®¡æ•°
        headings = re.findall(r'^#{1,6}\s+', content, re.MULTILINE)
        links = re.findall(r'\[([^\]]+)\]\([^)]+\)', content)
        images = re.findall(r'!\[([^\]]*)\]\([^)]+\)', content)
        code_blocks = re.findall(r'```[^`]*```', content, re.DOTALL)
        tables = re.findall(r'\|.*\|', content)

        # è®¡ç®—å„ç§åˆ†æ•°
        readability_score = self._calculate_readability_score(content)
        structure_score = self._calculate_structure_score(content)
        completeness_score = self._calculate_completeness_score(content)

        # ç»¼åˆè´¨é‡åˆ†æ•°
        quality_score = (readability_score + structure_score + completeness_score) / 3

        return DocumentMetrics(
            word_count=len(words),
            sentence_count=len([s for s in sentences if s.strip()]),
            paragraph_count=len(paragraphs),
            heading_count=len(headings),
            link_count=len(links),
            image_count=len(images),
            code_block_count=len(code_blocks),
            table_count=len(tables),
            readability_score=readability_score,
            structure_score=structure_score,
            completeness_score=completeness_score,
            quality_score=quality_score
        )

    def _calculate_readability_score(self, content: str) -> float:
        """è®¡ç®—å¯è¯»æ€§åˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆFlesch Reading Easeï¼‰"""
        words = re.findall(r'\b\w+\b', content)
        sentences = re.split(r'[.!?]+', content)
        sentences = [s for s in sentences if s.strip()]

        if not sentences or not words:
            return 0.0

        # è®¡ç®—å¹³å‡å¥é•¿å’Œå¹³å‡éŸ³èŠ‚æ•°ï¼ˆç®€åŒ–ï¼‰
        avg_sentence_length = len(words) / len(sentences)
        avg_syllables = sum(self._count_syllables(word) for word in words) / len(words)

        # ç®€åŒ–çš„Fleschå…¬å¼
        score = 206.835 - (1.015 * avg_sentence_length) - (84.6 * avg_syllables)

        # å½’ä¸€åŒ–åˆ°0-100
        return max(0, min(100, score))

    def _count_syllables(self, word: str) -> int:
        """ç®€å•çš„éŸ³èŠ‚è®¡æ•°ï¼ˆè‹±æ–‡ï¼‰"""
        word = word.lower()
        if not word:
            return 0

        vowels = 'aeiouy'
        syllable_count = 0
        prev_was_vowel = False

        for char in word:
            is_vowel = char in vowels
            if is_vowel and not prev_was_vowel:
                syllable_count += 1
            prev_was_vowel = is_vowel

        # å¦‚æœä»¥eç»“å°¾ï¼Œå‡å»1ï¼ˆè‹±æ–‡è§„åˆ™ï¼‰
        if word.endswith('e') and syllable_count > 1:
            syllable_count -= 1

        return max(1, syllable_count)

    def _calculate_structure_score(self, content: str) -> float:
        """è®¡ç®—ç»“æ„åˆ†æ•°"""
        score = 0.0
        max_score = 100.0

        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡é¢˜
        headings = re.findall(r'^#{1,6}\s+', content, re.MULTILINE)
        if headings:
            score += 20

            # æ£€æŸ¥æ ‡é¢˜å±‚æ¬¡ç»“æ„
            heading_levels = [len(h.split()[0]) for h in headings]
            if len(set(heading_levels)) > 1:  # æœ‰ä¸åŒå±‚æ¬¡çš„æ ‡é¢˜
                score += 15

        # æ£€æŸ¥æ®µè½ç»“æ„
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        if len(paragraphs) >= 3:
            score += 15

        # æ£€æŸ¥æ˜¯å¦æœ‰é“¾æ¥
        links = re.findall(r'\[([^\]]+)\]\([^)]+\)', content)
        if links:
            score += 10

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»£ç ç¤ºä¾‹
        code_blocks = re.findall(r'```[^`]*```', content, re.DOTALL)
        if code_blocks:
            score += 15

        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ—è¡¨
        lists = re.findall(r'^[-*]\s+', content, re.MULTILINE)
        if lists:
            score += 10

        # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨æ ¼
        tables = re.findall(r'\|.*\|', content)
        if tables:
            score += 15

        return min(max_score, score)

    def _calculate_completeness_score(self, content: str) -> float:
        """è®¡ç®—å®Œæ•´æ€§åˆ†æ•°"""
        score = 0.0
        max_score = 100.0

        # æ£€æŸ¥æ–‡æ¡£é•¿åº¦
        word_count = len(re.findall(r'\b\w+\b', content))
        if word_count >= self.quality_standards['min_word_count']:
            score += 20

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»‹ç»éƒ¨åˆ†
        intro_patterns = [r'^#{1,2}\s+(ä»‹ç»|Introduction|Overview|ç®€ä»‹)', r'^.*(?:æ˜¯ä»€ä¹ˆ|what is|æ¦‚è¿°)']
        if any(re.search(pattern, content, re.MULTILINE | re.IGNORECASE) for pattern in intro_patterns):
            score += 15

        # æ£€æŸ¥æ˜¯å¦æœ‰ä½¿ç”¨è¯´æ˜
        usage_patterns = [r'^#{1,3}\s+(ä½¿ç”¨|Usage|How to|å®‰è£…|Installation)']
        if any(re.search(pattern, content, re.MULTILINE | re.IGNORECASE) for pattern in usage_patterns):
            score += 15

        # æ£€æŸ¥æ˜¯å¦æœ‰ç¤ºä¾‹
        example_patterns = [r'```', r'^#{1,3}\s+(ç¤ºä¾‹|Example|ä¾‹å­)']
        if any(re.search(pattern, content, re.MULTILINE | re.IGNORECASE) for pattern in example_patterns):
            score += 20

        # æ£€æŸ¥æ˜¯å¦æœ‰è”ç³»ä¿¡æ¯æˆ–è´¡çŒ®æŒ‡å—
        contact_patterns = [r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', r'github\.com', r'è´¡çŒ®|contribute']
        if any(re.search(pattern, content, re.IGNORECASE) for pattern in contact_patterns):
            score += 10

        # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°æ—¥æœŸ
        date_patterns = [r'\d{4}-\d{2}-\d{2}', r'\d{4}/\d{2}/\d{2}', r'æ›´æ–°|updated|ä¿®è®¢|revised']
        if any(re.search(pattern, content, re.IGNORECASE) for pattern in date_patterns):
            score += 10

        # æ£€æŸ¥ç›®å½•æˆ–å¤§çº²
        toc_patterns = [r'^#{1,2}\s+(ç›®å½•|Table of Contents|TOC)', r'^\s*[-*]\s+\[.*\]\(#']
        if any(re.search(pattern, content, re.MULTILINE | re.IGNORECASE) for pattern in toc_patterns):
            score += 10

        return min(max_score, score)

    def _detect_quality_issues(self, content: str, file_path: str) -> List[QualityIssue]:
        """æ£€æµ‹è´¨é‡é—®é¢˜"""
        issues = []

        # æ£€æŸ¥æ–‡æ¡£é•¿åº¦
        word_count = len(re.findall(r'\b\w+\b', content))
        if word_count < self.quality_standards['min_word_count']:
            issues.append(QualityIssue(
                type='length',
                severity='major',
                location='document',
                description=f'æ–‡æ¡£å¤ªçŸ­ï¼Œåªæœ‰{word_count}ä¸ªå•è¯',
                suggestion=f'å»ºè®®è‡³å°‘{self.quality_standards["min_word_count"]}ä¸ªå•è¯'
            ))
        elif word_count > self.quality_standards['max_word_count']:
            issues.append(QualityIssue(
                type='length',
                severity='minor',
                location='document',
                description=f'æ–‡æ¡£è¿‡é•¿ï¼Œæœ‰{word_count}ä¸ªå•è¯',
                suggestion='è€ƒè™‘åˆ†å‰²æˆå¤šä¸ªæ–‡æ¡£æˆ–æ·»åŠ ç›®å½•'
            ))

        # æ£€æŸ¥æ ‡é¢˜ç»“æ„
        headings = re.findall(r'^(#{1,6})\s+(.+)', content, re.MULTILINE)
        if len(headings) < self.quality_standards['min_headings']:
            issues.append(QualityIssue(
                type='structure',
                severity='major',
                location='document',
                description='ç¼ºå°‘è¶³å¤Ÿçš„æ ‡é¢˜ç»“æ„',
                suggestion='æ·»åŠ è‡³å°‘2ä¸ªæ ‡é¢˜æ¥ç»„ç»‡å†…å®¹'
            ))

        # æ£€æŸ¥è¿‡é•¿çš„å¥å­
        sentences = re.split(r'[.!?]+', content)
        for i, sentence in enumerate(sentences):
            words = re.findall(r'\b\w+\b', sentence)
            if len(words) > self.quality_standards['max_sentence_length']:
                issues.append(QualityIssue(
                    type='readability',
                    severity='minor',
                    location=f'sentence {i+1}',
                    description=f'å¥å­è¿‡é•¿ï¼ˆ{len(words)}ä¸ªå•è¯ï¼‰',
                    suggestion='è€ƒè™‘åˆ†è§£ä¸ºå¤šä¸ªè¾ƒçŸ­çš„å¥å­'
                ))

        # æ£€æŸ¥æ–­é“¾
        links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
        for link_text, link_url in links:
            if link_url.startswith('http') and not self._check_url_accessible(link_url):
                issues.append(QualityIssue(
                    type='links',
                    severity='major',
                    location=f'link: {link_text}',
                    description=f'é“¾æ¥å¯èƒ½å¤±æ•ˆ: {link_url}',
                    suggestion='æ£€æŸ¥å¹¶æ›´æ–°é“¾æ¥åœ°å€'
                ))

        # æ£€æŸ¥é‡å¤å†…å®¹
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        for i, para1 in enumerate(paragraphs):
            for j, para2 in enumerate(paragraphs[i+1:], i+1):
                similarity = difflib.SequenceMatcher(None, para1, para2).ratio()
                if similarity > 0.8:
                    issues.append(QualityIssue(
                        type='duplication',
                        severity='minor',
                        location=f'paragraphs {i+1} and {j+1}',
                        description='å‘ç°é‡å¤æˆ–é«˜åº¦ç›¸ä¼¼çš„æ®µè½',
                        suggestion='åˆå¹¶æˆ–é‡å†™é‡å¤çš„å†…å®¹'
                    ))

        return issues

    def _check_url_accessible(self, url: str) -> bool:
        """æ£€æŸ¥URLæ˜¯å¦å¯è®¿é—®ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥å‘é€HTTPè¯·æ±‚
        # ç”±äºæˆ‘ä»¬ä¸æƒ³æ·»åŠ ç½‘ç»œä¾èµ–ï¼Œè¿™é‡ŒåªåšåŸºæœ¬æ£€æŸ¥
        return not any(indicator in url.lower() for indicator in ['example.com', 'localhost', '127.0.0.1'])

    def _generate_suggestions(self, metrics: DocumentMetrics, issues: List[QualityIssue]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        # åŸºäºæŒ‡æ ‡çš„å»ºè®®
        if metrics.readability_score < 50:
            suggestions.append('æé«˜å¯è¯»æ€§ï¼šä½¿ç”¨æ›´ç®€å•çš„è¯æ±‡å’Œæ›´çŸ­çš„å¥å­')

        if metrics.structure_score < 60:
            suggestions.append('æ”¹è¿›æ–‡æ¡£ç»“æ„ï¼šæ·»åŠ æ›´å¤šæ ‡é¢˜ã€åˆ—è¡¨å’Œä»£ç ç¤ºä¾‹')

        if metrics.completeness_score < 70:
            suggestions.append('å®Œå–„æ–‡æ¡£å†…å®¹ï¼šæ·»åŠ ä½¿ç”¨ç¤ºä¾‹ã€å®‰è£…è¯´æ˜æˆ–è´¡çŒ®æŒ‡å—')

        # åŸºäºé—®é¢˜çš„å»ºè®®
        issue_types = [issue.type for issue in issues]
        if 'length' in issue_types:
            suggestions.append('è°ƒæ•´æ–‡æ¡£é•¿åº¦ï¼šç¡®ä¿å†…å®¹å……å®ä½†ä¸å†—é•¿')

        if 'structure' in issue_types:
            suggestions.append('ä¼˜åŒ–æ–‡æ¡£ç»“æ„ï¼šä½¿ç”¨é€‚å½“çš„æ ‡é¢˜å±‚æ¬¡')

        if 'links' in issue_types:
            suggestions.append('æ£€æŸ¥æ‰€æœ‰é“¾æ¥ï¼šç¡®ä¿å¤–éƒ¨é“¾æ¥æœ‰æ•ˆ')

        if 'duplication' in issue_types:
            suggestions.append('æ¶ˆé™¤é‡å¤å†…å®¹ï¼šåˆå¹¶ç›¸ä¼¼çš„æ®µè½')

        # é€šç”¨å»ºè®®
        if not suggestions:
            suggestions.append('æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒï¼')

        return suggestions

    def _detect_document_type(self, file_path: str) -> str:
        """æ£€æµ‹æ–‡æ¡£ç±»å‹"""
        file_name = os.path.basename(file_path).lower()

        for doc_type, pattern in self.doc_patterns.items():
            if re.search(pattern, file_name, re.IGNORECASE):
                return doc_type

        return 'general'

    def _calculate_overall_score(self, metrics: DocumentMetrics, issues: List[QualityIssue]) -> float:
        """è®¡ç®—æ€»ä½“è´¨é‡è¯„åˆ†"""
        base_score = metrics.quality_score

        # æ ¹æ®é—®é¢˜ä¸¥é‡æ€§æ‰£åˆ†
        for issue in issues:
            if issue.severity == 'critical':
                base_score -= 15
            elif issue.severity == 'major':
                base_score -= 8
            elif issue.severity == 'minor':
                base_score -= 3

        return max(0, min(100, base_score))

    def _get_quality_level(self, score: float) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 90:
            return 'excellent'
        elif score >= 80:
            return 'good'
        elif score >= 70:
            return 'fair'
        elif score >= 60:
            return 'poor'
        else:
            return 'very_poor'

    def _extract_title(self, content: str) -> str:
        """æå–æ–‡æ¡£æ ‡é¢˜"""
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæ ‡é¢˜
        title_match = re.search(r'^#\s+(.+)', content, re.MULTILINE)
        if title_match:
            return title_match.group(1).strip()

        # æŸ¥æ‰¾æ–‡ä»¶åå½¢å¼çš„æ ‡é¢˜
        title_match = re.search(r'^(.+)\n=+\s*$', content, re.MULTILINE)
        if title_match:
            return title_match.group(1).strip()

        # å–ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜
        first_line = content.split('\n')[0].strip()
        if first_line and len(first_line) < 100:
            return first_line

        return 'Untitled Document'

    def _extract_key_points(self, content: str) -> List[str]:
        """æå–å…³é”®è¦ç‚¹"""
        key_points = []

        # æå–åˆ—è¡¨é¡¹
        list_items = re.findall(r'^[-*]\s+(.+)', content, re.MULTILINE)
        key_points.extend(list_items[:5])  # æœ€å¤š5ä¸ª

        # æå–äºŒçº§æ ‡é¢˜
        headings = re.findall(r'^##\s+(.+)', content, re.MULTILINE)
        key_points.extend(headings[:3])  # æœ€å¤š3ä¸ª

        # æå–é‡ç‚¹æ ‡è®°çš„å†…å®¹
        bold_text = re.findall(r'\*\*([^*]+)\*\*', content)
        key_points.extend(bold_text[:3])

        return list(set(key_points))[:8]  # å»é‡ï¼Œæœ€å¤š8ä¸ª

    def _generate_summary_sentences(self, content: str, max_sentences: int) -> List[str]:
        """ç”Ÿæˆæ‘˜è¦å¥å­"""
        sentences = re.split(r'[.!?]+', content)
        sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 20]

        if len(sentences) <= max_sentences:
            return sentences

        # ç®€å•çš„æ‘˜è¦ç®—æ³•ï¼šé€‰æ‹©æœ€æœ‰ä»£è¡¨æ€§çš„å¥å­
        # 1. åŒ…å«å…³é”®è¯çš„å¥å­
        # 2. ä½ç½®é å‰çš„å¥å­
        # 3. ä¸­ç­‰é•¿åº¦çš„å¥å­

        scored_sentences = []
        for i, sentence in enumerate(sentences):
            score = 0

            # ä½ç½®æƒé‡ï¼ˆè¶Šé å‰è¶Šé‡è¦ï¼‰
            score += (len(sentences) - i) / len(sentences) * 30

            # é•¿åº¦æƒé‡ï¼ˆä¸­ç­‰é•¿åº¦æœ€ä½³ï¼‰
            word_count = len(sentence.split())
            if 10 <= word_count <= 20:
                score += 20
            elif 5 <= word_count <= 30:
                score += 10

            # å…³é”®è¯æƒé‡
            keywords = ['æ˜¯', 'is', 'æä¾›', 'provide', 'æ”¯æŒ', 'support', 'åŠŸèƒ½', 'feature']
            for keyword in keywords:
                if keyword in sentence.lower():
                    score += 15

            scored_sentences.append((score, sentence))

        # æŒ‰åˆ†æ•°æ’åºå¹¶é€‰æ‹©å‰Nä¸ª
        scored_sentences.sort(reverse=True)
        return [sentence for _, sentence in scored_sentences[:max_sentences]]

    def _extract_metadata(self, content: str) -> Dict[str, Any]:
        """æå–æ–‡æ¡£å…ƒæ•°æ®"""
        metadata = {}

        # æŸ¥æ‰¾YAML front matter
        yaml_match = re.search(r'^---\n(.*?)\n---', content, re.DOTALL)
        if yaml_match:
            # ç®€å•è§£æYAMLï¼ˆä¸ä½¿ç”¨å¤–éƒ¨åº“ï¼‰
            yaml_content = yaml_match.group(1)
            for line in yaml_content.split('\n'):
                if ':' in line:
                    key, value = line.split(':', 1)
                    metadata[key.strip()] = value.strip()

        # æŸ¥æ‰¾å¸¸è§çš„å…ƒæ•°æ®æ¨¡å¼
        patterns = {
            'author': r'(?:author|ä½œè€…)[:ï¼š]\s*(.+)',
            'date': r'(?:date|æ—¥æœŸ|æ›´æ–°æ—¶é—´)[:ï¼š]\s*(\d{4}[-/]\d{2}[-/]\d{2})',
            'version': r'(?:version|ç‰ˆæœ¬)[:ï¼š]\s*([v\d.]+)',
            'tags': r'(?:tags|æ ‡ç­¾)[:ï¼š]\s*(.+)'
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                metadata[key] = match.group(1).strip()

        return metadata

    def _estimate_reading_time(self, content: str) -> str:
        """ä¼°ç®—é˜…è¯»æ—¶é—´"""
        words = re.findall(r'\b\w+\b', content)
        # å¹³å‡é˜…è¯»é€Ÿåº¦ï¼š200å­—/åˆ†é’Ÿ
        minutes = len(words) / 200

        if minutes < 1:
            return f"{int(minutes * 60)} seconds"
        elif minutes < 60:
            return f"{int(minutes)} minutes"
        else:
            hours = int(minutes // 60)
            remaining_minutes = int(minutes % 60)
            return f"{hours}h {remaining_minutes}m"

    def _calculate_similarity(self, content_a: str, content_b: str) -> SimilarityResult:
        """è®¡ç®—ä¸¤ä¸ªæ–‡æ¡£çš„ç›¸ä¼¼åº¦"""
        # é¢„å¤„ç†æ–‡æœ¬
        lines_a = [line.strip() for line in content_a.split('\n') if line.strip()]
        lines_b = [line.strip() for line in content_b.split('\n') if line.strip()]

        # è®¡ç®—åºåˆ—ç›¸ä¼¼åº¦
        seq_matcher = difflib.SequenceMatcher(None, lines_a, lines_b)
        similarity_ratio = seq_matcher.ratio()

        # æ‰¾å‡ºç›¸åŒçš„è¡Œ
        common_lines = []
        for tag, i1, i2, j1, j2 in seq_matcher.get_opcodes():
            if tag == 'equal':
                common_lines.extend(lines_a[i1:i2])

        # ç¡®å®šç›¸ä¼¼åº¦ç±»å‹
        if similarity_ratio >= 0.95:
            similarity_type = 'identical'
        elif similarity_ratio >= 0.8:
            similarity_type = 'high'
        elif similarity_ratio >= 0.5:
            similarity_type = 'medium'
        else:
            similarity_type = 'low'

        return SimilarityResult(
            document_a='',  # å°†åœ¨è°ƒç”¨æ—¶è®¾ç½®
            document_b='',  # å°†åœ¨è°ƒç”¨æ—¶è®¾ç½®
            similarity_ratio=similarity_ratio,
            common_lines=common_lines[:10],  # æœ€å¤šæ˜¾ç¤º10è¡Œ
            similarity_type=similarity_type
        )

    def _find_code_files(self, project_path) -> List[str]:
        """æŸ¥æ‰¾ä»£ç æ–‡ä»¶"""
        code_extensions = {'.py', '.js', '.ts', '.java', '.cpp', '.c', '.go', '.rs', '.php', '.rb'}
        code_files = []

        # ç¡®ä¿project_pathæ˜¯Pathå¯¹è±¡
        if isinstance(project_path, str):
            project_path = Path(project_path)

        for file_path in project_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in code_extensions:
                code_files.append(str(file_path))

        return code_files

    def _find_documentation_files(self, project_path) -> List[str]:
        """æŸ¥æ‰¾æ–‡æ¡£æ–‡ä»¶"""
        doc_extensions = {'.md', '.rst', '.txt', '.adoc'}
        doc_files = []

        # ç¡®ä¿project_pathæ˜¯Pathå¯¹è±¡
        if isinstance(project_path, str):
            project_path = Path(project_path)

        for file_path in project_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in doc_extensions:
                doc_files.append(str(file_path))

        return doc_files

    def _analyze_coverage(self, code_files: List[str], doc_files: List[str]) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£è¦†ç›–åº¦"""
        # ç®€åŒ–çš„è¦†ç›–åº¦åˆ†æ
        total_files = len(code_files)
        documented_files = 0

        # æ£€æŸ¥æ¯ä¸ªä»£ç æ–‡ä»¶æ˜¯å¦æœ‰å¯¹åº”çš„æ–‡æ¡£
        for code_file in code_files:
            code_path = Path(code_file)
            # æŸ¥æ‰¾åŒç›®å½•ä¸‹çš„READMEæˆ–åŒåçš„.mdæ–‡ä»¶
            possible_docs = [
                code_path.parent / 'README.md',
                code_path.with_suffix('.md'),
                code_path.parent / f"{code_path.stem}.md"
            ]

            if any(str(doc_path) in doc_files for doc_path in possible_docs):
                documented_files += 1

        coverage_percentage = (documented_files / total_files * 100) if total_files > 0 else 0

        return {
            'coverage_percentage': coverage_percentage,
            'total_code_files': total_files,
            'documented_files': documented_files,
            'undocumented_files': total_files - documented_files
        }

    def _find_missing_documentation(self, project_path: Path) -> List[str]:
        """æŸ¥æ‰¾ç¼ºå¤±çš„æ–‡æ¡£"""
        missing_docs = []

        # æ£€æŸ¥æ ‡å‡†æ–‡æ¡£æ–‡ä»¶
        standard_docs = ['README.md', 'CHANGELOG.md', 'CONTRIBUTING.md', 'LICENSE.md', 'API.md']
        for doc_name in standard_docs:
            doc_path = project_path / doc_name
            if not doc_path.exists():
                missing_docs.append(doc_name)

        return missing_docs

    def _analyze_doc_structure(self, doc_files: List[str]) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£ç»“æ„"""
        structure = {
            'total_files': len(doc_files),
            'by_type': defaultdict(int),
            'by_directory': defaultdict(int)
        }

        for doc_file in doc_files:
            file_path = Path(doc_file)

            # æŒ‰ç±»å‹åˆ†ç±»
            doc_type = self._detect_document_type(doc_file)
            structure['by_type'][doc_type] += 1

            # æŒ‰ç›®å½•åˆ†ç±»
            directory = str(file_path.parent)
            structure['by_directory'][directory] += 1

        return dict(structure)

    def _generate_coverage_recommendations(self, coverage_analysis: Dict[str, Any], missing_docs: List[str]) -> List[str]:
        """ç”Ÿæˆè¦†ç›–åº¦å»ºè®®"""
        recommendations = []

        coverage = coverage_analysis['coverage_percentage']

        if coverage < 30:
            recommendations.append('æ–‡æ¡£è¦†ç›–åº¦ä¸¥é‡ä¸è¶³ï¼Œå»ºè®®ä¸ºä¸»è¦æ¨¡å—æ·»åŠ æ–‡æ¡£')
        elif coverage < 60:
            recommendations.append('æ–‡æ¡£è¦†ç›–åº¦åä½ï¼Œå»ºè®®å¢åŠ APIæ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—')
        elif coverage < 80:
            recommendations.append('æ–‡æ¡£è¦†ç›–åº¦è‰¯å¥½ï¼Œå¯ä»¥å®Œå–„è¯¦ç»†è¯´æ˜å’Œç¤ºä¾‹')

        if missing_docs:
            recommendations.append(f'å»ºè®®æ·»åŠ ç¼ºå¤±çš„æ ‡å‡†æ–‡æ¡£ï¼š{", ".join(missing_docs)}')

        if coverage_analysis['undocumented_files'] > 0:
            recommendations.append(f'æœ‰{coverage_analysis["undocumented_files"]}ä¸ªä»£ç æ–‡ä»¶ç¼ºå°‘æ–‡æ¡£')

        return recommendations

    def _find_files_by_pattern(self, pattern: str) -> List[str]:
        """æŒ‰æ¨¡å¼æŸ¥æ‰¾æ–‡ä»¶"""
        project_path = Path(self.project_root)
        matching_files = []

        try:
            if '*' in pattern or '?' in pattern:
                # Globæ¨¡å¼
                matching_files = [str(p) for p in project_path.rglob(pattern) if p.is_file()]
            else:
                # ç²¾ç¡®åŒ¹é…æˆ–æ‰©å±•ååŒ¹é…
                if pattern.startswith('.'):
                    # æ‰©å±•ååŒ¹é…
                    matching_files = [str(p) for p in project_path.rglob(f'*{pattern}') if p.is_file()]
                else:
                    # æ–‡ä»¶ååŒ¹é…
                    matching_files = [str(p) for p in project_path.rglob(f'*{pattern}*') if p.is_file()]
        except Exception:
            pass

        return matching_files

    def _analyze_quality_distribution(self, quality_scores: List[float]) -> Dict[str, int]:
        """åˆ†æè´¨é‡åˆ†å¸ƒ"""
        distribution = {
            'excellent': 0,  # 90+
            'good': 0,       # 80-89
            'fair': 0,       # 70-79
            'poor': 0,       # 60-69
            'very_poor': 0   # <60
        }

        for score in quality_scores:
            if score >= 90:
                distribution['excellent'] += 1
            elif score >= 80:
                distribution['good'] += 1
            elif score >= 70:
                distribution['fair'] += 1
            elif score >= 60:
                distribution['poor'] += 1
            else:
                distribution['very_poor'] += 1

        return distribution

    def _analyze_common_issues(self, all_issues: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åˆ†æå¸¸è§é—®é¢˜"""
        issue_counter = Counter()
        severity_counter = Counter()

        for issue in all_issues:
            issue_type = issue['type']
            severity = issue['severity']

            issue_counter[issue_type] += 1
            severity_counter[severity] += 1

        return [
            {
                'type': 'most_common_issues',
                'data': dict(issue_counter.most_common(5))
            },
            {
                'type': 'severity_distribution',
                'data': dict(severity_counter)
            }
        ]

    def _generate_global_recommendations(self, statistics: Dict[str, Any], common_issues: List[Dict[str, Any]]) -> List[str]:
        """ç”Ÿæˆå…¨å±€å»ºè®®"""
        recommendations = []

        if not statistics:
            return ['æ— æ³•ç”Ÿæˆå»ºè®®ï¼Œç¼ºå°‘ç»Ÿè®¡æ•°æ®']

        avg_quality = statistics.get('average_quality', 0)

        if avg_quality < 60:
            recommendations.append('æ•´ä½“æ–‡æ¡£è´¨é‡è¾ƒä½ï¼Œå»ºè®®åˆ¶å®šæ–‡æ¡£è§„èŒƒå’Œæ”¹è¿›è®¡åˆ’')
        elif avg_quality < 80:
            recommendations.append('æ–‡æ¡£è´¨é‡ä¸­ç­‰ï¼Œå»ºè®®é‡ç‚¹æ”¹è¿›ä½è´¨é‡æ–‡æ¡£')
        else:
            recommendations.append('æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå¹¶æŒç»­ä¼˜åŒ–')

        # åŸºäºå¸¸è§é—®é¢˜çš„å»ºè®®
        for issue_analysis in common_issues:
            if issue_analysis['type'] == 'most_common_issues':
                top_issues = list(issue_analysis['data'].keys())[:3]
                if top_issues:
                    recommendations.append(f'é‡ç‚¹å…³æ³¨è¿™äº›é—®é¢˜ç±»å‹ï¼š{", ".join(top_issues)}')

        quality_std = statistics.get('quality_std_dev', 0)
        if quality_std > 20:
            recommendations.append('æ–‡æ¡£è´¨é‡å·®å¼‚è¾ƒå¤§ï¼Œå»ºè®®ç»Ÿä¸€æ ‡å‡†å’Œæ¨¡æ¿')

        return recommendations

    def generate_quality_report(self, output_file: Optional[str] = None) -> str:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = output_file or str(self.cache_dir / f'docgate_quality_report_{timestamp}.md')

        # åˆ†æé¡¹ç›®ä¸­çš„æ‰€æœ‰æ–‡æ¡£
        doc_files = self._find_documentation_files(Path(self.project_root))
        batch_result = self.batch_analyze_documents(['*.md', '*.rst', '*.txt'])

        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = f"""# DocGate æ–‡æ¡£è´¨é‡åˆ†ææŠ¥å‘Š

## ğŸ“Š ç”Ÿæˆä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **åˆ†æè·¯å¾„**: {self.project_root}
- **DocGateç‰ˆæœ¬**: 1.0.0

## ğŸ“ˆ æ€»ä½“ç»Ÿè®¡

"""

        if 'summary_statistics' in batch_result and batch_result['summary_statistics']:
            stats = batch_result['summary_statistics']
            report_content += f"""
- **æ–‡æ¡£æ€»æ•°**: {stats.get('total_documents', 0)}
- **å¹³å‡è´¨é‡**: {stats.get('average_quality', 0):.1f}/100
- **è´¨é‡ä¸­ä½æ•°**: {stats.get('median_quality', 0):.1f}/100
- **æœ€é«˜è´¨é‡**: {stats.get('highest_quality', 0):.1f}/100
- **æœ€ä½è´¨é‡**: {stats.get('lowest_quality', 0):.1f}/100
- **è´¨é‡æ ‡å‡†å·®**: {stats.get('quality_std_dev', 0):.1f}

"""

        # è´¨é‡åˆ†å¸ƒ
        if 'quality_distribution' in batch_result:
            dist = batch_result['quality_distribution']
            report_content += """## ğŸ“Š è´¨é‡åˆ†å¸ƒ

| è´¨é‡ç­‰çº§ | æ–‡æ¡£æ•°é‡ | ç™¾åˆ†æ¯” |
|----------|----------|--------|
"""
            total_docs = sum(dist.values()) if dist else 1
            for level, count in dist.items():
                percentage = count / total_docs * 100
                report_content += f"| {level} | {count} | {percentage:.1f}% |\n"

        # å¸¸è§é—®é¢˜
        if 'common_issues' in batch_result and batch_result['common_issues']:
            report_content += "\n## âš ï¸ å¸¸è§é—®é¢˜\n\n"
            for issue_analysis in batch_result['common_issues']:
                if issue_analysis['type'] == 'most_common_issues':
                    report_content += "### é—®é¢˜ç±»å‹åˆ†å¸ƒ\n\n"
                    for issue_type, count in issue_analysis['data'].items():
                        report_content += f"- **{issue_type}**: {count}æ¬¡\n"
                elif issue_analysis['type'] == 'severity_distribution':
                    report_content += "\n### ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ\n\n"
                    for severity, count in issue_analysis['data'].items():
                        report_content += f"- **{severity}**: {count}ä¸ªé—®é¢˜\n"

        # æ”¹è¿›å»ºè®®
        if 'global_recommendations' in batch_result and batch_result['global_recommendations']:
            report_content += "\n## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
            for i, recommendation in enumerate(batch_result['global_recommendations'], 1):
                report_content += f"{i}. {recommendation}\n"

        # è¯¦ç»†æ–‡æ¡£åˆ†æ
        if 'analyzed_files' in batch_result and batch_result['analyzed_files']:
            report_content += "\n## ğŸ“‹ è¯¦ç»†æ–‡æ¡£åˆ†æ\n\n"
            for doc in batch_result['analyzed_files'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                quality_level = doc.get('quality_level', 'unknown')
                overall_score = doc.get('overall_score', 0)
                file_path = doc.get('file_path', '').replace(self.project_root, '')

                report_content += f"### {file_path}\n\n"
                report_content += f"- **è´¨é‡è¯„åˆ†**: {overall_score:.1f}/100 ({quality_level})\n"
                report_content += f"- **æ–‡æ¡£ç±»å‹**: {doc.get('document_type', 'unknown')}\n"

                metrics = doc.get('metrics', {})
                if metrics:
                    report_content += f"- **å­—æ•°**: {metrics.get('word_count', 0)}\n"
                    report_content += f"- **å¯è¯»æ€§**: {metrics.get('readability_score', 0):.1f}/100\n"
                    report_content += f"- **ç»“æ„æ€§**: {metrics.get('structure_score', 0):.1f}/100\n"

                issues = doc.get('issues', [])
                if issues:
                    report_content += "- **ä¸»è¦é—®é¢˜**:\n"
                    for issue in issues[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé—®é¢˜
                        report_content += f"  - {issue.get('description', 'Unknown issue')}\n"

                report_content += "\n"

        # å†™å…¥æ–‡ä»¶
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)

        return report_file


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºDocGate Agentçš„åŠŸèƒ½"""
    docgate = DocGateAgent()

    print("ğŸš€ DocGate Agent - æ–‡æ¡£è´¨é‡åˆ†æä¸“å®¶")
    print("=" * 50)

    # æ¼”ç¤ºåŠŸèƒ½
    sample_doc = "/home/xx/dev/Claude Enhancer 5.0/README.md"

    if os.path.exists(sample_doc):
        print(f"\nğŸ“– åˆ†ææ–‡æ¡£: {sample_doc}")

        # è´¨é‡åˆ†æ
        quality_result = docgate.analyze_document_quality(sample_doc)
        if 'error' not in quality_result:
            print(f"âœ… è´¨é‡è¯„åˆ†: {quality_result['overall_score']:.1f}/100")
            print(f"âœ… è´¨é‡ç­‰çº§: {quality_result['quality_level']}")

        # ç”Ÿæˆæ‘˜è¦
        summary_result = docgate.generate_document_summary(sample_doc)
        if 'error' not in summary_result:
            print(f"âœ… æ‘˜è¦: {summary_result['summary'][:100]}...")

    # ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š
    print(f"\nğŸ“Š ç”Ÿæˆé¡¹ç›®è´¨é‡æŠ¥å‘Š...")
    report_file = docgate.generate_quality_report()
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    print("\nğŸ‰ DocGate Agent æ¼”ç¤ºå®Œæˆ!")


if __name__ == "__main__":
    main()