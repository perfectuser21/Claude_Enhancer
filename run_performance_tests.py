#!/usr/bin/env python3
"""
Perfect21 æ€§èƒ½æµ‹è¯•æ‰§è¡Œå™¨
è‡ªåŠ¨å¯åŠ¨æ¨¡æ‹ŸæœåŠ¡å™¨å¹¶æ‰§è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶
"""

import asyncio
import subprocess
import sys
import time
import signal
import os
import logging
from pathlib import Path
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class PerformanceTestRunner:
    """æ€§èƒ½æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self):
        self.server_process = None
        self.server_ready = False

    async def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–"""
        logger.info("ğŸ” æ£€æŸ¥æµ‹è¯•ä¾èµ–...")

        required_packages = [
            'aiohttp',
            'aiohttp-cors',
            'psutil',
            'matplotlib',
            'pandas'
        ]

        missing_packages = []
        for package in required_packages:
            try:
                __import__(package.replace('-', '_'))
            except ImportError:
                missing_packages.append(package)

        if missing_packages:
            logger.error(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
            logger.info("è¯·è¿è¡Œ: pip install " + " ".join(missing_packages))
            return False

        logger.info("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
        return True

    async def start_mock_server(self):
        """å¯åŠ¨æ¨¡æ‹ŸæœåŠ¡å™¨"""
        logger.info("ğŸš€ å¯åŠ¨æ¨¡æ‹Ÿæ€§èƒ½æµ‹è¯•æœåŠ¡å™¨...")

        try:
            # å¯åŠ¨æ¨¡æ‹ŸæœåŠ¡å™¨
            self.server_process = subprocess.Popen(
                [sys.executable, "mock_performance_server.py"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                preexec_fn=os.setsid if hasattr(os, 'setsid') else None
            )

            # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
            max_wait = 30  # æœ€å¤§ç­‰å¾…30ç§’
            wait_time = 0

            while wait_time < max_wait:
                try:
                    # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦å“åº”
                    import aiohttp
                    async with aiohttp.ClientSession() as session:
                        async with session.get('http://localhost:8080/health', timeout=aiohttp.ClientTimeout(total=2)) as response:
                            if response.status == 200:
                                self.server_ready = True
                                logger.info("âœ… æ¨¡æ‹ŸæœåŠ¡å™¨å¯åŠ¨æˆåŠŸ")
                                return True
                except Exception:
                    pass

                await asyncio.sleep(1)
                wait_time += 1

            logger.error("âŒ æ¨¡æ‹ŸæœåŠ¡å™¨å¯åŠ¨è¶…æ—¶")
            return False

        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨æ¨¡æ‹ŸæœåŠ¡å™¨å¤±è´¥: {e}")
            return False

    async def stop_mock_server(self):
        """åœæ­¢æ¨¡æ‹ŸæœåŠ¡å™¨"""
        if self.server_process:
            logger.info("ğŸ›‘ åœæ­¢æ¨¡æ‹ŸæœåŠ¡å™¨...")
            try:
                # å‘é€ç»ˆæ­¢ä¿¡å·
                if hasattr(os, 'killpg'):
                    os.killpg(os.getpgid(self.server_process.pid), signal.SIGTERM)
                else:
                    self.server_process.terminate()

                # ç­‰å¾…è¿›ç¨‹ç»“æŸ
                try:
                    self.server_process.wait(timeout=5)
                except subprocess.TimeoutExpired:
                    # å¼ºåˆ¶ç»ˆæ­¢
                    if hasattr(os, 'killpg'):
                        os.killpg(os.getpgid(self.server_process.pid), signal.SIGKILL)
                    else:
                        self.server_process.kill()

                logger.info("âœ… æ¨¡æ‹ŸæœåŠ¡å™¨å·²åœæ­¢")
            except Exception as e:
                logger.error(f"âŒ åœæ­¢æ¨¡æ‹ŸæœåŠ¡å™¨å¤±è´¥: {e}")

    async def run_performance_tests(self):
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        logger.info("âš¡ å¼€å§‹æ‰§è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•...")

        try:
            # å¯¼å…¥æµ‹è¯•æ¨¡å—
            from comprehensive_performance_test import ComprehensivePerformanceTester

            # åˆ›å»ºæµ‹è¯•å™¨
            tester = ComprehensivePerformanceTester("http://localhost:8080")

            # åˆå§‹åŒ–æµ‹è¯•å™¨
            await tester.initialize()

            # è¿è¡Œæµ‹è¯•
            report = await tester.run_comprehensive_tests()

            # ä¿å­˜æŠ¥å‘Š
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            report_filename = f"performance_report_{timestamp}.json"
            await tester.save_report_to_file(report, report_filename)

            # ç”Ÿæˆæµ‹è¯•æ‘˜è¦
            await self.generate_test_summary(report, report_filename)

            return report

        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            raise

    async def generate_test_summary(self, report, report_filename):
        """ç”Ÿæˆæµ‹è¯•æ‘˜è¦"""
        logger.info("ğŸ“‹ ç”Ÿæˆæµ‹è¯•æ‘˜è¦...")

        # åˆ›å»ºæ‘˜è¦æ•°æ®
        summary = {
            "æµ‹è¯•æ¦‚è¿°": {
                "æ•´ä½“è¯„åˆ†": f"{report.overall_score:.1f}/100",
                "æµ‹è¯•æ—¶é—´": report.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                "æµ‹è¯•é¡¹ç›®æ•°": len(report.test_results),
                "ç³»ç»Ÿä¿¡æ¯": report.system_info
            },
            "å…³é”®æŒ‡æ ‡": {},
            "æ€§èƒ½ç“¶é¢ˆ": report.bottlenecks,
            "ä¼˜åŒ–å»ºè®®": report.recommendations
        }

        # æå–å…³é”®æŒ‡æ ‡
        for result in report.test_results:
            summary["å…³é”®æŒ‡æ ‡"][result.test_name] = {
                "ååé‡(RPS)": f"{result.requests_per_second:.1f}",
                "å¹³å‡å“åº”æ—¶é—´(ms)": f"{result.avg_response_time_ms:.1f}",
                "P95å“åº”æ—¶é—´(ms)": f"{result.p95_response_time_ms:.1f}",
                "é”™è¯¯ç‡(%)": f"{result.error_rate_percent:.2f}",
                "CPUä½¿ç”¨ç‡(%)": f"{result.cpu_usage_percent:.1f}",
                "å†…å­˜ä½¿ç”¨(MB)": f"{result.memory_usage_mb:.1f}"
            }

            if result.cache_hit_rate_percent > 0:
                summary["å…³é”®æŒ‡æ ‡"][result.test_name]["ç¼“å­˜å‘½ä¸­ç‡(%)"] = f"{result.cache_hit_rate_percent:.1f}"

        # ä¿å­˜æ‘˜è¦
        summary_filename = f"performance_summary_{time.strftime('%Y%m%d_%H%M%S')}.json"
        with open(summary_filename, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

        # æ‰“å°æ§åˆ¶å°æ‘˜è¦
        self.print_console_summary(report)

        logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_filename}")
        logger.info(f"ğŸ“Š æµ‹è¯•æ‘˜è¦: {summary_filename}")

    def print_console_summary(self, report):
        """æ‰“å°æ§åˆ¶å°æ‘˜è¦"""
    # print("\n" + "="*80)
    # print("ğŸ¯ PERFECT21 æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
    # print("="*80)

        # æ•´ä½“è¯„åˆ†
        score_color = "ğŸŸ¢" if report.overall_score >= 80 else "ğŸŸ¡" if report.overall_score >= 60 else "ğŸ”´"
    # print(f"{score_color} æ•´ä½“æ€§èƒ½è¯„åˆ†: {report.overall_score:.1f}/100")

        # æµ‹è¯•ç»“æœæ¦‚è§ˆ
    # print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ¦‚è§ˆ:")
    # print(f"  æµ‹è¯•æ—¶é—´: {report.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
    # print(f"  æµ‹è¯•é¡¹ç›®: {len(report.test_results)}ä¸ª")
    # print(f"  ç³»ç»Ÿä¿¡æ¯: {report.system_info['cpu_count']}æ ¸CPU, {report.system_info['total_memory_gb']:.1f}GBå†…å­˜")

        # è¯¦ç»†æµ‹è¯•ç»“æœ
    # print(f"\nğŸ“ˆ è¯¦ç»†æµ‹è¯•ç»“æœ:")
    # print("-" * 80)
    # print(f"{'æµ‹è¯•é¡¹ç›®':<25} {'RPS':<8} {'å“åº”æ—¶é—´':<12} {'P95':<10} {'é”™è¯¯ç‡':<8} {'CPU':<6} {'å†…å­˜':<8}")
    # print("-" * 80)

        for result in report.test_results:
            test_name = result.test_name[:24]
            rps = f"{result.requests_per_second:.1f}"
            avg_time = f"{result.avg_response_time_ms:.1f}ms"
            p95_time = f"{result.p95_response_time_ms:.1f}ms"
            error_rate = f"{result.error_rate_percent:.2f}%"
            cpu = f"{result.cpu_usage_percent:.1f}%"
            memory = f"{result.memory_usage_mb:.0f}MB"

    # print(f"{test_name:<25} {rps:<8} {avg_time:<12} {p95_time:<10} {error_rate:<8} {cpu:<6} {memory:<8}")

        # æ€§èƒ½ç“¶é¢ˆ
        if report.bottlenecks:
    # print(f"\nâš ï¸ å‘ç°çš„æ€§èƒ½ç“¶é¢ˆ ({len(report.bottlenecks)}ä¸ª):")
            for i, bottleneck in enumerate(report.bottlenecks, 1):
    # print(f"  {i}. {bottleneck}")

        # ä¼˜åŒ–å»ºè®®
        if report.recommendations:
    # print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®® ({len(report.recommendations)}ä¸ª):")
            for i, recommendation in enumerate(report.recommendations, 1):
    # print(f"  {i}. {recommendation}")

        # å›¾è¡¨ä¿¡æ¯
        charts_dir = Path("performance_charts")
        if charts_dir.exists():
            charts = list(charts_dir.glob("*.png"))
            if charts:
    # print(f"\nğŸ“ˆ ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶ ({len(charts)}ä¸ª):")
                for chart in charts:
    # print(f"  ğŸ“Š {chart.name}")

    # print("\n" + "="*80)

async def main():
    """ä¸»å‡½æ•°"""
    # print("ğŸš€ Perfect21 æ€§èƒ½æµ‹è¯•æ‰§è¡Œå™¨")
    # print("=" * 50)

    runner = PerformanceTestRunner()

    try:
        # 1. æ£€æŸ¥ä¾èµ–
        if not await runner.check_dependencies():
            return 1

        # 2. å¯åŠ¨æ¨¡æ‹ŸæœåŠ¡å™¨
        if not await runner.start_mock_server():
            return 1

        # 3. ç­‰å¾…ç”¨æˆ·ç¡®è®¤æˆ–è‡ªåŠ¨å¼€å§‹
    # print("\nğŸ”„ æ¨¡æ‹ŸæœåŠ¡å™¨å·²å°±ç»ªï¼Œå‡†å¤‡å¼€å§‹æ€§èƒ½æµ‹è¯•...")
    # print("æµ‹è¯•å°†åŒ…æ‹¬:")
    # print("  âš¡ è´Ÿè½½æµ‹è¯• (1000å¹¶å‘ç”¨æˆ·)")
    # print("  â±ï¸ å“åº”æ—¶é—´æµ‹è¯•")
    # print("  ğŸ’¾ å†…å­˜ä½¿ç”¨æµ‹è¯•")
    # print("  ğŸ—„ï¸ æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–æµ‹è¯•")
    # print("  ğŸ—‚ï¸ ç¼“å­˜å‘½ä¸­ç‡æµ‹è¯•")
    # print("  ğŸ’¥ å‹åŠ›æµ‹è¯• (æé™è´Ÿè½½)")

    # print("\næŒ‰ Enter é”®å¼€å§‹æµ‹è¯• (æˆ–ç­‰å¾…10ç§’è‡ªåŠ¨å¼€å§‹)...")

        # ç­‰å¾…ç”¨æˆ·è¾“å…¥æˆ–è¶…æ—¶
        try:
            await asyncio.wait_for(asyncio.to_thread(input), timeout=10.0)
        except asyncio.TimeoutError:
    # print("â° è¶…æ—¶ï¼Œè‡ªåŠ¨å¼€å§‹æµ‹è¯•...")

        # 4. è¿è¡Œæ€§èƒ½æµ‹è¯•
        report = await runner.run_performance_tests()

    # print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
        return 0

    except KeyboardInterrupt:
    # print("\nâŒ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        return 1

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return 1

    finally:
        # æ¸…ç†
        await runner.stop_mock_server()

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)