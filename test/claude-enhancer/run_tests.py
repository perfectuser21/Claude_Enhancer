#!/usr/bin/env python3
"""
Claude Enhancer æµ‹è¯•æ‰§è¡Œå™¨
ç»Ÿä¸€çš„æµ‹è¯•è¿è¡Œå’ŒæŠ¥å‘Šç”Ÿæˆå·¥å…·
"""

import os
import sys
import argparse
import subprocess
import json
import time
from pathlib import Path
from typing import Dict, List, Any
import concurrent.futures


class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.test_root = project_root / "test" / "claude-enhancer"
        self.results = {}
        self.start_time = None
        self.end_time = None

    def run_all_tests(self, parallel: bool = True, categories: List[str] = None) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.start_time = time.time()

        test_categories = {
            "hooks": self.test_root / "hooks",
            "workflows": self.test_root / "workflows",
            "integration": self.test_root / "integration",
            "performance": self.test_root / "performance",
            "security": self.test_root / "security"
        }

        # è¿‡æ»¤è¦è¿è¡Œçš„æµ‹è¯•ç±»åˆ«
        if categories:
            test_categories = {k: v for k, v in test_categories.items() if k in categories}

        print(f"ğŸš€ å¼€å§‹è¿è¡Œ Claude Enhancer æµ‹è¯•å¥—ä»¶")
        print(f"ğŸ“ æµ‹è¯•ç›®å½•: {self.test_root}")
        print(f"ğŸ·ï¸  æµ‹è¯•ç±»åˆ«: {', '.join(test_categories.keys())}")
        print(f"âš¡ å¹¶è¡Œæ‰§è¡Œ: {'æ˜¯' if parallel else 'å¦'}")
        print("-" * 60)

        if parallel:
            self._run_tests_parallel(test_categories)
        else:
            self._run_tests_sequential(test_categories)

        self.end_time = time.time()
        return self._generate_summary()

    def _run_tests_parallel(self, test_categories: Dict[str, Path]):
        """å¹¶è¡Œè¿è¡Œæµ‹è¯•"""
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(test_categories)) as executor:
            futures = {
                executor.submit(self._run_test_category, category, path): category
                for category, path in test_categories.items()
            }

            for future in concurrent.futures.as_completed(futures):
                category = futures[future]
                try:
                    result = future.result()
                    self.results[category] = result
                    self._print_category_result(category, result)
                except Exception as e:
                    self.results[category] = {
                        "success": False,
                        "error": str(e),
                        "tests_run": 0,
                        "tests_passed": 0,
                        "tests_failed": 1,
                        "execution_time": 0
                    }
                    print(f"âŒ {category} æµ‹è¯•å¤±è´¥: {e}")

    def _run_tests_sequential(self, test_categories: Dict[str, Path]):
        """é¡ºåºè¿è¡Œæµ‹è¯•"""
        for category, path in test_categories.items():
            try:
                result = self._run_test_category(category, path)
                self.results[category] = result
                self._print_category_result(category, result)
            except Exception as e:
                self.results[category] = {
                    "success": False,
                    "error": str(e),
                    "tests_run": 0,
                    "tests_passed": 0,
                    "tests_failed": 1,
                    "execution_time": 0
                }
                print(f"âŒ {category} æµ‹è¯•å¤±è´¥: {e}")

    def _run_test_category(self, category: str, test_path: Path) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæµ‹è¯•ç±»åˆ«"""
        if not test_path.exists():
            return {
                "success": False,
                "error": f"Test directory not found: {test_path}",
                "tests_run": 0,
                "tests_passed": 0,
                "tests_failed": 1,
                "execution_time": 0
            }

        start_time = time.time()

        # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
        test_files = list(test_path.glob("test_*.py"))
        if not test_files:
            return {
                "success": False,
                "error": "No test files found",
                "tests_run": 0,
                "tests_passed": 0,
                "tests_failed": 1,
                "execution_time": 0
            }

        # è¿è¡Œpytest
        cmd = [
            sys.executable, "-m", "pytest",
            str(test_path),
            "-v",
            "--tb=short",
            "--json-report",
            f"--json-report-file={self.project_root}/test-results/{category}-results.json"
        ]

        # ä¸ºæ€§èƒ½æµ‹è¯•æ·»åŠ ç‰¹æ®Šæ ‡å¿—
        if category == "performance":
            cmd.extend(["--benchmark-only", "--benchmark-json=performance-results.json"])

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=self.project_root,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )

            end_time = time.time()
            execution_time = end_time - start_time

            # è§£æpytestè¾“å‡º
            return self._parse_pytest_result(result, execution_time)

        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "error": "Tests timed out after 5 minutes",
                "tests_run": 0,
                "tests_passed": 0,
                "tests_failed": 1,
                "execution_time": 300
            }

    def _parse_pytest_result(self, result: subprocess.CompletedProcess, execution_time: float) -> Dict[str, Any]:
        """è§£æpytestç»“æœ"""
        success = result.returncode == 0

        # ä»è¾“å‡ºä¸­æå–æµ‹è¯•ç»Ÿè®¡
        output_lines = result.stdout.split('\n')
        tests_run = 0
        tests_passed = 0
        tests_failed = 0
        tests_skipped = 0

        for line in output_lines:
            if "failed" in line and "passed" in line:
                # è§£æç±»ä¼¼ "2 failed, 8 passed in 1.23s" çš„è¡Œ
                parts = line.split()
                for i, part in enumerate(parts):
                    if part == "failed" and i > 0:
                        tests_failed = int(parts[i-1])
                    elif part == "passed" and i > 0:
                        tests_passed = int(parts[i-1])
                    elif part == "skipped" and i > 0:
                        tests_skipped = int(parts[i-1])

        tests_run = tests_passed + tests_failed + tests_skipped

        return {
            "success": success,
            "tests_run": tests_run,
            "tests_passed": tests_passed,
            "tests_failed": tests_failed,
            "tests_skipped": tests_skipped,
            "execution_time": execution_time,
            "stdout": result.stdout,
            "stderr": result.stderr
        }

    def _print_category_result(self, category: str, result: Dict[str, Any]):
        """æ‰“å°ç±»åˆ«æµ‹è¯•ç»“æœ"""
        if result["success"]:
            status_icon = "âœ…"
            status_text = "é€šè¿‡"
        else:
            status_icon = "âŒ"
            status_text = "å¤±è´¥"

        print(f"{status_icon} {category.upper()} {status_text}")
        print(f"   ğŸ“Š è¿è¡Œ: {result['tests_run']}, é€šè¿‡: {result['tests_passed']}, å¤±è´¥: {result['tests_failed']}")
        print(f"   â±ï¸  è€—æ—¶: {result['execution_time']:.2f}s")

        if not result["success"] and "error" in result:
            print(f"   â— é”™è¯¯: {result['error']}")

        print()

    def _generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ‘˜è¦"""
        total_tests = sum(r.get("tests_run", 0) for r in self.results.values())
        total_passed = sum(r.get("tests_passed", 0) for r in self.results.values())
        total_failed = sum(r.get("tests_failed", 0) for r in self.results.values())
        total_skipped = sum(r.get("tests_skipped", 0) for r in self.results.values())
        total_time = self.end_time - self.start_time if self.end_time and self.start_time else 0

        success_rate = (total_passed / total_tests * 100) if total_tests > 0 else 0
        overall_success = all(r.get("success", False) for r in self.results.values())

        summary = {
            "overall_success": overall_success,
            "total_tests": total_tests,
            "total_passed": total_passed,
            "total_failed": total_failed,
            "total_skipped": total_skipped,
            "success_rate": success_rate,
            "total_execution_time": total_time,
            "categories": self.results,
            "timestamp": time.time()
        }

        self._print_summary(summary)
        return summary

    def _print_summary(self, summary: Dict[str, Any]):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print("=" * 60)
        print("ğŸ“‹ Claude Enhancer æµ‹è¯•æ‘˜è¦")
        print("=" * 60)

        if summary["overall_success"]:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")

        print(f"ğŸ“Š æ€»è®¡: {summary['total_tests']} ä¸ªæµ‹è¯•")
        print(f"âœ… é€šè¿‡: {summary['total_passed']} ä¸ª")
        print(f"âŒ å¤±è´¥: {summary['total_failed']} ä¸ª")
        print(f"â­ï¸  è·³è¿‡: {summary['total_skipped']} ä¸ª")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"â±ï¸  æ€»è€—æ—¶: {summary['total_execution_time']:.2f}s")

        print("\nğŸ“ åˆ†ç±»è¯¦æƒ…:")
        for category, result in summary["categories"].items():
            status = "âœ…" if result.get("success", False) else "âŒ"
            print(f"  {status} {category}: {result.get('tests_passed', 0)}/{result.get('tests_run', 0)} é€šè¿‡")

        print("=" * 60)

    def save_results(self, output_file: Path):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        summary = self._generate_summary()

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


class TestValidator:
    """æµ‹è¯•éªŒè¯å™¨"""

    def __init__(self, project_root: Path):
        self.project_root = project_root

    def validate_test_environment(self) -> bool:
        """éªŒè¯æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ” éªŒè¯æµ‹è¯•ç¯å¢ƒ...")

        checks = [
            self._check_python_version,
            self._check_required_packages,
            self._check_test_files,
            self._check_hook_scripts
        ]

        all_passed = True
        for check in checks:
            try:
                if not check():
                    all_passed = False
            except Exception as e:
                print(f"âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {e}")
                all_passed = False

        if all_passed:
            print("âœ… æµ‹è¯•ç¯å¢ƒéªŒè¯é€šè¿‡")
        else:
            print("âŒ æµ‹è¯•ç¯å¢ƒéªŒè¯å¤±è´¥")

        return all_passed

    def _check_python_version(self) -> bool:
        """æ£€æŸ¥Pythonç‰ˆæœ¬"""
        version = sys.version_info
        if version.major >= 3 and version.minor >= 7:
            print(f"âœ… Pythonç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")
            return True
        else:
            print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {version.major}.{version.minor}.{version.micro} (éœ€è¦ 3.7+)")
            return False

    def _check_required_packages(self) -> bool:
        """æ£€æŸ¥å¿…éœ€çš„åŒ…"""
        required_packages = [
            "pytest",
            "psutil",
            "memory_profiler"
        ]

        missing_packages = []
        for package in required_packages:
            try:
                __import__(package)
                print(f"âœ… {package} å·²å®‰è£…")
            except ImportError:
                missing_packages.append(package)
                print(f"âŒ {package} æœªå®‰è£…")

        if missing_packages:
            print(f"ğŸ’¡ è¯·å®‰è£…ç¼ºå¤±çš„åŒ…: pip install {' '.join(missing_packages)}")
            return False

        return True

    def _check_test_files(self) -> bool:
        """æ£€æŸ¥æµ‹è¯•æ–‡ä»¶"""
        test_root = self.project_root / "test" / "claude-enhancer"
        if not test_root.exists():
            print(f"âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_root}")
            return False

        test_categories = ["hooks", "workflows", "integration", "performance", "security"]
        all_exist = True

        for category in test_categories:
            category_path = test_root / category
            if category_path.exists():
                test_files = list(category_path.glob("test_*.py"))
                print(f"âœ… {category}: {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
            else:
                print(f"âŒ {category} ç›®å½•ä¸å­˜åœ¨")
                all_exist = False

        return all_exist

    def _check_hook_scripts(self) -> bool:
        """æ£€æŸ¥Hookè„šæœ¬"""
        hooks_dir = self.project_root / ".claude" / "hooks"
        if not hooks_dir.exists():
            print(f"âŒ Hooksç›®å½•ä¸å­˜åœ¨: {hooks_dir}")
            return False

        required_scripts = [
            "agent_validator.sh",
            "phase_manager.py"
        ]

        all_exist = True
        for script in required_scripts:
            script_path = hooks_dir / script
            if script_path.exists():
                print(f"âœ… {script} å­˜åœ¨")
            else:
                print(f"âŒ {script} ä¸å­˜åœ¨")
                all_exist = False

        return all_exist


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Claude Enhancer æµ‹è¯•è¿è¡Œå™¨")
    parser.add_argument("--categories", nargs="+",
                       choices=["hooks", "workflows", "integration", "performance", "security"],
                       help="è¦è¿è¡Œçš„æµ‹è¯•ç±»åˆ«")
    parser.add_argument("--sequential", action="store_true", help="é¡ºåºè¿è¡Œæµ‹è¯•ï¼ˆé»˜è®¤å¹¶è¡Œï¼‰")
    parser.add_argument("--validate-only", action="store_true", help="åªéªŒè¯ç¯å¢ƒï¼Œä¸è¿è¡Œæµ‹è¯•")
    parser.add_argument("--output", type=str, help="ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    # ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
    script_path = Path(__file__).resolve()
    project_root = script_path.parent.parent.parent

    print("ğŸ§ª Claude Enhancer æµ‹è¯•å¥—ä»¶")
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    print()

    # éªŒè¯æµ‹è¯•ç¯å¢ƒ
    validator = TestValidator(project_root)
    if not validator.validate_test_environment():
        sys.exit(1)

    if args.validate_only:
        print("âœ… ç¯å¢ƒéªŒè¯å®Œæˆ")
        return

    # è¿è¡Œæµ‹è¯•
    runner = TestRunner(project_root)

    try:
        results = runner.run_all_tests(
            parallel=not args.sequential,
            categories=args.categories
        )

        # ä¿å­˜ç»“æœ
        if args.output:
            output_path = Path(args.output)
        else:
            output_path = project_root / "test-results" / "claude-enhancer-results.json"

        runner.save_results(output_path)

        # æ ¹æ®æµ‹è¯•ç»“æœè®¾ç½®é€€å‡ºç 
        if results["overall_success"]:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•æˆåŠŸå®Œæˆï¼")
            sys.exit(0)
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•æ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()