#!/usr/bin/env python3
"""
Claude Enhancer å‹åŠ›æµ‹è¯•å¥—ä»¶
é«˜å¼ºåº¦ã€é«˜å‡†ç¡®æ€§çš„å‹åŠ›æµ‹è¯•ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨æé™æ¡ä»¶ä¸‹çš„ç¨³å®šæ€§
"""

import time
import threading
import concurrent.futures
import subprocess
import psutil
import tempfile
import shutil
import json
import random
import signal
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass, asdict
import queue
import multiprocessing


@dataclass
class StressTestResult:
    """å‹åŠ›æµ‹è¯•ç»“æœ"""

    test_name: str
    test_type: str
    duration: float
    total_operations: int
    successful_operations: int
    failed_operations: int
    operations_per_second: float
    peak_memory_mb: float
    peak_cpu_percent: float
    error_rate: float
    timestamp: str
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class SystemResourceMonitor:
    """ç³»ç»Ÿèµ„æºå®æ—¶ç›‘æ§"""

    def __init__(self, interval: float = 0.1):
        self.interval = interval
        self.monitoring = False
        self.metrics = {
            "cpu_percent": [],
            "memory_percent": [],
            "memory_mb": [],
            "disk_io_read": [],
            "disk_io_write": [],
            "network_io_sent": [],
            "network_io_recv": [],
            "process_count": [],
            "load_average": [],
        }
        self.monitor_thread = None

    def start_monitoring(self):
        """å¼€å§‹èµ„æºç›‘æ§"""
        self.monitoring = True
        self.metrics = {key: [] for key in self.metrics.keys()}

        def monitor():
            prev_disk_io = psutil.disk_io_counters()
            prev_net_io = psutil.net_io_counters()

            while self.monitoring:
                try:
                    # CPUä½¿ç”¨ç‡
                    cpu_percent = psutil.cpu_percent(interval=None)
                    self.metrics["cpu_percent"].append(cpu_percent)

                    # å†…å­˜ä½¿ç”¨
                    memory = psutil.virtual_memory()
                    self.metrics["memory_percent"].append(memory.percent)
                    self.metrics["memory_mb"].append(memory.used / 1024 / 1024)

                    # ç£ç›˜IO
                    current_disk_io = psutil.disk_io_counters()
                    if current_disk_io and prev_disk_io:
                        read_rate = (
                            current_disk_io.read_bytes - prev_disk_io.read_bytes
                        ) / self.interval
                        write_rate = (
                            current_disk_io.write_bytes - prev_disk_io.write_bytes
                        ) / self.interval
                        self.metrics["disk_io_read"].append(read_rate)
                        self.metrics["disk_io_write"].append(write_rate)
                        prev_disk_io = current_disk_io

                    # ç½‘ç»œIO
                    current_net_io = psutil.net_io_counters()
                    if current_net_io and prev_net_io:
                        sent_rate = (
                            current_net_io.bytes_sent - prev_net_io.bytes_sent
                        ) / self.interval
                        recv_rate = (
                            current_net_io.bytes_recv - prev_net_io.bytes_recv
                        ) / self.interval
                        self.metrics["network_io_sent"].append(sent_rate)
                        self.metrics["network_io_recv"].append(recv_rate)
                        prev_net_io = current_net_io

                    # è¿›ç¨‹æ•°é‡
                    process_count = len(psutil.pids())
                    self.metrics["process_count"].append(process_count)

                    # ç³»ç»Ÿè´Ÿè½½
                    if hasattr(os, "getloadavg"):
                        load_avg = os.getloadavg()[0]
                        self.metrics["load_average"].append(load_avg)

                    time.sleep(self.interval)

                except Exception:
                    pass

        self.monitor_thread = threading.Thread(target=monitor, daemon=True)
        self.monitor_thread.start()

    def stop_monitoring(self) -> Dict[str, float]:
        """åœæ­¢ç›‘æ§å¹¶è¿”å›ç»Ÿè®¡æ•°æ®"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2.0)

        stats = {}
        for key, values in self.metrics.items():
            if values:
                stats[f"{key}_avg"] = sum(values) / len(values)
                stats[f"{key}_max"] = max(values)
                stats[f"{key}_min"] = min(values)
                stats[f"{key}_samples"] = len(values)

        return stats


class HookStressTest:
    """Hookç³»ç»Ÿå‹åŠ›æµ‹è¯•"""

    def __init__(self, claude_dir: str = "/home/xx/dev/Perfect21/.claude"):
        self.claude_dir = Path(claude_dir)
        self.hooks_dir = self.claude_dir / "hooks"

    def rapid_fire_hook_test(
        self, duration: float = 30.0, concurrent_hooks: int = 5
    ) -> StressTestResult:
        """å¿«é€Ÿè¿ç»­Hookæ‰§è¡Œå‹åŠ›æµ‹è¯•"""
        if not self.hooks_dir.exists():
            return self._create_error_result(
                "rapid_fire_hooks", "hooks directory not found"
            )

        # æ‰¾åˆ°å¯ç”¨çš„Hookæ–‡ä»¶
        available_hooks = [
            h
            for h in self.hooks_dir.glob("*.sh")
            if h.name
            in ["performance_monitor.sh", "error_handler.sh", "quality_gate.sh"]
        ]

        if not available_hooks:
            return self._create_error_result(
                "rapid_fire_hooks", "no suitable hooks found"
            )

        monitor = SystemResourceMonitor()
        monitor.start_monitoring()

        start_time = time.perf_counter()
        end_time = start_time + duration

        total_operations = 0
        successful_operations = 0
        failed_operations = 0

        def execute_hook_burst():
            nonlocal total_operations, successful_operations, failed_operations

            while time.perf_counter() < end_time:
                # éšæœºé€‰æ‹©ä¸€ä¸ªHook
                hook = random.choice(available_hooks)

                try:
                    result = subprocess.run(
                        ["bash", str(hook), "--test"],
                        capture_output=True,
                        text=True,
                        timeout=5,
                        env={
                            "CLAUDE_TEST_MODE": "1",
                            "STRESS_TEST_MODE": "1",
                            "RAPID_FIRE_TEST": "1",
                        },
                    )

                    total_operations += 1
                    if result.returncode == 0:
                        successful_operations += 1
                    else:
                        failed_operations += 1

                except Exception:
                    total_operations += 1
                    failed_operations += 1

                # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡åº¦å ç”¨èµ„æº
                time.sleep(0.01)

        # å¯åŠ¨å¹¶å‘çº¿ç¨‹
        threads = []
        for _ in range(concurrent_hooks):
            thread = threading.Thread(target=execute_hook_burst)
            thread.start()
            threads.append(thread)

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()

        actual_duration = time.perf_counter() - start_time
        system_stats = monitor.stop_monitoring()

        operations_per_second = (
            total_operations / actual_duration if actual_duration > 0 else 0
        )
        error_rate = failed_operations / total_operations if total_operations > 0 else 0

        return StressTestResult(
            test_name="rapid_fire_hooks",
            test_type="concurrency",
            duration=actual_duration,
            total_operations=total_operations,
            successful_operations=successful_operations,
            failed_operations=failed_operations,
            operations_per_second=operations_per_second,
            peak_memory_mb=system_stats.get("memory_mb_max", 0),
            peak_cpu_percent=system_stats.get("cpu_percent_max", 0),
            error_rate=error_rate,
            timestamp=datetime.now().isoformat(),
            metadata={
                "concurrent_threads": concurrent_hooks,
                "available_hooks": len(available_hooks),
                "system_stats": system_stats,
            },
        )

    def hook_timeout_stress_test(self, iterations: int = 50) -> StressTestResult:
        """Hookè¶…æ—¶å‹åŠ›æµ‹è¯•"""
        if not self.hooks_dir.exists():
            return self._create_error_result(
                "hook_timeout_stress", "hooks directory not found"
            )

        monitor = SystemResourceMonitor()
        monitor.start_monitoring()

        start_time = time.perf_counter()

        total_operations = 0
        successful_operations = 0
        failed_operations = 0

        # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿæ…¢é€ŸHook
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".sh", delete=False
        ) as temp_hook:
            temp_hook.write(
                """#!/bin/bash
# æ¨¡æ‹Ÿæ…¢é€ŸHook
sleep_time=${1:-0.5}
sleep $sleep_time
echo "Slow hook completed after ${sleep_time}s"
exit 0
"""
            )
            temp_hook_path = Path(temp_hook.name)
            os.chmod(temp_hook_path, 0o755)

        try:
            for i in range(iterations):
                # éšæœºå»¶è¿Ÿæ—¶é—´ï¼Œæµ‹è¯•è¶…æ—¶å¤„ç†
                sleep_time = random.uniform(0.1, 2.0)

                try:
                    result = subprocess.run(
                        ["bash", str(temp_hook_path), str(sleep_time)],
                        capture_output=True,
                        text=True,
                        timeout=1.0,  # 1ç§’è¶…æ—¶
                        env={"TIMEOUT_STRESS_TEST": "1"},
                    )

                    total_operations += 1
                    if result.returncode == 0:
                        successful_operations += 1
                    else:
                        failed_operations += 1

                except subprocess.TimeoutExpired:
                    total_operations += 1
                    failed_operations += 1  # è¶…æ—¶è¢«è®¤ä¸ºæ˜¯å¤±è´¥

                except Exception:
                    total_operations += 1
                    failed_operations += 1

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_hook_path.exists():
                temp_hook_path.unlink()

        actual_duration = time.perf_counter() - start_time
        system_stats = monitor.stop_monitoring()

        operations_per_second = (
            total_operations / actual_duration if actual_duration > 0 else 0
        )
        error_rate = failed_operations / total_operations if total_operations > 0 else 0

        return StressTestResult(
            test_name="hook_timeout_stress",
            test_type="timeout_handling",
            duration=actual_duration,
            total_operations=total_operations,
            successful_operations=successful_operations,
            failed_operations=failed_operations,
            operations_per_second=operations_per_second,
            peak_memory_mb=system_stats.get("memory_mb_max", 0),
            peak_cpu_percent=system_stats.get("cpu_percent_max", 0),
            error_rate=error_rate,
            timestamp=datetime.now().isoformat(),
            metadata={
                "iterations": iterations,
                "timeout_threshold": 1.0,
                "system_stats": system_stats,
            },
        )

    def memory_pressure_test(self, duration: float = 60.0) -> StressTestResult:
        """å†…å­˜å‹åŠ›æµ‹è¯•"""
        monitor = SystemResourceMonitor()
        monitor.start_monitoring()

        start_time = time.perf_counter()
        end_time = start_time + duration

        total_operations = 0
        successful_operations = 0
        failed_operations = 0

        # å†…å­˜å‹åŠ›ç”Ÿæˆå™¨
        memory_blocks = []

        def memory_pressure_worker():
            nonlocal total_operations, successful_operations, failed_operations

            while time.perf_counter() < end_time:
                try:
                    # åˆ†é…å†…å­˜å—ï¼ˆæ¯æ¬¡10MBï¼‰
                    block_size = 10 * 1024 * 1024  # 10MB
                    memory_block = bytearray(block_size)

                    # å†™å…¥ä¸€äº›æ•°æ®ä»¥ç¡®ä¿å†…å­˜çœŸæ­£è¢«ä½¿ç”¨
                    for i in range(0, block_size, 4096):
                        memory_block[i] = random.randint(0, 255)

                    memory_blocks.append(memory_block)
                    total_operations += 1
                    successful_operations += 1

                    # å½“å†…å­˜å—è¿‡å¤šæ—¶ï¼Œé‡Šæ”¾ä¸€äº›
                    if len(memory_blocks) > 50:  # é™åˆ¶åœ¨500MBå·¦å³
                        memory_blocks.pop(0)

                    time.sleep(0.1)

                except Exception:
                    total_operations += 1
                    failed_operations += 1
                    time.sleep(0.1)

        # åŒæ—¶è¿è¡ŒHookæµ‹è¯•
        def hook_under_pressure():
            if not self.hooks_dir.exists():
                return

            available_hooks = list(self.hooks_dir.glob("*.sh"))[:3]  # é™åˆ¶Hookæ•°é‡

            while time.perf_counter() < end_time:
                if available_hooks:
                    hook = random.choice(available_hooks)
                    try:
                        subprocess.run(
                            ["bash", str(hook), "--test"],
                            capture_output=True,
                            text=True,
                            timeout=2,
                            env={"MEMORY_PRESSURE_TEST": "1"},
                        )
                    except Exception:
                        pass

                time.sleep(1)

        # å¯åŠ¨å†…å­˜å‹åŠ›å’ŒHookæµ‹è¯•
        memory_thread = threading.Thread(target=memory_pressure_worker)
        hook_thread = threading.Thread(target=hook_under_pressure)

        memory_thread.start()
        hook_thread.start()

        memory_thread.join()
        hook_thread.join()

        # æ¸…ç†å†…å­˜
        memory_blocks.clear()

        actual_duration = time.perf_counter() - start_time
        system_stats = monitor.stop_monitoring()

        operations_per_second = (
            total_operations / actual_duration if actual_duration > 0 else 0
        )
        error_rate = failed_operations / total_operations if total_operations > 0 else 0

        return StressTestResult(
            test_name="memory_pressure",
            test_type="resource_stress",
            duration=actual_duration,
            total_operations=total_operations,
            successful_operations=successful_operations,
            failed_operations=failed_operations,
            operations_per_second=operations_per_second,
            peak_memory_mb=system_stats.get("memory_mb_max", 0),
            peak_cpu_percent=system_stats.get("cpu_percent_max", 0),
            error_rate=error_rate,
            timestamp=datetime.now().isoformat(),
            metadata={
                "peak_memory_blocks": len(memory_blocks),
                "system_stats": system_stats,
            },
        )

    def _create_error_result(self, test_name: str, error_msg: str) -> StressTestResult:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return StressTestResult(
            test_name=test_name,
            test_type="error",
            duration=0.0,
            total_operations=0,
            successful_operations=0,
            failed_operations=1,
            operations_per_second=0.0,
            peak_memory_mb=0.0,
            peak_cpu_percent=0.0,
            error_rate=1.0,
            timestamp=datetime.now().isoformat(),
            metadata={"error": error_msg},
        )


class FileSystemStressTest:
    """æ–‡ä»¶ç³»ç»Ÿå‹åŠ›æµ‹è¯•"""

    def __init__(self, claude_dir: str = "/home/xx/dev/Perfect21/.claude"):
        self.claude_dir = Path(claude_dir)

    def rapid_file_operations_test(self, duration: float = 30.0) -> StressTestResult:
        """å¿«é€Ÿæ–‡ä»¶æ“ä½œå‹åŠ›æµ‹è¯•"""
        monitor = SystemResourceMonitor()
        monitor.start_monitoring()

        start_time = time.perf_counter()
        end_time = start_time + duration

        total_operations = 0
        successful_operations = 0
        failed_operations = 0

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            def file_operations_worker():
                nonlocal total_operations, successful_operations, failed_operations

                file_counter = 0
                while time.perf_counter() < end_time:
                    try:
                        # åˆ›å»ºæ–‡ä»¶
                        file_path = temp_path / f"test_file_{file_counter}.txt"
                        file_content = f"Test content {file_counter}" * random.randint(
                            10, 100
                        )

                        file_path.write_text(file_content)
                        total_operations += 1

                        # è¯»å–æ–‡ä»¶
                        content = file_path.read_text()
                        total_operations += 1

                        # ä¿®æ”¹æ–‡ä»¶
                        file_path.write_text(content + " modified")
                        total_operations += 1

                        # åˆ é™¤æ–‡ä»¶
                        file_path.unlink()
                        total_operations += 1

                        successful_operations += 4
                        file_counter += 1

                        # é¿å…åˆ›å»ºè¿‡å¤šæ–‡ä»¶
                        if file_counter % 10 == 0:
                            time.sleep(0.01)

                    except Exception:
                        failed_operations += 1
                        total_operations += 1

            # å¯åŠ¨å¤šä¸ªæ–‡ä»¶æ“ä½œçº¿ç¨‹
            threads = []
            for _ in range(3):
                thread = threading.Thread(target=file_operations_worker)
                thread.start()
                threads.append(thread)

            for thread in threads:
                thread.join()

        actual_duration = time.perf_counter() - start_time
        system_stats = monitor.stop_monitoring()

        operations_per_second = (
            total_operations / actual_duration if actual_duration > 0 else 0
        )
        error_rate = failed_operations / total_operations if total_operations > 0 else 0

        return StressTestResult(
            test_name="rapid_file_operations",
            test_type="file_system_stress",
            duration=actual_duration,
            total_operations=total_operations,
            successful_operations=successful_operations,
            failed_operations=failed_operations,
            operations_per_second=operations_per_second,
            peak_memory_mb=system_stats.get("memory_mb_max", 0),
            peak_cpu_percent=system_stats.get("cpu_percent_max", 0),
            error_rate=error_rate,
            timestamp=datetime.now().isoformat(),
            metadata={"concurrent_threads": 3, "system_stats": system_stats},
        )


class ProcessStressTest:
    """è¿›ç¨‹å‹åŠ›æµ‹è¯•"""

    def __init__(self, claude_dir: str = "/home/xx/dev/Perfect21/.claude"):
        self.claude_dir = Path(claude_dir)

    def process_spawn_stress_test(
        self, duration: float = 30.0, max_processes: int = 20
    ) -> StressTestResult:
        """è¿›ç¨‹ç”Ÿæˆå‹åŠ›æµ‹è¯•"""
        monitor = SystemResourceMonitor()
        monitor.start_monitoring()

        start_time = time.perf_counter()
        end_time = start_time + duration

        total_operations = 0
        successful_operations = 0
        failed_operations = 0

        active_processes = []

        def process_manager():
            nonlocal total_operations, successful_operations, failed_operations

            while time.perf_counter() < end_time:
                try:
                    # æ¸…ç†å·²å®Œæˆçš„è¿›ç¨‹
                    active_processes[:] = [
                        p for p in active_processes if p.poll() is None
                    ]

                    # å¦‚æœè¿›ç¨‹æ•°é‡æœªè¾¾åˆ°ä¸Šé™ï¼Œåˆ›å»ºæ–°è¿›ç¨‹
                    if len(active_processes) < max_processes:
                        # åˆ›å»ºç®€å•çš„æµ‹è¯•è¿›ç¨‹
                        process = subprocess.Popen(
                            ["bash", "-c", "sleep 0.5; echo 'test process'"],
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE,
                        )
                        active_processes.append(process)
                        total_operations += 1
                        successful_operations += 1

                    time.sleep(0.1)

                except Exception:
                    total_operations += 1
                    failed_operations += 1

        # è¿è¡Œè¿›ç¨‹ç®¡ç†å™¨
        process_thread = threading.Thread(target=process_manager)
        process_thread.start()
        process_thread.join()

        # æ¸…ç†å‰©ä½™è¿›ç¨‹
        for process in active_processes:
            try:
                process.terminate()
                process.wait(timeout=2)
            except Exception:
                try:
                    process.kill()
                    process.wait(timeout=1)
                except Exception:
                    pass

        actual_duration = time.perf_counter() - start_time
        system_stats = monitor.stop_monitoring()

        operations_per_second = (
            total_operations / actual_duration if actual_duration > 0 else 0
        )
        error_rate = failed_operations / total_operations if total_operations > 0 else 0

        return StressTestResult(
            test_name="process_spawn_stress",
            test_type="process_stress",
            duration=actual_duration,
            total_operations=total_operations,
            successful_operations=successful_operations,
            failed_operations=failed_operations,
            operations_per_second=operations_per_second,
            peak_memory_mb=system_stats.get("memory_mb_max", 0),
            peak_cpu_percent=system_stats.get("cpu_percent_max", 0),
            error_rate=error_rate,
            timestamp=datetime.now().isoformat(),
            metadata={
                "max_concurrent_processes": max_processes,
                "final_active_processes": len(active_processes),
                "system_stats": system_stats,
            },
        )


class ComprehensiveStressTestSuite:
    """ç»¼åˆå‹åŠ›æµ‹è¯•å¥—ä»¶"""

    def __init__(self, claude_dir: str = "/home/xx/dev/Perfect21/.claude"):
        self.claude_dir = claude_dir
        self.hook_stress = HookStressTest(claude_dir)
        self.fs_stress = FileSystemStressTest(claude_dir)
        self.process_stress = ProcessStressTest(claude_dir)

    def run_full_stress_test_suite(self, test_duration: float = 60.0) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å‹åŠ›æµ‹è¯•å¥—ä»¶"""
        print("ğŸ’ª å¼€å§‹è¿è¡Œç»¼åˆå‹åŠ›æµ‹è¯•å¥—ä»¶...")
        print("=" * 80)

        results = []

        # è®°å½•ç³»ç»Ÿåˆå§‹çŠ¶æ€
        initial_stats = {
            "cpu_count": psutil.cpu_count(),
            "memory_total_gb": psutil.virtual_memory().total / (1024**3),
            "memory_available_gb": psutil.virtual_memory().available / (1024**3),
            "disk_free_gb": psutil.disk_usage("/").free / (1024**3),
            "load_average": os.getloadavg() if hasattr(os, "getloadavg") else None,
        }

        # 1. Hookç³»ç»Ÿå‹åŠ›æµ‹è¯•
        print("ğŸ”— è¿è¡ŒHookç³»ç»Ÿå‹åŠ›æµ‹è¯•...")

        print("  - å¿«é€Ÿè¿ç»­Hookæ‰§è¡Œæµ‹è¯•...")
        rapid_fire_result = self.hook_stress.rapid_fire_hook_test(
            duration=test_duration / 4
        )
        results.append(rapid_fire_result)

        print("  - Hookè¶…æ—¶å‹åŠ›æµ‹è¯•...")
        timeout_result = self.hook_stress.hook_timeout_stress_test(iterations=20)
        results.append(timeout_result)

        print("  - å†…å­˜å‹åŠ›ä¸‹çš„Hookæµ‹è¯•...")
        memory_pressure_result = self.hook_stress.memory_pressure_test(
            duration=test_duration / 3
        )
        results.append(memory_pressure_result)

        # 2. æ–‡ä»¶ç³»ç»Ÿå‹åŠ›æµ‹è¯•
        print("ğŸ“ è¿è¡Œæ–‡ä»¶ç³»ç»Ÿå‹åŠ›æµ‹è¯•...")
        fs_result = self.fs_stress.rapid_file_operations_test(
            duration=test_duration / 4
        )
        results.append(fs_result)

        # 3. è¿›ç¨‹å‹åŠ›æµ‹è¯•
        print("âš™ï¸  è¿è¡Œè¿›ç¨‹å‹åŠ›æµ‹è¯•...")
        process_result = self.process_stress.process_spawn_stress_test(
            duration=test_duration / 4
        )
        results.append(process_result)

        # 4. ç»¼åˆåˆ†æ
        print("ğŸ“Š åˆ†æå‹åŠ›æµ‹è¯•ç»“æœ...")
        analysis = self._analyze_stress_results(results, initial_stats)

        # 5. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        final_report = {
            "timestamp": datetime.now().isoformat(),
            "test_duration": test_duration,
            "initial_system_stats": initial_stats,
            "stress_test_results": [asdict(result) for result in results],
            "analysis": analysis,
            "recommendations": self._generate_stress_recommendations(results, analysis),
        }

        print("âœ… å‹åŠ›æµ‹è¯•å¥—ä»¶æ‰§è¡Œå®Œæˆ!")
        return final_report

    def _analyze_stress_results(
        self, results: List[StressTestResult], initial_stats: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ†æå‹åŠ›æµ‹è¯•ç»“æœ"""
        analysis = {
            "overall_summary": {},
            "performance_metrics": {},
            "stress_tolerance": {},
            "resource_usage": {},
            "stability_assessment": {},
        }

        successful_results = [r for r in results if r.successful_operations > 0]

        if successful_results:
            # æ€»ä½“æ‘˜è¦
            total_ops = sum(r.total_operations for r in results)
            total_successful = sum(r.successful_operations for r in results)
            total_failed = sum(r.failed_operations for r in results)

            analysis["overall_summary"] = {
                "total_tests": len(results),
                "successful_tests": len(successful_results),
                "total_operations": total_ops,
                "total_successful_operations": total_successful,
                "total_failed_operations": total_failed,
                "overall_success_rate": total_successful / total_ops
                if total_ops > 0
                else 0,
                "average_error_rate": sum(r.error_rate for r in results) / len(results),
            }

            # æ€§èƒ½æŒ‡æ ‡
            ops_per_sec = [r.operations_per_second for r in successful_results]
            durations = [r.duration for r in successful_results]

            analysis["performance_metrics"] = {
                "avg_operations_per_second": sum(ops_per_sec) / len(ops_per_sec)
                if ops_per_sec
                else 0,
                "max_operations_per_second": max(ops_per_sec) if ops_per_sec else 0,
                "min_operations_per_second": min(ops_per_sec) if ops_per_sec else 0,
                "avg_test_duration": sum(durations) / len(durations)
                if durations
                else 0,
                "total_test_time": sum(durations),
            }

            # èµ„æºä½¿ç”¨åˆ†æ
            peak_memory = [r.peak_memory_mb for r in successful_results]
            peak_cpu = [r.peak_cpu_percent for r in successful_results]

            analysis["resource_usage"] = {
                "peak_memory_usage_mb": max(peak_memory) if peak_memory else 0,
                "avg_memory_usage_mb": sum(peak_memory) / len(peak_memory)
                if peak_memory
                else 0,
                "peak_cpu_usage_percent": max(peak_cpu) if peak_cpu else 0,
                "avg_cpu_usage_percent": sum(peak_cpu) / len(peak_cpu)
                if peak_cpu
                else 0,
                "memory_efficiency": (
                    initial_stats.get("memory_available_gb", 1) * 1024
                )
                / (max(peak_memory) if peak_memory else 1),
            }

            # å‹åŠ›å®¹å¿åº¦è¯„ä¼°
            error_rates = [r.error_rate for r in results]
            high_stress_tests = [
                r for r in results if r.test_type in ["concurrency", "resource_stress"]
            ]

            analysis["stress_tolerance"] = {
                "max_error_rate": max(error_rates) if error_rates else 0,
                "high_stress_success_rate": sum(
                    r.successful_operations for r in high_stress_tests
                )
                / sum(r.total_operations for r in high_stress_tests)
                if high_stress_tests
                else 0,
                "stability_score": 1 - (sum(error_rates) / len(error_rates))
                if error_rates
                else 0,
            }

            # ç¨³å®šæ€§è¯„ä¼°
            timeout_tests = [r for r in results if r.test_type == "timeout_handling"]
            concurrency_tests = [r for r in results if r.test_type == "concurrency"]

            analysis["stability_assessment"] = {
                "timeout_handling_score": sum(
                    r.successful_operations for r in timeout_tests
                )
                / sum(r.total_operations for r in timeout_tests)
                if timeout_tests
                else 0,
                "concurrency_stability": sum(
                    r.successful_operations for r in concurrency_tests
                )
                / sum(r.total_operations for r in concurrency_tests)
                if concurrency_tests
                else 0,
                "overall_stability_grade": self._calculate_stability_grade(analysis),
            }

        return analysis

    def _calculate_stability_grade(self, analysis: Dict[str, Any]) -> str:
        """è®¡ç®—ç¨³å®šæ€§ç­‰çº§"""
        try:
            overall_success = analysis["overall_summary"]["overall_success_rate"]
            stability_score = analysis["stress_tolerance"]["stability_score"]

            combined_score = (overall_success + stability_score) / 2

            if combined_score >= 0.95:
                return "A+ (Excellent)"
            elif combined_score >= 0.90:
                return "A (Very Good)"
            elif combined_score >= 0.80:
                return "B (Good)"
            elif combined_score >= 0.70:
                return "C (Fair)"
            elif combined_score >= 0.60:
                return "D (Poor)"
            else:
                return "F (Critical Issues)"
        except Exception:
            return "Unknown"

    def _generate_stress_recommendations(
        self, results: List[StressTestResult], analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå‹åŠ›æµ‹è¯•å»ºè®®"""
        recommendations = []

        try:
            overall_success_rate = analysis["overall_summary"]["overall_success_rate"]
            avg_error_rate = analysis["overall_summary"]["average_error_rate"]
            stability_score = analysis["stress_tolerance"]["stability_score"]

            # åŸºäºæˆåŠŸç‡çš„å»ºè®®
            if overall_success_rate < 0.8:
                recommendations.append(
                    {
                        "category": "System Stability",
                        "priority": "CRITICAL",
                        "issue": f"å‹åŠ›æµ‹è¯•æ•´ä½“æˆåŠŸç‡è¿‡ä½: {overall_success_rate:.1%}",
                        "recommendation": "éœ€è¦ç«‹å³è°ƒæŸ¥ç³»ç»Ÿç¨³å®šæ€§é—®é¢˜ï¼Œæ£€æŸ¥èµ„æºé…ç½®å’Œé”™è¯¯å¤„ç†æœºåˆ¶",
                        "action_items": ["æ£€æŸ¥ç³»ç»Ÿèµ„æºé™åˆ¶", "ä¼˜åŒ–é”™è¯¯å¤„ç†é€»è¾‘", "å¢åŠ é‡è¯•æœºåˆ¶", "è€ƒè™‘å¢åŠ ç³»ç»Ÿèµ„æº"],
                    }
                )

            # åŸºäºé”™è¯¯ç‡çš„å»ºè®®
            if avg_error_rate > 0.1:
                recommendations.append(
                    {
                        "category": "Error Handling",
                        "priority": "HIGH",
                        "issue": f"å¹³å‡é”™è¯¯ç‡è¾ƒé«˜: {avg_error_rate:.1%}",
                        "recommendation": "æ”¹å–„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶",
                        "action_items": ["åˆ†æå¸¸è§é”™è¯¯æ¨¡å¼", "å®æ–½æ›´å¥½çš„é”™è¯¯æ¢å¤ç­–ç•¥", "å¢åŠ ç›‘æ§å’Œå‘Šè­¦"],
                    }
                )

            # åŸºäºèµ„æºä½¿ç”¨çš„å»ºè®®
            resource_usage = analysis.get("resource_usage", {})
            peak_memory = resource_usage.get("peak_memory_usage_mb", 0)
            peak_cpu = resource_usage.get("peak_cpu_usage_percent", 0)

            if peak_memory > 1000:  # è¶…è¿‡1GB
                recommendations.append(
                    {
                        "category": "Memory Management",
                        "priority": "MEDIUM",
                        "issue": f"å³°å€¼å†…å­˜ä½¿ç”¨è¿‡é«˜: {peak_memory:.1f}MB",
                        "recommendation": "ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå®æ–½å†…å­˜ç®¡ç†ç­–ç•¥",
                        "action_items": ["è¯†åˆ«å†…å­˜æ³„æ¼", "ä¼˜åŒ–æ•°æ®ç»“æ„", "å®æ–½å†…å­˜æ± ", "å¢åŠ å†…å­˜ç›‘æ§"],
                    }
                )

            if peak_cpu > 90:
                recommendations.append(
                    {
                        "category": "CPU Performance",
                        "priority": "MEDIUM",
                        "issue": f"å³°å€¼CPUä½¿ç”¨ç‡è¿‡é«˜: {peak_cpu:.1f}%",
                        "recommendation": "ä¼˜åŒ–CPUå¯†é›†å‹æ“ä½œï¼Œè€ƒè™‘è´Ÿè½½å‡è¡¡",
                        "action_items": ["è¯†åˆ«CPUç“¶é¢ˆ", "ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦", "å®æ–½å¼‚æ­¥å¤„ç†", "è€ƒè™‘å¤šè¿›ç¨‹æ¶æ„"],
                    }
                )

            # åŸºäºç¨³å®šæ€§çš„å»ºè®®
            if stability_score < 0.8:
                recommendations.append(
                    {
                        "category": "System Reliability",
                        "priority": "HIGH",
                        "issue": f"ç³»ç»Ÿç¨³å®šæ€§åˆ†æ•°è¾ƒä½: {stability_score:.2f}",
                        "recommendation": "å…¨é¢æå‡ç³»ç»Ÿå¯é æ€§å’Œå®¹é”™èƒ½åŠ›",
                        "action_items": ["å®æ–½ç†”æ–­å™¨æ¨¡å¼", "å¢åŠ å¥åº·æ£€æŸ¥", "æ”¹è¿›è¶…æ—¶å¤„ç†", "å¢åŠ ç³»ç»ŸéŸ§æ€§"],
                    }
                )

        except Exception as e:
            recommendations.append(
                {
                    "category": "Analysis Error",
                    "priority": "LOW",
                    "issue": f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                    "recommendation": "æ£€æŸ¥åˆ†æé€»è¾‘å¹¶ä¿®å¤é”™è¯¯",
                }
            )

        return recommendations

    def save_stress_test_report(
        self, report: Dict[str, Any], filename: str = "stress_test_report.json"
    ) -> Path:
        """ä¿å­˜å‹åŠ›æµ‹è¯•æŠ¥å‘Š"""
        report_path = (
            Path(self.claude_dir).parent / "test" / "claude_enhancer" / filename
        )
        report_path.parent.mkdir(parents=True, exist_ok=True)

        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“„ å‹åŠ›æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        return report_path


def main():
    """ä¸»å‡½æ•°"""
    try:
        suite = ComprehensiveStressTestSuite()

        # è¿è¡Œå‹åŠ›æµ‹è¯•ï¼ˆå¯ä»¥è°ƒæ•´æŒç»­æ—¶é—´ï¼‰
        test_duration = 120.0  # 2åˆ†é’Ÿçš„å‹åŠ›æµ‹è¯•
        report = suite.run_full_stress_test_suite(test_duration)

        # ä¿å­˜æŠ¥å‘Š
        report_path = suite.save_stress_test_report(report)

        # æ‰“å°æ‘˜è¦
        print("\n" + "=" * 80)
        print("ğŸ’ª å‹åŠ›æµ‹è¯•æ‘˜è¦")
        print("=" * 80)

        summary = report.get("analysis", {}).get("overall_summary", {})
        if summary:
            print(f"æ€»æµ‹è¯•æ•°é‡: {summary.get('total_tests', 0)}")
            print(f"æˆåŠŸæµ‹è¯•: {summary.get('successful_tests', 0)}")
            print(f"æ€»æ“ä½œæ•°: {summary.get('total_operations', 0)}")
            print(f"æˆåŠŸæ“ä½œ: {summary.get('total_successful_operations', 0)}")
            print(f"æ•´ä½“æˆåŠŸç‡: {summary.get('overall_success_rate', 0):.1%}")
            print(f"å¹³å‡é”™è¯¯ç‡: {summary.get('average_error_rate', 0):.1%}")

        # æ€§èƒ½æŒ‡æ ‡
        perf_metrics = report.get("analysis", {}).get("performance_metrics", {})
        if perf_metrics:
            print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
            print(f"å¹³å‡æ“ä½œ/ç§’: {perf_metrics.get('avg_operations_per_second', 0):.1f}")
            print(f"æœ€é«˜æ“ä½œ/ç§’: {perf_metrics.get('max_operations_per_second', 0):.1f}")

        # èµ„æºä½¿ç”¨
        resource_usage = report.get("analysis", {}).get("resource_usage", {})
        if resource_usage:
            print(f"\nğŸ“Š èµ„æºä½¿ç”¨:")
            print(f"å³°å€¼å†…å­˜: {resource_usage.get('peak_memory_usage_mb', 0):.1f}MB")
            print(f"å³°å€¼CPU: {resource_usage.get('peak_cpu_usage_percent', 0):.1f}%")

        # ç¨³å®šæ€§è¯„ä¼°
        stability = report.get("analysis", {}).get("stability_assessment", {})
        if stability:
            print(f"\nğŸ›¡ï¸  ç¨³å®šæ€§è¯„ä¼°:")
            print(f"ç¨³å®šæ€§ç­‰çº§: {stability.get('overall_stability_grade', 'Unknown')}")

        # å»ºè®®
        recommendations = report.get("recommendations", [])
        if recommendations:
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®® ({len(recommendations)}æ¡):")
            for rec in recommendations[:3]:  # æ˜¾ç¤ºå‰3æ¡æœ€é‡è¦çš„å»ºè®®
                print(f"  [{rec['priority']}] {rec['issue']}")

        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
        return True

    except Exception as e:
        print(f"âŒ å‹åŠ›æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
