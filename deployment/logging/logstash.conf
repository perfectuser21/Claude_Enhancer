# =============================================================================
# Logstash Configuration for Claude Enhancer 5.1
# Centralized log processing with filtering, parsing, and enrichment
# =============================================================================

input {
  # File inputs for application logs
  file {
    path => "/var/log/app/*.log"
    start_position => "beginning"
    tags => ["application"]
    type => "application"
    codec => "json"
  }

  # Nginx access logs
  file {
    path => "/var/log/nginx/access.log"
    start_position => "beginning"
    tags => ["nginx", "access"]
    type => "nginx_access"
  }

  # Nginx error logs
  file {
    path => "/var/log/nginx/error.log"
    start_position => "beginning"
    tags => ["nginx", "error"]
    type => "nginx_error"
  }

  # Docker container logs
  docker {
    host => "unix:///var/run/docker.sock"
    start_position => "beginning"
    tags => ["docker"]
  }

  # Syslog input for system logs
  syslog {
    port => 514
    tags => ["syslog"]
  }

  # Beats input for metrics
  beats {
    port => 5044
    tags => ["beats"]
  }
}

filter {
  # ===========================================================================
  # Common Filters
  # ===========================================================================

  # Add timestamp if missing
  if ![timestamp] {
    mutate {
      add_field => { "timestamp" => "%{@timestamp}" }
    }
  }

  # Add environment information
  mutate {
    add_field => {
      "environment" => "production"
      "service" => "claude-enhancer"
      "version" => "5.1.0"
    }
  }

  # ===========================================================================
  # Application Log Processing
  # ===========================================================================
  if [type] == "application" {
    # Parse JSON structured logs
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
        target => "app"
      }
    }

    # Extract log level
    if [app][level] {
      mutate {
        add_field => { "log_level" => "%{[app][level]}" }
      }
    }

    # Extract request ID for tracing
    if [app][request_id] {
      mutate {
        add_field => { "trace_id" => "%{[app][request_id]}" }
      }
    }

    # Parse agent execution logs
    if [app][component] == "agent" {
      mutate {
        add_field => {
          "agent_type" => "%{[app][agent_type]}"
          "agent_id" => "%{[app][agent_id]}"
          "execution_id" => "%{[app][execution_id]}"
        }
      }

      # Convert execution time to number
      if [app][execution_time] {
        mutate {
          convert => { "[app][execution_time]" => "float" }
        }
      }
    }

    # Parse workflow logs
    if [app][component] == "workflow" {
      mutate {
        add_field => {
          "workflow_phase" => "%{[app][phase]}"
          "workflow_id" => "%{[app][workflow_id]}"
        }
      }
    }

    # Parse API request logs
    if [app][component] == "api" {
      mutate {
        add_field => {
          "api_endpoint" => "%{[app][endpoint]}"
          "api_method" => "%{[app][method]}"
          "api_status" => "%{[app][status_code]}"
          "api_response_time" => "%{[app][response_time]}"
        }
      }

      # Convert numeric fields
      mutate {
        convert => {
          "api_status" => "integer"
          "api_response_time" => "float"
        }
      }
    }

    # Error detection and classification
    if [log_level] in ["ERROR", "CRITICAL", "FATAL"] {
      mutate {
        add_field => { "is_error" => "true" }
        add_tag => ["error"]
      }

      # Extract error details
      if [app][error] {
        mutate {
          add_field => {
            "error_type" => "%{[app][error][type]}"
            "error_message" => "%{[app][error][message]}"
            "error_stack" => "%{[app][error][stack]}"
          }
        }
      }
    }
  }

  # ===========================================================================
  # Nginx Log Processing
  # ===========================================================================
  if [type] == "nginx_access" {
    grok {
      match => {
        "message" => '%{IPORHOST:remote_addr} - %{DATA:remote_user} \[%{HTTPDATE:time_local}\] "%{WORD:method} %{DATA:request_uri} HTTP/%{NUMBER:http_version}" %{INT:status} %{INT:body_bytes_sent} "%{DATA:http_referer}" "%{DATA:http_user_agent}" "%{DATA:http_x_forwarded_for}"'
      }
    }

    # Convert numeric fields
    mutate {
      convert => {
        "status" => "integer"
        "body_bytes_sent" => "integer"
        "http_version" => "float"
      }
    }

    # Parse timestamp
    date {
      match => [ "time_local", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }

    # Extract response time if available
    if [upstream_response_time] {
      mutate {
        convert => { "upstream_response_time" => "float" }
      }
    }

    # Classify request types
    if [request_uri] =~ "^/api/" {
      mutate { add_tag => ["api_request"] }
    } else if [request_uri] =~ "^/static/" {
      mutate { add_tag => ["static_request"] }
    } else if [request_uri] =~ "^/health" {
      mutate { add_tag => ["health_check"] }
    }

    # Error classification
    if [status] >= 400 {
      mutate { add_tag => ["http_error"] }
    }
    if [status] >= 500 {
      mutate { add_tag => ["server_error"] }
    }
  }

  if [type] == "nginx_error" {
    grok {
      match => {
        "message" => "(?<timestamp>%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME}) \[%{LOGLEVEL:log_level}\] %{POSINT:pid}#%{NUMBER:tid}: %{GREEDYDATA:error_message}"
      }
    }

    # Parse timestamp
    date {
      match => [ "timestamp", "yyyy/MM/dd HH:mm:ss" ]
    }

    mutate { add_tag => ["nginx_error"] }
  }

  # ===========================================================================
  # Docker Log Processing
  # ===========================================================================
  if "docker" in [tags] {
    # Extract container information
    if [docker] {
      mutate {
        add_field => {
          "container_name" => "%{[docker][name]}"
          "container_id" => "%{[docker][id]}"
          "container_image" => "%{[docker][image]}"
        }
      }
    }

    # Parse JSON logs from containers
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
        target => "container_log"
      }
    }
  }

  # ===========================================================================
  # Security Log Processing
  # ===========================================================================

  # Detect potential security events
  if [message] =~ /(?i)(failed login|authentication failed|unauthorized|forbidden|sql injection|xss|csrf)/ {
    mutate {
      add_tag => ["security_event"]
      add_field => { "security_alert" => "true" }
    }
  }

  # Detect rate limiting
  if [api_status] == 429 or [status] == 429 {
    mutate {
      add_tag => ["rate_limited"]
    }
  }

  # ===========================================================================
  # Performance Metrics Extraction
  # ===========================================================================

  # Extract performance metrics from logs
  if [api_response_time] {
    if [api_response_time] > 2000 {
      mutate { add_tag => ["slow_request"] }
    }
    if [api_response_time] > 5000 {
      mutate { add_tag => ["very_slow_request"] }
    }
  }

  # ===========================================================================
  # Data Enrichment
  # ===========================================================================

  # GeoIP enrichment for external IPs
  if [remote_addr] and [remote_addr] !~ /^(10\.|192\.168\.|172\.(1[6-9]|2[0-9]|3[0-1])\.)/ {
    geoip {
      source => "remote_addr"
      target => "geoip"
    }
  }

  # User agent parsing
  if [http_user_agent] {
    useragent {
      source => "http_user_agent"
      target => "user_agent"
    }
  }

  # ===========================================================================
  # Final Processing
  # ===========================================================================

  # Remove unwanted fields
  mutate {
    remove_field => ["host", "beat", "input", "prospector", "offset"]
  }

  # Add final timestamp
  mutate {
    add_field => { "processed_at" => "%{@timestamp}" }
  }
}

output {
  # ===========================================================================
  # Elasticsearch Output
  # ===========================================================================
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "claude-enhancer-logs-%{+YYYY.MM.dd}"
    template_name => "claude-enhancer"
    template_pattern => "claude-enhancer-*"
    template => "/usr/share/logstash/templates/claude-enhancer-template.json"
  }

  # ===========================================================================
  # Conditional Outputs
  # ===========================================================================

  # Send error logs to separate index
  if "error" in [tags] or "server_error" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "claude-enhancer-errors-%{+YYYY.MM.dd}"
    }
  }

  # Send security events to security index
  if "security_event" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "claude-enhancer-security-%{+YYYY.MM.dd}"
    }
  }

  # Send performance logs to metrics index
  if "slow_request" in [tags] or "very_slow_request" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "claude-enhancer-performance-%{+YYYY.MM.dd}"
    }
  }

  # ===========================================================================
  # Debug Output (remove in production)
  # ===========================================================================
  # stdout {
  #   codec => rubydebug
  # }
}