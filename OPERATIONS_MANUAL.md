# ğŸ› ï¸ Claude Enhancer è¿ç»´æ‰‹å†Œ

> æ—¥å¸¸è¿ç»´æ“ä½œæŒ‡å—ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œ

## ğŸ“‹ è¿ç»´æ‰‹å†Œæ¦‚è§ˆ

### ğŸ¯ è¿ç»´ç›®æ ‡
- **ç³»ç»Ÿå¯ç”¨æ€§**: 99.9%+
- **å“åº”æ—¶é—´**: < 200ms
- **æ•…éšœæ¢å¤æ—¶é—´**: < 5åˆ†é’Ÿ
- **æ•°æ®å®Œæ•´æ€§**: 100%

### ğŸ‘¥ è¿ç»´å›¢é˜Ÿè§’è‰²
- **è¿ç»´å·¥ç¨‹å¸ˆ**: æ—¥å¸¸ç›‘æ§å’Œç»´æŠ¤
- **SRE å·¥ç¨‹å¸ˆ**: å¯é æ€§å·¥ç¨‹å’Œè‡ªåŠ¨åŒ–
- **DBA**: æ•°æ®åº“ç®¡ç†å’Œä¼˜åŒ–
- **å®‰å…¨å·¥ç¨‹å¸ˆ**: å®‰å…¨ç›‘æ§å’Œå“åº”

## ğŸ“Š æ—¥å¸¸è¿ç»´æ“ä½œ

### æ¯æ—¥æ£€æŸ¥æ¸…å•

#### ğŸŒ… æ™¨æ£€ (9:00 AM)
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/daily_morning_check.sh

echo "ğŸŒ… Claude Enhancer æ¯æ—¥æ™¨æ£€å¼€å§‹..."

# 1. ç³»ç»Ÿå¥åº·æ£€æŸ¥
echo "ğŸ¥ æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€..."
curl -f http://localhost:8080/health || echo "âŒ å¥åº·æ£€æŸ¥å¤±è´¥"

# 2. æœåŠ¡çŠ¶æ€æ£€æŸ¥
echo "ğŸ” æ£€æŸ¥æ‰€æœ‰æœåŠ¡çŠ¶æ€..."
docker-compose ps || kubectl get pods -n claude-enhancer

# 3. æ•°æ®åº“è¿æ¥æ£€æŸ¥
echo "ğŸ—„ï¸ æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
psql -h localhost -U postgres -d claude_enhancer -c "SELECT 1;" || echo "âŒ æ•°æ®åº“è¿æ¥å¤±è´¥"

# 4. ç¼“å­˜æœåŠ¡æ£€æŸ¥
echo "ğŸ’¾ æ£€æŸ¥ Redis ç¼“å­˜..."
redis-cli ping || echo "âŒ Redis è¿æ¥å¤±è´¥"

# 5. ç£ç›˜ç©ºé—´æ£€æŸ¥
echo "ğŸ’½ æ£€æŸ¥ç£ç›˜ç©ºé—´..."
df -h | grep -E '(8[0-9]|9[0-9])%' && echo "âš ï¸ ç£ç›˜ç©ºé—´ä¸è¶³"

# 6. å†…å­˜ä½¿ç”¨æ£€æŸ¥
echo "ğŸ§  æ£€æŸ¥å†…å­˜ä½¿ç”¨..."
free -h

# 7. ç½‘ç»œè¿æ¥æ£€æŸ¥
echo "ğŸŒ æ£€æŸ¥ç½‘ç»œè¿æ¥..."
netstat -an | grep :8080

# 8. é”™è¯¯æ—¥å¿—æ£€æŸ¥
echo "ğŸ“„ æ£€æŸ¥æ˜¨æ—¥é”™è¯¯æ—¥å¿—..."
grep ERROR /var/log/perfect21/*.log | tail -20

echo "âœ… æ¯æ—¥æ™¨æ£€å®Œæˆ!"
```

#### ğŸŒ† æ™šæ£€ (6:00 PM)
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/daily_evening_check.sh

echo "ğŸŒ† Claude Enhancer æ¯æ—¥æ™šæ£€å¼€å§‹..."

# 1. æ€§èƒ½æŒ‡æ ‡æ±‡æ€»
echo "ğŸ“Š ç”Ÿæˆä»Šæ—¥æ€§èƒ½æŠ¥å‘Š..."
python scripts/generate_daily_report.py

# 2. å¤‡ä»½çŠ¶æ€æ£€æŸ¥
echo "ğŸ’¾ æ£€æŸ¥ä»Šæ—¥å¤‡ä»½çŠ¶æ€..."
ls -la /backups/$(date +%Y%m%d)* || echo "âš ï¸ ä»Šæ—¥å¤‡ä»½æœªæ‰¾åˆ°"

# 3. å®‰å…¨äº‹ä»¶æ£€æŸ¥
echo "ğŸ›¡ï¸ æ£€æŸ¥ä»Šæ—¥å®‰å…¨äº‹ä»¶..."
grep -i "security\|authentication\|unauthorized" /var/log/perfect21/*.log

# 4. ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡
echo "ğŸ‘¥ ç»Ÿè®¡ä»Šæ—¥ç”¨æˆ·æ´»åŠ¨..."
psql -h localhost -U postgres -d claude_enhancer -c "
SELECT
  COUNT(DISTINCT user_id) as active_users,
  COUNT(*) as total_requests
FROM user_activity
WHERE DATE(created_at) = CURRENT_DATE;"

# 5. ç³»ç»Ÿèµ„æºè¶‹åŠ¿
echo "ğŸ“ˆ åˆ†æç³»ç»Ÿèµ„æºè¶‹åŠ¿..."
top -b -n1 | head -10

echo "âœ… æ¯æ—¥æ™šæ£€å®Œæˆ!"
```

### æ¯å‘¨ç»´æŠ¤ä»»åŠ¡

#### ğŸ—“ï¸ å‘¨ä¸€ï¼šç³»ç»Ÿä¼˜åŒ–
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/weekly_optimization.sh

echo "ğŸ”§ å¼€å§‹æ¯å‘¨ç³»ç»Ÿä¼˜åŒ–..."

# 1. æ•°æ®åº“ç»´æŠ¤
echo "ğŸ—„ï¸ æ‰§è¡Œæ•°æ®åº“ç»´æŠ¤..."
psql -h localhost -U postgres -d claude_enhancer << EOF
-- é‡å»ºç´¢å¼•
REINDEX DATABASE claude_enhancer;

-- æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
ANALYZE;

-- æ¸…ç†è¿‡æœŸæ•°æ®
DELETE FROM user_sessions WHERE expires_at < NOW() - INTERVAL '7 days';
DELETE FROM audit_logs WHERE created_at < NOW() - INTERVAL '30 days';
EOF

# 2. ç¼“å­˜æ¸…ç†å’Œä¼˜åŒ–
echo "ğŸ’¾ ä¼˜åŒ– Redis ç¼“å­˜..."
redis-cli FLUSHEXPIRED
redis-cli MEMORY PURGE

# 3. æ—¥å¿—è½®è½¬
echo "ğŸ“„ æ‰§è¡Œæ—¥å¿—è½®è½¬..."
logrotate /etc/logrotate.d/perfect21

# 4. ç³»ç»Ÿæ¸…ç†
echo "ğŸ§¹ æ‰§è¡Œç³»ç»Ÿæ¸…ç†..."
bash .claude/scripts/cleanup.sh

# 5. æ€§èƒ½åŸºå‡†æµ‹è¯•
echo "ğŸ“Š æ‰§è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•..."
bash .claude/scripts/performance_benchmark.sh

echo "âœ… æ¯å‘¨ç³»ç»Ÿä¼˜åŒ–å®Œæˆ!"
```

### æ¯æœˆç»´æŠ¤ä»»åŠ¡

#### ğŸ“… æœˆåº¦å¥åº·æ£€æŸ¥
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/monthly_health_check.sh

echo "ğŸ¥ å¼€å§‹æœˆåº¦å¥åº·æ£€æŸ¥..."

# 1. æ·±åº¦ç³»ç»Ÿæ‰«æ
echo "ğŸ” æ‰§è¡Œæ·±åº¦ç³»ç»Ÿæ‰«æ..."

# å®‰å…¨æ‰«æ
nmap -sS localhost
lynis audit system

# æ€§èƒ½åˆ†æ
iostat -x 1 10 > /tmp/iostat_report.txt
sar -u 1 10 > /tmp/cpu_report.txt

# 2. å®¹é‡è§„åˆ’åˆ†æ
echo "ğŸ“Š æ‰§è¡Œå®¹é‡è§„åˆ’åˆ†æ..."
python scripts/capacity_planning_analysis.py

# 3. å¤‡ä»½å®Œæ•´æ€§éªŒè¯
echo "ğŸ’¾ éªŒè¯å¤‡ä»½å®Œæ•´æ€§..."
python scripts/backup_integrity_check.py

# 4. æ–‡æ¡£æ›´æ–°æ£€æŸ¥
echo "ğŸ“š æ£€æŸ¥æ–‡æ¡£æ›´æ–°..."
bash scripts/documentation_sync_check.sh

# 5. ä¾èµ–é¡¹å®‰å…¨æ›´æ–°
echo "ğŸ”’ æ£€æŸ¥ä¾èµ–é¡¹å®‰å…¨æ›´æ–°..."
npm audit
pip-audit

echo "âœ… æœˆåº¦å¥åº·æ£€æŸ¥å®Œæˆ!"
```

## ğŸš¨ æ•…éšœå“åº”æµç¨‹

### å‘Šè­¦å“åº”çŸ©é˜µ

#### å‘Šè­¦çº§åˆ«å®šä¹‰
```yaml
alert_levels:
  P1_CRITICAL:
    description: "ç³»ç»Ÿå®Œå…¨ä¸å¯ç”¨æˆ–æ•°æ®ä¸¢å¤±é£é™©"
    response_time: "< 15åˆ†é’Ÿ"
    escalation: "ç«‹å³é€šçŸ¥æ‰€æœ‰ç›¸å…³äººå‘˜"
    examples:
      - "ç³»ç»Ÿå®•æœº"
      - "æ•°æ®åº“æŸå"
      - "å®‰å…¨æ¼æ´è¢«åˆ©ç”¨"

  P2_HIGH:
    description: "æ ¸å¿ƒåŠŸèƒ½å—å½±å“ï¼Œç”¨æˆ·ä½“éªŒä¸¥é‡ä¸‹é™"
    response_time: "< 1å°æ—¶"
    escalation: "é€šçŸ¥ä¸»è¦å“åº”å›¢é˜Ÿ"
    examples:
      - "Agent ç³»ç»Ÿå¤±æ•ˆ"
      - "æ€§èƒ½ä¸¥é‡ä¸‹é™"
      - "éƒ¨åˆ†æœåŠ¡ä¸å¯ç”¨"

  P3_MEDIUM:
    description: "éæ ¸å¿ƒåŠŸèƒ½å—å½±å“æˆ–æ€§èƒ½è½»å¾®ä¸‹é™"
    response_time: "< 4å°æ—¶"
    escalation: "åˆ†é…ç»™å€¼ç­å·¥ç¨‹å¸ˆ"
    examples:
      - "ç›‘æ§å‘Šè­¦"
      - "æ—¥å¿—é”™è¯¯å¢åŠ "
      - "èµ„æºä½¿ç”¨ç‡é«˜"

  P4_LOW:
    description: "æ½œåœ¨é—®é¢˜æˆ–ç»´æŠ¤éœ€æ±‚"
    response_time: "< 24å°æ—¶"
    escalation: "è®°å½•åˆ°å·¥ä½œé˜Ÿåˆ—"
    examples:
      - "ç£ç›˜ç©ºé—´é¢„è­¦"
      - "è¯ä¹¦å³å°†è¿‡æœŸ"
      - "æ€§èƒ½ä¼˜åŒ–å»ºè®®"
```

#### æ•…éšœå“åº”è„šæœ¬
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/incident_response.sh

set -euo pipefail

INCIDENT_LEVEL="$1"
INCIDENT_DESCRIPTION="$2"
INCIDENT_ID="INC-$(date +%Y%m%d-%H%M%S)"

echo "ğŸš¨ æ•…éšœå“åº”å¯åŠ¨: $INCIDENT_ID"
echo "çº§åˆ«: $INCIDENT_LEVEL"
echo "æè¿°: $INCIDENT_DESCRIPTION"

# åˆ›å»ºæ•…éšœè®°å½•
create_incident_record() {
    cat > "/var/log/perfect21/incidents/${INCIDENT_ID}.json" << EOF
{
  "incident_id": "$INCIDENT_ID",
  "level": "$INCIDENT_LEVEL",
  "description": "$INCIDENT_DESCRIPTION",
  "started_at": "$(date -Iseconds)",
  "status": "investigating",
  "assigned_to": "$USER",
  "steps": []
}
EOF
}

# æ”¶é›†ç³»ç»Ÿä¿¡æ¯
collect_system_info() {
    echo "ğŸ“Š æ”¶é›†ç³»ç»Ÿä¿¡æ¯..."

    # ç³»ç»ŸçŠ¶æ€
    systemctl status docker > "/tmp/${INCIDENT_ID}_docker_status.txt"

    # å®¹å™¨çŠ¶æ€
    docker ps -a > "/tmp/${INCIDENT_ID}_containers.txt"

    # èµ„æºä½¿ç”¨
    top -b -n1 > "/tmp/${INCIDENT_ID}_top.txt"
    free -h > "/tmp/${INCIDENT_ID}_memory.txt"
    df -h > "/tmp/${INCIDENT_ID}_disk.txt"

    # ç½‘ç»œçŠ¶æ€
    netstat -tlnp > "/tmp/${INCIDENT_ID}_network.txt"

    # æœ€è¿‘æ—¥å¿—
    tail -1000 /var/log/perfect21/error.log > "/tmp/${INCIDENT_ID}_error_logs.txt"
}

# è‡ªåŠ¨ä¿®å¤å°è¯•
attempt_auto_recovery() {
    echo "ğŸ”§ å°è¯•è‡ªåŠ¨ä¿®å¤..."

    case "$INCIDENT_LEVEL" in
        "P1"|"P2")
            # é«˜ä¼˜å…ˆçº§ï¼šé‡å¯æœåŠ¡
            echo "é‡å¯æ ¸å¿ƒæœåŠ¡..."
            docker-compose restart claude-enhancer
            ;;
        "P3")
            # ä¸­ä¼˜å…ˆçº§ï¼šæ¸…ç†å’Œä¼˜åŒ–
            echo "æ‰§è¡Œç³»ç»Ÿæ¸…ç†..."
            bash .claude/scripts/cleanup.sh
            ;;
        "P4")
            # ä½ä¼˜å…ˆçº§ï¼šè®°å½•è§‚å¯Ÿ
            echo "è®°å½•é—®é¢˜ï¼ŒæŒç»­è§‚å¯Ÿ..."
            ;;
    esac
}

# å‘é€é€šçŸ¥
send_notifications() {
    # Slack é€šçŸ¥
    curl -X POST "$SLACK_WEBHOOK_URL" \
      -H 'Content-type: application/json' \
      --data '{
        "text": "ğŸš¨ æ•…éšœè­¦æŠ¥",
        "attachments": [
          {
            "color": "danger",
            "fields": [
              {"title": "æ•…éšœID", "value": "'$INCIDENT_ID'", "short": true},
              {"title": "çº§åˆ«", "value": "'$INCIDENT_LEVEL'", "short": true},
              {"title": "æè¿°", "value": "'$INCIDENT_DESCRIPTION'", "short": false}
            ]
          }
        ]
      }'

    # é‚®ä»¶é€šçŸ¥ï¼ˆP1/P2ï¼‰
    if [[ "$INCIDENT_LEVEL" =~ ^P[12]$ ]]; then
        echo "å‘é€ç´§æ€¥é‚®ä»¶é€šçŸ¥..."
        echo "æ•…éšœè­¦æŠ¥: $INCIDENT_DESCRIPTION" | mail -s "ç´§æ€¥æ•…éšœ: $INCIDENT_ID" ops-team@company.com
    fi
}

# æ‰§è¡Œå“åº”æµç¨‹
main() {
    create_incident_record
    collect_system_info
    attempt_auto_recovery
    send_notifications

    echo "âœ… æ•…éšœå“åº”å®Œæˆ: $INCIDENT_ID"
    echo "ğŸ“‹ è¯·æŸ¥çœ‹æ•…éšœè®°å½•: /var/log/perfect21/incidents/${INCIDENT_ID}.json"
}

main "$@"
```

## ğŸ”„ å¤‡ä»½å’Œæ¢å¤æ“ä½œ

### è‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿ

#### æ•°æ®åº“å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/database_backup.sh

set -euo pipefail

BACKUP_DIR="/backups/database"
DB_HOST="localhost"
DB_NAME="claude_enhancer"
DB_USER="postgres"
RETENTION_DAYS=30

echo "ğŸ’¾ å¼€å§‹æ•°æ®åº“å¤‡ä»½..."

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR"

# ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
BACKUP_FILE="$BACKUP_DIR/claude_enhancer_$(date +%Y%m%d_%H%M%S).sql"
BACKUP_COMPRESSED="$BACKUP_FILE.gz"

# æ‰§è¡Œå¤‡ä»½
echo "ğŸ“¦ åˆ›å»ºæ•°æ®åº“å¤‡ä»½: $BACKUP_FILE"
pg_dump -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" \
  --verbose \
  --no-password \
  --format=custom \
  --file="$BACKUP_FILE"

# å‹ç¼©å¤‡ä»½æ–‡ä»¶
echo "ğŸ—œï¸ å‹ç¼©å¤‡ä»½æ–‡ä»¶..."
gzip "$BACKUP_FILE"

# éªŒè¯å¤‡ä»½å®Œæ•´æ€§
echo "âœ… éªŒè¯å¤‡ä»½å®Œæ•´æ€§..."
if pg_restore --list "$BACKUP_COMPRESSED" > /dev/null 2>&1; then
    echo "âœ… å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡"
else
    echo "âŒ å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯å¤±è´¥"
    exit 1
fi

# æ¸…ç†è¿‡æœŸå¤‡ä»½
echo "ğŸ§¹ æ¸…ç†è¿‡æœŸå¤‡ä»½..."
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete

# è®°å½•å¤‡ä»½ä¿¡æ¯
echo "ğŸ“ è®°å½•å¤‡ä»½ä¿¡æ¯..."
cat >> "$BACKUP_DIR/backup_log.txt" << EOF
$(date -Iseconds): å¤‡ä»½å®Œæˆ - $BACKUP_COMPRESSED ($(du -h "$BACKUP_COMPRESSED" | cut -f1))
EOF

echo "âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: $BACKUP_COMPRESSED"
```

#### åº”ç”¨æ•°æ®å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/application_backup.sh

set -euo pipefail

BACKUP_DIR="/backups/application"
APP_DIR="/app"
CONFIG_DIR="/app/.claude"

echo "ğŸ“‚ å¼€å§‹åº”ç”¨æ•°æ®å¤‡ä»½..."

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR"

# å¤‡ä»½é…ç½®æ–‡ä»¶
echo "âš™ï¸ å¤‡ä»½é…ç½®æ–‡ä»¶..."
tar -czf "$BACKUP_DIR/config_$(date +%Y%m%d_%H%M%S).tar.gz" \
  -C "$APP_DIR" \
  .claude/settings.json \
  .claude/config/ \
  .claude/agents/ \
  deployment/

# å¤‡ä»½ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶
echo "ğŸ“ å¤‡ä»½ç”¨æˆ·æ•°æ®..."
if [ -d "$APP_DIR/uploads" ]; then
    tar -czf "$BACKUP_DIR/uploads_$(date +%Y%m%d_%H%M%S).tar.gz" \
      -C "$APP_DIR" uploads/
fi

# å¤‡ä»½æ—¥å¿—æ–‡ä»¶
echo "ğŸ“„ å¤‡ä»½é‡è¦æ—¥å¿—..."
tar -czf "$BACKUP_DIR/logs_$(date +%Y%m%d_%H%M%S).tar.gz" \
  -C "/var/log" perfect21/

echo "âœ… åº”ç”¨æ•°æ®å¤‡ä»½å®Œæˆ"
```

### æ¢å¤æ“ä½œæµç¨‹

#### æ•°æ®åº“æ¢å¤è„šæœ¬
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/database_restore.sh

set -euo pipefail

BACKUP_FILE="$1"
DB_HOST="localhost"
DB_NAME="claude_enhancer"
DB_USER="postgres"

if [ -z "$BACKUP_FILE" ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <backup_file.sql.gz>"
    exit 1
fi

echo "ğŸ”„ å¼€å§‹æ•°æ®åº“æ¢å¤..."
echo "å¤‡ä»½æ–‡ä»¶: $BACKUP_FILE"

# éªŒè¯å¤‡ä»½æ–‡ä»¶
echo "âœ… éªŒè¯å¤‡ä»½æ–‡ä»¶..."
if [ ! -f "$BACKUP_FILE" ]; then
    echo "âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: $BACKUP_FILE"
    exit 1
fi

# åœæ­¢åº”ç”¨æœåŠ¡
echo "â¹ï¸ åœæ­¢åº”ç”¨æœåŠ¡..."
docker-compose stop claude-enhancer

# åˆ›å»ºæ¢å¤å‰å¤‡ä»½
echo "ğŸ’¾ åˆ›å»ºæ¢å¤å‰å¤‡ä»½..."
pg_dump -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" \
  --format=custom \
  --file="/tmp/pre_restore_backup_$(date +%Y%m%d_%H%M%S).sql"

# åˆ é™¤ç°æœ‰æ•°æ®åº“
echo "ğŸ—‘ï¸ åˆ é™¤ç°æœ‰æ•°æ®åº“..."
psql -h "$DB_HOST" -U "$DB_USER" -d postgres -c "DROP DATABASE IF EXISTS $DB_NAME;"

# åˆ›å»ºæ–°æ•°æ®åº“
echo "ğŸ—ï¸ åˆ›å»ºæ–°æ•°æ®åº“..."
psql -h "$DB_HOST" -U "$DB_USER" -d postgres -c "CREATE DATABASE $DB_NAME;"

# æ¢å¤æ•°æ®
echo "ğŸ“¥ æ¢å¤æ•°æ®åº“æ•°æ®..."
if [[ "$BACKUP_FILE" == *.gz ]]; then
    gunzip -c "$BACKUP_FILE" | pg_restore -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" --verbose
else
    pg_restore -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" --verbose "$BACKUP_FILE"
fi

# éªŒè¯æ¢å¤ç»“æœ
echo "âœ… éªŒè¯æ¢å¤ç»“æœ..."
TABLE_COUNT=$(psql -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';")
echo "æ¢å¤åè¡¨æ•°é‡: $TABLE_COUNT"

# é‡å¯åº”ç”¨æœåŠ¡
echo "ğŸš€ é‡å¯åº”ç”¨æœåŠ¡..."
docker-compose start claude-enhancer

echo "âœ… æ•°æ®åº“æ¢å¤å®Œæˆ"
```

## ğŸ“Š æ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜

### å®æ—¶æ€§èƒ½ç›‘æ§

#### æ€§èƒ½ç›‘æ§è„šæœ¬
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/performance_monitor.sh

INTERVAL=10
LOG_FILE="/var/log/perfect21/performance.log"

echo "ğŸ“Š å¯åŠ¨æ€§èƒ½ç›‘æ§ (é—´éš”: ${INTERVAL}ç§’)..."

while true; do
    TIMESTAMP=$(date -Iseconds)

    # CPU ä½¿ç”¨ç‡
    CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)

    # å†…å­˜ä½¿ç”¨ç‡
    MEM_USAGE=$(free | grep Mem | awk '{printf "%.1f", $3/$2 * 100.0}')

    # ç£ç›˜ä½¿ç”¨ç‡
    DISK_USAGE=$(df -h / | tail -1 | awk '{print $5}' | cut -d'%' -f1)

    # ç½‘ç»œè¿æ¥æ•°
    CONNECTIONS=$(netstat -an | grep :8080 | wc -l)

    # åº”ç”¨å“åº”æ—¶é—´
    RESPONSE_TIME=$(curl -w "%{time_total}" -o /dev/null -s http://localhost:8080/health)

    # è®°å½•æ€§èƒ½æ•°æ®
    echo "$TIMESTAMP,CPU:$CPU_USAGE,MEM:$MEM_USAGE,DISK:$DISK_USAGE,CONN:$CONNECTIONS,RT:$RESPONSE_TIME" >> "$LOG_FILE"

    # æ£€æŸ¥å‘Šè­¦é˜ˆå€¼
    if (( $(echo "$CPU_USAGE > 80" | bc -l) )); then
        echo "âš ï¸ CPU ä½¿ç”¨ç‡è¿‡é«˜: $CPU_USAGE%"
    fi

    if (( $(echo "$MEM_USAGE > 85" | bc -l) )); then
        echo "âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: $MEM_USAGE%"
    fi

    if (( DISK_USAGE > 90 )); then
        echo "âš ï¸ ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: $DISK_USAGE%"
    fi

    if (( $(echo "$RESPONSE_TIME > 1.0" | bc -l) )); then
        echo "âš ï¸ å“åº”æ—¶é—´è¿‡é•¿: ${RESPONSE_TIME}s"
    fi

    sleep $INTERVAL
done
```

### æ€§èƒ½è°ƒä¼˜æ“ä½œ

#### æ•°æ®åº“æ€§èƒ½è°ƒä¼˜
```sql
-- æ–‡ä»¶: scripts/database_tuning.sql

-- åˆ†ææ…¢æŸ¥è¯¢
SELECT
    query,
    mean_time,
    calls,
    total_time,
    (total_time/calls) as avg_time
FROM pg_stat_statements
ORDER BY total_time DESC
LIMIT 10;

-- æ£€æŸ¥æœªä½¿ç”¨çš„ç´¢å¼•
SELECT
    schemaname,
    tablename,
    indexname,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_tup_read = 0 AND idx_tup_fetch = 0;

-- åˆ†æè¡¨è†¨èƒ€
SELECT
    schemaname,
    tablename,
    n_dead_tup,
    n_live_tup,
    ROUND((n_dead_tup::numeric / (n_live_tup + n_dead_tup)) * 100, 2) as dead_percentage
FROM pg_stat_user_tables
WHERE n_dead_tup > 0
ORDER BY dead_percentage DESC;

-- ä¼˜åŒ–å»ºè®®æŸ¥è¯¢
SELECT
    'VACUUM ANALYZE ' || schemaname || '.' || tablename || ';' as optimization_command
FROM pg_stat_user_tables
WHERE n_dead_tup > n_live_tup * 0.1;
```

#### åº”ç”¨æ€§èƒ½è°ƒä¼˜
```python
# æ–‡ä»¶: scripts/application_tuning.py

import psutil
import asyncio
import aiohttp
from typing import Dict, List

class PerformanceTuner:
    """åº”ç”¨æ€§èƒ½è°ƒä¼˜å™¨"""

    def __init__(self):
        self.optimization_recommendations = []

    async def analyze_performance(self) -> Dict[str, any]:
        """åˆ†æåº”ç”¨æ€§èƒ½"""

        # CPU åˆ†æ
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_cores = psutil.cpu_count()

        # å†…å­˜åˆ†æ
        memory = psutil.virtual_memory()

        # ç£ç›˜ I/O åˆ†æ
        disk_io = psutil.disk_io_counters()

        # ç½‘ç»œåˆ†æ
        network_io = psutil.net_io_counters()

        # åº”ç”¨å“åº”æ—¶é—´åˆ†æ
        response_times = await self.measure_response_times()

        analysis = {
            'cpu': {
                'usage_percent': cpu_percent,
                'cores': cpu_cores,
                'load_average': psutil.getloadavg()
            },
            'memory': {
                'usage_percent': memory.percent,
                'available_gb': memory.available / (1024**3),
                'used_gb': memory.used / (1024**3)
            },
            'disk_io': {
                'read_mb_per_sec': disk_io.read_bytes / (1024**2),
                'write_mb_per_sec': disk_io.write_bytes / (1024**2)
            },
            'network_io': {
                'sent_mb': network_io.bytes_sent / (1024**2),
                'recv_mb': network_io.bytes_recv / (1024**2)
            },
            'response_times': response_times
        }

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        self.generate_recommendations(analysis)

        return analysis

    async def measure_response_times(self) -> Dict[str, float]:
        """æµ‹é‡å„ä¸ªç«¯ç‚¹çš„å“åº”æ—¶é—´"""
        endpoints = [
            'http://localhost:8080/health',
            'http://localhost:8080/api/agents/status',
            'http://localhost:8080/api/workflow/status'
        ]

        response_times = {}

        async with aiohttp.ClientSession() as session:
            for endpoint in endpoints:
                try:
                    start_time = asyncio.get_event_loop().time()
                    async with session.get(endpoint) as response:
                        await response.text()
                    end_time = asyncio.get_event_loop().time()

                    response_times[endpoint] = end_time - start_time
                except Exception as e:
                    response_times[endpoint] = float('inf')

        return response_times

    def generate_recommendations(self, analysis: Dict[str, any]) -> None:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""

        # CPU ä¼˜åŒ–å»ºè®®
        if analysis['cpu']['usage_percent'] > 80:
            self.optimization_recommendations.append({
                'type': 'cpu',
                'severity': 'high',
                'message': f"CPU ä½¿ç”¨ç‡è¿‡é«˜ ({analysis['cpu']['usage_percent']}%)",
                'suggestions': [
                    'è€ƒè™‘å¢åŠ æœåŠ¡å™¨ CPU æ ¸å¿ƒæ•°',
                    'ä¼˜åŒ–åº”ç”¨ä»£ç ï¼Œå‡å°‘ CPU å¯†é›†å‹æ“ä½œ',
                    'å¯ç”¨åº”ç”¨ç¼“å­˜å‡å°‘è®¡ç®—è´Ÿè·'
                ]
            })

        # å†…å­˜ä¼˜åŒ–å»ºè®®
        if analysis['memory']['usage_percent'] > 85:
            self.optimization_recommendations.append({
                'type': 'memory',
                'severity': 'high',
                'message': f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ ({analysis['memory']['usage_percent']}%)",
                'suggestions': [
                    'å¢åŠ æœåŠ¡å™¨å†…å­˜',
                    'æ£€æŸ¥å†…å­˜æ³„æ¼',
                    'ä¼˜åŒ–æ•°æ®ç»“æ„å’Œç®—æ³•'
                ]
            })

        # å“åº”æ—¶é—´ä¼˜åŒ–å»ºè®®
        slow_endpoints = [
            endpoint for endpoint, time in analysis['response_times'].items()
            if time > 1.0
        ]

        if slow_endpoints:
            self.optimization_recommendations.append({
                'type': 'response_time',
                'severity': 'medium',
                'message': f"å‘ç° {len(slow_endpoints)} ä¸ªæ…¢å“åº”ç«¯ç‚¹",
                'suggestions': [
                    'ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢',
                    'æ·»åŠ é€‚å½“çš„ç´¢å¼•',
                    'å¯ç”¨åº”ç”¨å±‚ç¼“å­˜',
                    'è€ƒè™‘ä½¿ç”¨ CDN'
                ]
            })

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    tuner = PerformanceTuner()
    analysis = await tuner.analyze_performance()

    print("ğŸ“Š æ€§èƒ½åˆ†æç»“æœ:")
    print(f"CPU: {analysis['cpu']['usage_percent']}%")
    print(f"å†…å­˜: {analysis['memory']['usage_percent']}%")

    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    for rec in tuner.optimization_recommendations:
        print(f"- {rec['message']}")
        for suggestion in rec['suggestions']:
            print(f"  â€¢ {suggestion}")

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ”’ å®‰å…¨è¿ç»´æ“ä½œ

### å®‰å…¨ç›‘æ§è„šæœ¬

#### å®‰å…¨äº‹ä»¶ç›‘æ§
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/security_monitor.sh

SECURITY_LOG="/var/log/perfect21/security.log"
ALERT_EMAIL="security@company.com"

echo "ğŸ›¡ï¸ å¯åŠ¨å®‰å…¨ç›‘æ§..."

# ç›‘æ§ç™»å½•å¼‚å¸¸
monitor_login_anomalies() {
    # æ£€æŸ¥çŸ­æ—¶é—´å†…çš„å¤šæ¬¡å¤±è´¥ç™»å½•
    FAILED_LOGINS=$(grep "authentication failed" /var/log/perfect21/auth.log | grep "$(date +%Y-%m-%d)" | wc -l)

    if [ "$FAILED_LOGINS" -gt 10 ]; then
        echo "$(date -Iseconds): æ£€æµ‹åˆ°å¼‚å¸¸ç™»å½•å°è¯•: $FAILED_LOGINS æ¬¡å¤±è´¥" >> "$SECURITY_LOG"

        # å‘é€å‘Šè­¦
        echo "å®‰å…¨å‘Šè­¦: æ£€æµ‹åˆ° $FAILED_LOGINS æ¬¡å¤±è´¥ç™»å½•å°è¯•" | \
            mail -s "å®‰å…¨å‘Šè­¦: å¼‚å¸¸ç™»å½•æ´»åŠ¨" "$ALERT_EMAIL"
    fi
}

# ç›‘æ§æ–‡ä»¶å®Œæ•´æ€§
monitor_file_integrity() {
    # æ£€æŸ¥å…³é”®é…ç½®æ–‡ä»¶çš„å˜æ›´
    CRITICAL_FILES=(
        "/app/.claude/settings.json"
        "/app/.claude/config/main.yaml"
        "/etc/passwd"
        "/etc/shadow"
    )

    for file in "${CRITICAL_FILES[@]}"; do
        if [ -f "$file" ]; then
            CURRENT_HASH=$(sha256sum "$file" | cut -d' ' -f1)
            STORED_HASH_FILE="/var/lib/perfect21/hashes/$(basename "$file").hash"

            if [ -f "$STORED_HASH_FILE" ]; then
                STORED_HASH=$(cat "$STORED_HASH_FILE")

                if [ "$CURRENT_HASH" != "$STORED_HASH" ]; then
                    echo "$(date -Iseconds): æ–‡ä»¶å®Œæ•´æ€§å‘Šè­¦: $file å·²è¢«ä¿®æ”¹" >> "$SECURITY_LOG"

                    # æ›´æ–°å­˜å‚¨çš„å“ˆå¸Œå€¼
                    echo "$CURRENT_HASH" > "$STORED_HASH_FILE"
                fi
            else
                # é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºå“ˆå¸Œæ–‡ä»¶
                mkdir -p "$(dirname "$STORED_HASH_FILE")"
                echo "$CURRENT_HASH" > "$STORED_HASH_FILE"
            fi
        fi
    done
}

# ç›‘æ§ç½‘ç»œå¼‚å¸¸
monitor_network_anomalies() {
    # æ£€æŸ¥å¼‚å¸¸çš„ç½‘ç»œè¿æ¥
    SUSPICIOUS_CONNECTIONS=$(netstat -an | grep -E ":(22|23|3389|4444|5555)" | grep ESTABLISHED | wc -l)

    if [ "$SUSPICIOUS_CONNECTIONS" -gt 0 ]; then
        echo "$(date -Iseconds): æ£€æµ‹åˆ°å¯ç–‘ç½‘ç»œè¿æ¥: $SUSPICIOUS_CONNECTIONS ä¸ª" >> "$SECURITY_LOG"
    fi
}

# ä¸»ç›‘æ§å¾ªç¯
while true; do
    monitor_login_anomalies
    monitor_file_integrity
    monitor_network_anomalies

    sleep 60  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
done
```

### å®‰å…¨åŠ å›ºæ“ä½œ

#### ç³»ç»Ÿå®‰å…¨åŠ å›ºè„šæœ¬
```bash
#!/bin/bash
# æ–‡ä»¶: scripts/security_hardening.sh

set -euo pipefail

echo "ğŸ”’ å¼€å§‹ç³»ç»Ÿå®‰å…¨åŠ å›º..."

# 1. æ›´æ–°ç³»ç»Ÿå’Œè½¯ä»¶åŒ…
echo "ğŸ“¦ æ›´æ–°ç³»ç»Ÿè½¯ä»¶åŒ…..."
apt update && apt upgrade -y

# 2. é…ç½®é˜²ç«å¢™
echo "ğŸ›¡ï¸ é…ç½®é˜²ç«å¢™è§„åˆ™..."
ufw --force reset
ufw default deny incoming
ufw default allow outgoing

# å…è®¸å¿…è¦çš„ç«¯å£
ufw allow 22/tcp    # SSH
ufw allow 80/tcp    # HTTP
ufw allow 443/tcp   # HTTPS
ufw allow 8080/tcp  # åº”ç”¨ç«¯å£

ufw --force enable

# 3. é…ç½® SSH å®‰å…¨
echo "ğŸ” é…ç½® SSH å®‰å…¨..."
sed -i 's/#PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config
sed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config
sed -i 's/#PubkeyAuthentication yes/PubkeyAuthentication yes/' /etc/ssh/sshd_config

systemctl restart sshd

# 4. é…ç½®è‡ªåŠ¨å®‰å…¨æ›´æ–°
echo "ğŸ”„ é…ç½®è‡ªåŠ¨å®‰å…¨æ›´æ–°..."
apt install -y unattended-upgrades
echo 'Unattended-Upgrade::Automatic-Reboot "false";' >> /etc/apt/apt.conf.d/50unattended-upgrades

# 5. å®‰è£…å’Œé…ç½® fail2ban
echo "ğŸš« å®‰è£…å’Œé…ç½® fail2ban..."
apt install -y fail2ban

cat > /etc/fail2ban/jail.local << EOF
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 3

[sshd]
enabled = true
port = ssh
filter = sshd
logpath = /var/log/auth.log

[claude-enhancer]
enabled = true
port = 8080
filter = claude-enhancer
logpath = /var/log/perfect21/access.log
maxretry = 5
EOF

# åˆ›å»º Claude Enhancer fail2ban è¿‡æ»¤å™¨
cat > /etc/fail2ban/filter.d/claude-enhancer.conf << EOF
[Definition]
failregex = ^.*authentication failed.*<HOST>.*$
            ^.*unauthorized access.*<HOST>.*$
ignoreregex =
EOF

systemctl restart fail2ban

# 6. è®¾ç½®æ–‡ä»¶æƒé™
echo "ğŸ“ è®¾ç½®å®‰å…¨æ–‡ä»¶æƒé™..."
chmod 600 /app/.claude/settings.json
chmod 700 /app/.claude/config/
chown -R app:app /app/.claude/

# 7. é…ç½®å®¡è®¡æ—¥å¿—
echo "ğŸ“‹ é…ç½®å®¡è®¡æ—¥å¿—..."
apt install -y auditd
systemctl enable auditd

# 8. é…ç½®å®‰å…¨å†…æ ¸å‚æ•°
echo "âš™ï¸ é…ç½®å®‰å…¨å†…æ ¸å‚æ•°..."
cat >> /etc/sysctl.conf << EOF
# ç½‘ç»œå®‰å…¨å‚æ•°
net.ipv4.conf.all.send_redirects = 0
net.ipv4.conf.default.send_redirects = 0
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv4.conf.all.secure_redirects = 0
net.ipv4.conf.default.secure_redirects = 0
net.ipv4.ip_forward = 0
net.ipv4.conf.all.log_martians = 1
net.ipv4.conf.default.log_martians = 1

# é˜²æ­¢ SYN flood æ”»å‡»
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 2048
net.ipv4.tcp_synack_retries = 2
net.ipv4.tcp_syn_retries = 5
EOF

sysctl -p

echo "âœ… ç³»ç»Ÿå®‰å…¨åŠ å›ºå®Œæˆ!"
```

## ğŸ“ˆ å®¹é‡è§„åˆ’å’Œæ‰©å±•

### å®¹é‡ç›‘æ§è„šæœ¬
```python
# æ–‡ä»¶: scripts/capacity_planning.py

import psutil
import psycopg2
import redis
import json
import datetime
from typing import Dict, List
from dataclasses import dataclass

@dataclass
class CapacityMetrics:
    """å®¹é‡æŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: datetime.datetime
    cpu_usage: float
    memory_usage: float
    disk_usage: float
    network_io: Dict[str, float]
    database_size: float
    active_connections: int
    cache_usage: float

class CapacityPlanner:
    """å®¹é‡è§„åˆ’åˆ†æå™¨"""

    def __init__(self):
        self.db_connection = psycopg2.connect(
            host="localhost",
            database="claude_enhancer",
            user="postgres",
            password="password"
        )
        self.redis_connection = redis.Redis(host="localhost", port=6379, db=0)

    def collect_current_metrics(self) -> CapacityMetrics:
        """æ”¶é›†å½“å‰å®¹é‡æŒ‡æ ‡"""

        # ç³»ç»Ÿèµ„æºæŒ‡æ ‡
        cpu_usage = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        network = psutil.net_io_counters()

        # æ•°æ®åº“æŒ‡æ ‡
        with self.db_connection.cursor() as cursor:
            cursor.execute("SELECT pg_database_size('claude_enhancer');")
            db_size = cursor.fetchone()[0] / (1024**3)  # GB

            cursor.execute("SELECT count(*) FROM pg_stat_activity WHERE state = 'active';")
            active_connections = cursor.fetchone()[0]

        # Redis æŒ‡æ ‡
        redis_info = self.redis_connection.info()
        cache_usage = redis_info['used_memory'] / (1024**2)  # MB

        return CapacityMetrics(
            timestamp=datetime.datetime.now(),
            cpu_usage=cpu_usage,
            memory_usage=memory.percent,
            disk_usage=(disk.used / disk.total) * 100,
            network_io={
                'bytes_sent': network.bytes_sent / (1024**2),
                'bytes_recv': network.bytes_recv / (1024**2)
            },
            database_size=db_size,
            active_connections=active_connections,
            cache_usage=cache_usage
        )

    def analyze_growth_trend(self, historical_data: List[CapacityMetrics]) -> Dict[str, float]:
        """åˆ†æå¢é•¿è¶‹åŠ¿"""
        if len(historical_data) < 2:
            return {}

        # è®¡ç®—å„é¡¹æŒ‡æ ‡çš„å¢é•¿ç‡
        first_metric = historical_data[0]
        last_metric = historical_data[-1]
        time_diff = (last_metric.timestamp - first_metric.timestamp).days

        if time_diff == 0:
            return {}

        growth_rates = {
            'cpu_growth_rate': (last_metric.cpu_usage - first_metric.cpu_usage) / time_diff,
            'memory_growth_rate': (last_metric.memory_usage - first_metric.memory_usage) / time_diff,
            'disk_growth_rate': (last_metric.disk_usage - first_metric.disk_usage) / time_diff,
            'database_growth_rate': (last_metric.database_size - first_metric.database_size) / time_diff,
            'connection_growth_rate': (last_metric.active_connections - first_metric.active_connections) / time_diff
        }

        return growth_rates

    def predict_capacity_needs(self, growth_rates: Dict[str, float], days_ahead: int = 90) -> Dict[str, any]:
        """é¢„æµ‹å®¹é‡éœ€æ±‚"""
        current_metrics = self.collect_current_metrics()

        predictions = {}

        # CPU é¢„æµ‹
        predicted_cpu = current_metrics.cpu_usage + (growth_rates.get('cpu_growth_rate', 0) * days_ahead)
        if predicted_cpu > 80:
            predictions['cpu'] = {
                'status': 'warning',
                'predicted_usage': predicted_cpu,
                'recommendation': 'è€ƒè™‘å‡çº§ CPU æˆ–ä¼˜åŒ–åº”ç”¨æ€§èƒ½'
            }

        # å†…å­˜é¢„æµ‹
        predicted_memory = current_metrics.memory_usage + (growth_rates.get('memory_growth_rate', 0) * days_ahead)
        if predicted_memory > 85:
            predictions['memory'] = {
                'status': 'warning',
                'predicted_usage': predicted_memory,
                'recommendation': 'è€ƒè™‘å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨'
            }

        # ç£ç›˜é¢„æµ‹
        predicted_disk = current_metrics.disk_usage + (growth_rates.get('disk_growth_rate', 0) * days_ahead)
        if predicted_disk > 90:
            predictions['disk'] = {
                'status': 'critical',
                'predicted_usage': predicted_disk,
                'recommendation': 'ç´§æ€¥æ‰©å±•ç£ç›˜ç©ºé—´'
            }

        # æ•°æ®åº“é¢„æµ‹
        predicted_db_size = current_metrics.database_size + (growth_rates.get('database_growth_rate', 0) * days_ahead)
        predictions['database'] = {
            'status': 'info',
            'predicted_size_gb': predicted_db_size,
            'recommendation': f'é¢„è®¡æ•°æ®åº“å¤§å°å°†è¾¾åˆ° {predicted_db_size:.2f} GB'
        }

        return predictions

    def generate_capacity_report(self) -> str:
        """ç”Ÿæˆå®¹é‡è§„åˆ’æŠ¥å‘Š"""
        current_metrics = self.collect_current_metrics()

        # è¿™é‡Œåº”è¯¥ä»å†å²æ•°æ®å­˜å‚¨ä¸­è·å–æ•°æ®
        # ä¸ºäº†ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä½¿ç”¨å½“å‰æŒ‡æ ‡
        growth_rates = {
            'cpu_growth_rate': 0.1,  # ç¤ºä¾‹å€¼
            'memory_growth_rate': 0.2,
            'disk_growth_rate': 0.05,
            'database_growth_rate': 0.01,
            'connection_growth_rate': 0.5
        }

        predictions = self.predict_capacity_needs(growth_rates)

        report = f"""
# Claude Enhancer å®¹é‡è§„åˆ’æŠ¥å‘Š

## å½“å‰èµ„æºä½¿ç”¨æƒ…å†µ
- CPU ä½¿ç”¨ç‡: {current_metrics.cpu_usage:.1f}%
- å†…å­˜ä½¿ç”¨ç‡: {current_metrics.memory_usage:.1f}%
- ç£ç›˜ä½¿ç”¨ç‡: {current_metrics.disk_usage:.1f}%
- æ•°æ®åº“å¤§å°: {current_metrics.database_size:.2f} GB
- æ´»è·ƒè¿æ¥æ•°: {current_metrics.active_connections}
- ç¼“å­˜ä½¿ç”¨: {current_metrics.cache_usage:.1f} MB

## 90å¤©å®¹é‡é¢„æµ‹
"""

        for resource, prediction in predictions.items():
            report += f"\n### {resource.upper()}\n"
            report += f"- çŠ¶æ€: {prediction['status']}\n"
            report += f"- å»ºè®®: {prediction['recommendation']}\n"

        return report

# ä½¿ç”¨ç¤ºä¾‹
def main():
    planner = CapacityPlanner()

    # æ”¶é›†å½“å‰æŒ‡æ ‡
    current_metrics = planner.collect_current_metrics()
    print(f"å½“å‰ CPU ä½¿ç”¨ç‡: {current_metrics.cpu_usage:.1f}%")

    # ç”Ÿæˆå®¹é‡æŠ¥å‘Š
    report = planner.generate_capacity_report()
    print(report)

    # ä¿å­˜æŠ¥å‘Š
    with open(f"/var/log/perfect21/capacity_report_{datetime.date.today()}.txt", "w") as f:
        f.write(report)

if __name__ == "__main__":
    main()
```

## ğŸ“‹ è¿ç»´æ£€æŸ¥æ¸…å•

### æ¯æ—¥è¿ç»´æ£€æŸ¥æ¸…å•
- [ ] **ç³»ç»Ÿå¥åº·æ£€æŸ¥**
  - [ ] åº”ç”¨æœåŠ¡çŠ¶æ€æ­£å¸¸
  - [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸
  - [ ] ç¼“å­˜æœåŠ¡å¯ç”¨
  - [ ] ç£ç›˜ç©ºé—´å……è¶³ (< 80%)
  - [ ] å†…å­˜ä½¿ç”¨æ­£å¸¸ (< 85%)
  - [ ] CPU è´Ÿè½½åˆç† (< 80%)

- [ ] **å®‰å…¨çŠ¶æ€æ£€æŸ¥**
  - [ ] æ— å®‰å…¨å‘Šè­¦
  - [ ] é˜²ç«å¢™çŠ¶æ€æ­£å¸¸
  - [ ] SSL è¯ä¹¦æœ‰æ•ˆ
  - [ ] è®¿é—®æ—¥å¿—æ­£å¸¸
  - [ ] æ— å¼‚å¸¸ç™»å½•å°è¯•

- [ ] **å¤‡ä»½çŠ¶æ€æ£€æŸ¥**
  - [ ] æ•°æ®åº“å¤‡ä»½å®Œæˆ
  - [ ] åº”ç”¨é…ç½®å¤‡ä»½å®Œæˆ
  - [ ] å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯
  - [ ] è¿œç¨‹å¤‡ä»½åŒæ­¥æ­£å¸¸

### æ¯å‘¨è¿ç»´æ£€æŸ¥æ¸…å•
- [ ] **æ€§èƒ½åˆ†æ**
  - [ ] å“åº”æ—¶é—´è¶‹åŠ¿åˆ†æ
  - [ ] é”™è¯¯ç‡ç»Ÿè®¡
  - [ ] ç”¨æˆ·æ´»è·ƒåº¦åˆ†æ
  - [ ] èµ„æºä½¿ç”¨è¶‹åŠ¿

- [ ] **ç³»ç»Ÿç»´æŠ¤**
  - [ ] æ•°æ®åº“æ€§èƒ½è°ƒä¼˜
  - [ ] æ—¥å¿—æ–‡ä»¶è½®è½¬
  - [ ] ä¸´æ—¶æ–‡ä»¶æ¸…ç†
  - [ ] ç¼“å­˜ä¼˜åŒ–

- [ ] **å®‰å…¨å®¡è®¡**
  - [ ] å®‰å…¨æ—¥å¿—å®¡æŸ¥
  - [ ] ç”¨æˆ·æƒé™å®¡æŸ¥
  - [ ] ç³»ç»Ÿæ¼æ´æ‰«æ
  - [ ] é…ç½®å®‰å…¨æ£€æŸ¥

### æ¯æœˆè¿ç»´æ£€æŸ¥æ¸…å•
- [ ] **å®¹é‡è§„åˆ’**
  - [ ] èµ„æºä½¿ç”¨è¶‹åŠ¿åˆ†æ
  - [ ] å®¹é‡é¢„æµ‹æŠ¥å‘Š
  - [ ] æ‰©å®¹éœ€æ±‚è¯„ä¼°
  - [ ] æˆæœ¬ä¼˜åŒ–å»ºè®®

- [ ] **ç¾éš¾æ¢å¤æµ‹è¯•**
  - [ ] å¤‡ä»½æ¢å¤æµ‹è¯•
  - [ ] æ•…éšœåˆ‡æ¢æµ‹è¯•
  - [ ] æ¢å¤æ—¶é—´éªŒè¯
  - [ ] åº”æ€¥æµç¨‹æ¼”ç»ƒ

---

**ğŸ“ ç´§æ€¥è”ç³»æ–¹å¼**:
- **è¿ç»´å€¼ç­**: [ç”µè¯å·ç ]
- **æŠ€æœ¯è´Ÿè´£äºº**: [ç”µè¯å·ç ]
- **ç³»ç»Ÿç®¡ç†å‘˜**: [ç”µè¯å·ç ]

**ğŸ¯ è¿ç»´ç›®æ ‡**: ç¡®ä¿ Claude Enhancer ç³»ç»Ÿ 7x24 å°æ—¶ç¨³å®šè¿è¡Œï¼Œä¸ºç”¨æˆ·æä¾›å¯é çš„æœåŠ¡