#!/usr/bin/env python3
"""
Perfect21å¢å¼ºæ€§èƒ½ä¼˜åŒ–å™¨ - å…¨é¢æ€§èƒ½ä¼˜åŒ–è§£å†³æ–¹æ¡ˆ

ğŸš€ æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ - Agentç»“æœç¼“å­˜ã€æ¨¡æ¿é¢„ç¼–è¯‘
2. å¹¶è¡Œæ‰§è¡Œä¼˜åŒ– - èµ„æºæ± ç®¡ç†ã€å¼‚æ­¥åè°ƒ
3. Gitæ“ä½œä¼˜åŒ– - æ‰¹é‡åŒ–ã€ç¼“å­˜åˆ©ç”¨
4. å†…å­˜ç®¡ç† - æ™ºèƒ½GCã€å¯¹è±¡å¤ç”¨
5. æ€§èƒ½ç›‘æ§ - å®æ—¶åˆ†æã€è‡ªåŠ¨ä¼˜åŒ–
6. åŸºå‡†æµ‹è¯• - æ€§èƒ½å›å½’æ£€æµ‹
"""

import os
import sys
import time
import asyncio
import threading
import concurrent.futures
import psutil
import gc
import pickle
import hashlib
import json
from typing import Dict, Any, List, Optional, Callable, Tuple, Union
from datetime import datetime, timedelta
from collections import defaultdict, deque
from dataclasses import dataclass, field
from contextlib import contextmanager, asynccontextmanager
from functools import wraps, lru_cache
import statistics
import logging
from pathlib import Path

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from modules.logger import log_info, log_error, log_warning
from modules.config import config
from modules.performance_cache import performance_cache
from modules.performance_monitor import performance_monitor, PerformanceMetric

logger = logging.getLogger(__name__)

@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    key: str
    value: Any
    timestamp: float
    ttl: float
    hit_count: int = 0
    size_bytes: int = 0
    last_access: float = 0.0

@dataclass
class AgentExecutionContext:
    """Agentæ‰§è¡Œä¸Šä¸‹æ–‡"""
    agent_id: str
    request_id: str
    start_time: float
    parameters: Dict[str, Any]
    cached_result: Optional[Any] = None
    execution_time: float = 0.0
    memory_usage: float = 0.0

@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    category: str
    before_metric: float
    after_metric: float
    improvement: float
    description: str
    timestamp: datetime = field(default_factory=datetime.now)

class IntelligentCacheSystem:
    """æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ - Agentç»“æœå’Œæ¨¡æ¿é¢„ç¼–è¯‘"""

    def __init__(self, max_size: int = 2048, ttl: int = 3600):
        self.max_size = max_size
        self.ttl = ttl
        self.cache: Dict[str, CacheEntry] = {}
        self.access_history = deque(maxlen=10000)
        self.lock = threading.RLock()

        # åˆ†å±‚ç¼“å­˜
        self.hot_cache = {}  # é«˜é¢‘è®¿é—®
        self.warm_cache = {}  # ä¸­ç­‰é¢‘ç‡
        self.cold_cache = {}  # ä½é¢‘è®¿é—®

        # é¢„ç¼–è¯‘æ¨¡æ¿ç¼“å­˜
        self.template_cache = {}
        self.compiled_workflows = {}

        # æ™ºèƒ½é¢„æµ‹
        self.access_patterns = defaultdict(list)
        self.prediction_accuracy = 0.0

        log_info("æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def _generate_cache_key(self, category: str, identifier: str, params: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_parts = [category, identifier]
        if params:
            # å‚æ•°æ ‡å‡†åŒ–
            sorted_params = sorted(params.items())
            param_str = str(sorted_params)
            param_hash = hashlib.md5(param_str.encode()).hexdigest()[:8]
            key_parts.append(param_hash)
        return ":".join(key_parts)

    def _estimate_size(self, value: Any) -> int:
        """ä¼°ç®—å¯¹è±¡å¤§å°"""
        try:
            return len(pickle.dumps(value))
        except:
            return sys.getsizeof(value)

    def _categorize_by_frequency(self, key: str) -> str:
        """æ ¹æ®è®¿é—®é¢‘ç‡åˆ†ç±»"""
        if key in self.cache:
            hit_count = self.cache[key].hit_count
            if hit_count > 50:
                return 'hot'
            elif hit_count > 10:
                return 'warm'
            else:
                return 'cold'
        return 'cold'

    async def get_agent_result(self, agent_type: str, request_hash: str,
                              params: Dict[str, Any] = None) -> Optional[Any]:
        """è·å–Agentæ‰§è¡Œç»“æœç¼“å­˜"""
        cache_key = self._generate_cache_key("agent", f"{agent_type}:{request_hash}", params)

        with self.lock:
            if cache_key in self.cache:
                entry = self.cache[cache_key]

                # æ£€æŸ¥TTL
                if time.time() - entry.timestamp <= entry.ttl:
                    entry.hit_count += 1
                    entry.last_access = time.time()
                    self.access_history.append((cache_key, time.time(), 'hit'))

                    # è®°å½•è®¿é—®æ¨¡å¼
                    self.access_patterns[cache_key].append(time.time())

                    log_info(f"Agentç¼“å­˜å‘½ä¸­: {agent_type} (hit_count: {entry.hit_count})")
                    return entry.value
                else:
                    # è¿‡æœŸåˆ é™¤
                    del self.cache[cache_key]

        self.access_history.append((cache_key, time.time(), 'miss'))
        return None

    async def cache_agent_result(self, agent_type: str, request_hash: str, result: Any,
                                params: Dict[str, Any] = None, ttl: int = None) -> None:
        """ç¼“å­˜Agentæ‰§è¡Œç»“æœ"""
        cache_key = self._generate_cache_key("agent", f"{agent_type}:{request_hash}", params)
        ttl = ttl or self.ttl

        # ä¼°ç®—å¤§å°
        size_bytes = self._estimate_size(result)

        # æ£€æŸ¥ç¼“å­˜å®¹é‡
        if len(self.cache) >= self.max_size:
            await self._evict_cache()

        with self.lock:
            entry = CacheEntry(
                key=cache_key,
                value=result,
                timestamp=time.time(),
                ttl=ttl,
                size_bytes=size_bytes,
                last_access=time.time()
            )

            self.cache[cache_key] = entry
            log_info(f"Agentç»“æœå·²ç¼“å­˜: {agent_type} (size: {size_bytes} bytes)")

    async def precompile_template(self, template_name: str, template_content: str) -> str:
        """é¢„ç¼–è¯‘å·¥ä½œæµæ¨¡æ¿"""
        template_hash = hashlib.md5(template_content.encode()).hexdigest()

        if template_hash in self.template_cache:
            log_info(f"æ¨¡æ¿ç¼“å­˜å‘½ä¸­: {template_name}")
            return self.template_cache[template_hash]

        # æ¨¡æ‹Ÿæ¨¡æ¿ç¼–è¯‘ä¼˜åŒ–
        compiled_template = template_content.replace('\n', ' ').strip()

        # ç¼“å­˜ç¼–è¯‘ç»“æœ
        self.template_cache[template_hash] = compiled_template
        log_info(f"æ¨¡æ¿é¢„ç¼–è¯‘å®Œæˆ: {template_name}")

        return compiled_template

    async def _evict_cache(self) -> None:
        """æ™ºèƒ½ç¼“å­˜æ·˜æ±°"""
        with self.lock:
            if not self.cache:
                return

            # LFU + LRU æ··åˆç­–ç•¥
            entries = list(self.cache.values())

            # æŒ‰è®¿é—®é¢‘ç‡å’Œæ—¶é—´æ’åº
            entries.sort(key=lambda e: (e.hit_count, e.last_access))

            # æ·˜æ±°æœ€å°‘ä½¿ç”¨çš„25%
            evict_count = max(1, len(entries) // 4)
            for i in range(evict_count):
                if entries[i].key in self.cache:
                    del self.cache[entries[i].key]

        log_info(f"ç¼“å­˜æ·˜æ±°å®Œæˆï¼Œç§»é™¤ {evict_count} ä¸ªæ¡ç›®")

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        with self.lock:
            total_size = sum(entry.size_bytes for entry in self.cache.values())
            hit_rate = 0.0

            if len(self.access_history) > 100:
                recent_hits = sum(1 for _, _, status in list(self.access_history)[-100:] if status == 'hit')
                hit_rate = recent_hits / 100 * 100

            return {
                'total_entries': len(self.cache),
                'total_size_mb': total_size / 1024 / 1024,
                'hit_rate': f"{hit_rate:.1f}%",
                'template_cache_size': len(self.template_cache),
                'access_history_size': len(self.access_history),
                'prediction_accuracy': f"{self.prediction_accuracy:.1f}%"
            }

class ResourcePoolManager:
    """èµ„æºæ± ç®¡ç†å™¨ - å¤ç”¨è¿æ¥å’Œä¸Šä¸‹æ–‡"""

    def __init__(self):
        self.pools: Dict[str, List[Any]] = defaultdict(list)
        self.pool_configs: Dict[str, Dict[str, int]] = {}
        self.pool_stats: Dict[str, Dict[str, int]] = defaultdict(lambda: {
            'created': 0, 'reused': 0, 'destroyed': 0, 'active': 0
        })
        self.lock = threading.RLock()

        # é»˜è®¤æ± é…ç½®
        self._setup_default_pools()

        log_info("èµ„æºæ± ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _setup_default_pools(self):
        """è®¾ç½®é»˜è®¤èµ„æºæ± """
        self.pool_configs.update({
            'dict': {'initial': 50, 'max': 200, 'factory': dict},
            'list': {'initial': 50, 'max': 200, 'factory': list},
            'execution_context': {'initial': 20, 'max': 100, 'factory': lambda: AgentExecutionContext('', '', 0.0, {})},
            'thread_executor': {'initial': 2, 'max': 10, 'factory': lambda: concurrent.futures.ThreadPoolExecutor(max_workers=4)},
        })

        # é¢„åˆ†é…å¯¹è±¡
        for pool_name, config in self.pool_configs.items():
            for _ in range(config['initial']):
                obj = config['factory']()
                self.pools[pool_name].append(obj)
                self.pool_stats[pool_name]['created'] += 1

    @contextmanager
    def get_resource(self, pool_name: str):
        """ä»èµ„æºæ± è·å–èµ„æº"""
        with self.lock:
            if self.pools[pool_name]:
                resource = self.pools[pool_name].pop()
                self.pool_stats[pool_name]['reused'] += 1
                self.pool_stats[pool_name]['active'] += 1
            else:
                # åˆ›å»ºæ–°èµ„æº
                if pool_name in self.pool_configs:
                    resource = self.pool_configs[pool_name]['factory']()
                    self.pool_stats[pool_name]['created'] += 1
                    self.pool_stats[pool_name]['active'] += 1
                else:
                    raise ValueError(f"æœªçŸ¥èµ„æºæ± : {pool_name}")

        try:
            yield resource
        finally:
            self.return_resource(pool_name, resource)

    def return_resource(self, pool_name: str, resource: Any):
        """å½’è¿˜èµ„æºåˆ°æ± """
        with self.lock:
            if len(self.pools[pool_name]) < self.pool_configs.get(pool_name, {}).get('max', 100):
                # é‡ç½®èµ„æºçŠ¶æ€
                if hasattr(resource, 'clear'):
                    resource.clear()
                elif hasattr(resource, 'reset'):
                    resource.reset()

                self.pools[pool_name].append(resource)
                self.pool_stats[pool_name]['active'] -= 1
            else:
                # è¶…è¿‡æœ€å¤§å®¹é‡ï¼Œé”€æ¯èµ„æº
                self.pool_stats[pool_name]['destroyed'] += 1
                self.pool_stats[pool_name]['active'] -= 1
                if hasattr(resource, 'shutdown'):
                    resource.shutdown(wait=False)

    def get_pool_stats(self) -> Dict[str, Any]:
        """è·å–æ± ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            return {
                pool_name: {
                    'available': len(self.pools[pool_name]),
                    'stats': dict(stats)
                }
                for pool_name, stats in self.pool_stats.items()
            }

class GitOperationOptimizer:
    """Gitæ“ä½œä¼˜åŒ–å™¨ - æ‰¹é‡åŒ–å’Œç¼“å­˜åˆ©ç”¨"""

    def __init__(self):
        self.batch_operations = deque()
        self.batch_lock = threading.Lock()
        self.batch_timer = None
        self.batch_interval = 2.0  # 2ç§’æ‰¹é‡å¤„ç†

        # Gitç¼“å­˜é›†æˆ
        self.git_cache = performance_cache.git_cache

        # æ“ä½œç»Ÿè®¡
        self.stats = {
            'batched_operations': 0,
            'cache_hits': 0,
            'single_operations': 0,
            'optimization_ratio': 0.0
        }

        log_info("Gitæ“ä½œä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")

    def queue_git_operation(self, operation: str, args: List[str],
                           callback: Optional[Callable] = None, priority: int = 5) -> str:
        """é˜Ÿåˆ—åŒ–Gitæ“ä½œç”¨äºæ‰¹é‡å¤„ç†"""
        operation_id = f"{operation}_{int(time.time() * 1000000)}"

        with self.batch_lock:
            self.batch_operations.append({
                'id': operation_id,
                'operation': operation,
                'args': args,
                'callback': callback,
                'priority': priority,
                'timestamp': time.time()
            })

        # å¯åŠ¨æ‰¹é‡å¤„ç†å®šæ—¶å™¨
        self._schedule_batch_processing()

        return operation_id

    def _schedule_batch_processing(self):
        """è°ƒåº¦æ‰¹é‡å¤„ç†"""
        if self.batch_timer is None or not self.batch_timer.is_alive():
            self.batch_timer = threading.Timer(self.batch_interval, self._process_batch)
            self.batch_timer.start()

    def _process_batch(self):
        """å¤„ç†æ‰¹é‡Gitæ“ä½œ"""
        with self.batch_lock:
            if not self.batch_operations:
                return

            # æŒ‰ä¼˜å…ˆçº§å’Œæ“ä½œç±»å‹åˆ†ç»„
            operations_by_type = defaultdict(list)
            for op in self.batch_operations:
                operations_by_type[op['operation']].append(op)

            self.batch_operations.clear()

        # ä¼˜åŒ–æ‰¹é‡æ“ä½œ
        for operation_type, ops in operations_by_type.items():
            self._execute_batch_operations(operation_type, ops)

        self.batch_timer = None

    def _execute_batch_operations(self, operation_type: str, operations: List[Dict]):
        """æ‰§è¡Œæ‰¹é‡æ“ä½œ"""
        if operation_type == 'status':
            # çŠ¶æ€æŸ¥è¯¢å¯ä»¥åˆå¹¶
            self._batch_status_operations(operations)
        elif operation_type == 'log':
            # æ—¥å¿—æŸ¥è¯¢å¯ä»¥åˆå¹¶
            self._batch_log_operations(operations)
        else:
            # å…¶ä»–æ“ä½œé€ä¸ªæ‰§è¡Œ
            for op in operations:
                self._execute_single_operation(op)

        self.stats['batched_operations'] += len(operations)

    def _batch_status_operations(self, operations: List[Dict]):
        """æ‰¹é‡çŠ¶æ€æ“ä½œ"""
        # åˆå¹¶çŠ¶æ€æŸ¥è¯¢ï¼Œä¸€æ¬¡æ€§è·å–å®Œæ•´çŠ¶æ€
        try:
            # æ¨¡æ‹Ÿæ‰¹é‡GitçŠ¶æ€è·å–
            batch_result = {
                'status': 'clean',
                'branch': 'main',
                'ahead': 0,
                'behind': 0,
                'staged': [],
                'modified': [],
                'untracked': []
            }

            # ä¸ºæ‰€æœ‰æ“ä½œè¿”å›ç»“æœ
            for op in operations:
                if op['callback']:
                    op['callback'](batch_result)

            log_info(f"æ‰¹é‡çŠ¶æ€æŸ¥è¯¢å®Œæˆ: {len(operations)} ä¸ªæ“ä½œ")

        except Exception as e:
            log_error(f"æ‰¹é‡çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {e}")

    def _batch_log_operations(self, operations: List[Dict]):
        """æ‰¹é‡æ—¥å¿—æ“ä½œ"""
        # åˆå¹¶æ—¥å¿—æŸ¥è¯¢å‚æ•°
        max_count = max((int(op['args'][1]) if len(op['args']) > 1 else 10) for op in operations)

        try:
            # æ¨¡æ‹Ÿæ‰¹é‡Gitæ—¥å¿—è·å–
            batch_result = [
                {'hash': 'abc123', 'message': 'commit message', 'author': 'user', 'date': '2024-01-17'}
            ] * max_count

            # ä¸ºæ¯ä¸ªæ“ä½œç­›é€‰å¯¹åº”ç»“æœ
            for op in operations:
                count = int(op['args'][1]) if len(op['args']) > 1 else 10
                result = batch_result[:count]

                if op['callback']:
                    op['callback'](result)

            log_info(f"æ‰¹é‡æ—¥å¿—æŸ¥è¯¢å®Œæˆ: {len(operations)} ä¸ªæ“ä½œ")

        except Exception as e:
            log_error(f"æ‰¹é‡æ—¥å¿—æŸ¥è¯¢å¤±è´¥: {e}")

    def _execute_single_operation(self, operation: Dict):
        """æ‰§è¡Œå•ä¸ªGitæ“ä½œ"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{operation['operation']}:{':'.join(operation['args'])}"
            cached_result = self.git_cache.get_cached_result(cache_key)

            if cached_result:
                self.stats['cache_hits'] += 1
                if operation['callback']:
                    operation['callback'](cached_result)
                return

            # æ‰§è¡Œå®é™…Gitæ“ä½œ (æ¨¡æ‹Ÿ)
            result = f"Git {operation['operation']} result"

            # ç¼“å­˜ç»“æœ
            self.git_cache.cache_result(cache_key, result)

            if operation['callback']:
                operation['callback'](result)

            self.stats['single_operations'] += 1

        except Exception as e:
            log_error(f"Gitæ“ä½œæ‰§è¡Œå¤±è´¥ {operation['operation']}: {e}")

    def get_optimization_stats(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–ç»Ÿè®¡"""
        total_ops = self.stats['batched_operations'] + self.stats['single_operations']
        optimization_ratio = (self.stats['batched_operations'] / total_ops * 100) if total_ops > 0 else 0

        return {
            **self.stats,
            'optimization_ratio': f"{optimization_ratio:.1f}%",
            'pending_operations': len(self.batch_operations)
        }

class MemoryOptimizer:
    """å†…å­˜ä¼˜åŒ–å™¨ - æ™ºèƒ½GCå’Œå¯¹è±¡å¤ç”¨"""

    def __init__(self):
        self.gc_stats = {'collections': 0, 'freed_objects': 0, 'freed_memory_mb': 0.0}
        self.object_pools: Dict[type, List[Any]] = defaultdict(list)
        self.weak_refs: Dict[str, Any] = {}
        self.memory_pressure_threshold = 80.0  # 80%å†…å­˜ä½¿ç”¨ç‡

        # è®¾ç½®GCè°ƒä¼˜
        self._tune_gc()

        log_info("å†…å­˜ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")

    def _tune_gc(self):
        """è°ƒä¼˜åƒåœ¾æ”¶é›†å™¨"""
        # è®¾ç½®æ›´æ¿€è¿›çš„GCé˜ˆå€¼ä»¥å‡å°‘å†…å­˜ç¢ç‰‡
        gc.set_threshold(700, 10, 10)

        # å¯ç”¨è‡ªåŠ¨åƒåœ¾å›æ”¶
        gc.enable()

    async def smart_gc(self, force: bool = False) -> Dict[str, Any]:
        """æ™ºèƒ½åƒåœ¾å›æ”¶"""
        # æ£€æŸ¥å†…å­˜å‹åŠ›
        memory_percent = psutil.virtual_memory().percent

        if not force and memory_percent < self.memory_pressure_threshold:
            return {'message': 'Memory pressure low, GC skipped', 'memory_percent': memory_percent}

        before_memory = psutil.Process().memory_info().rss / 1024 / 1024

        # æ‰§è¡Œåƒåœ¾å›æ”¶
        collected = gc.collect()

        after_memory = psutil.Process().memory_info().rss / 1024 / 1024
        freed_memory = before_memory - after_memory

        # æ›´æ–°ç»Ÿè®¡
        self.gc_stats['collections'] += 1
        self.gc_stats['freed_objects'] += collected
        self.gc_stats['freed_memory_mb'] += freed_memory

        result = {
            'objects_collected': collected,
            'memory_freed_mb': freed_memory,
            'before_memory_mb': before_memory,
            'after_memory_mb': after_memory,
            'memory_percent': memory_percent
        }

        log_info(f"æ™ºèƒ½GCå®Œæˆ: å›æ”¶ {collected} å¯¹è±¡, é‡Šæ”¾ {freed_memory:.2f}MB å†…å­˜")
        return result

    @contextmanager
    def managed_object(self, obj_type: type, *args, **kwargs):
        """ç®¡ç†å¯¹è±¡ç”Ÿå‘½å‘¨æœŸ"""
        # ä»å¯¹è±¡æ± è·å–æˆ–åˆ›å»º
        if self.object_pools[obj_type]:
            obj = self.object_pools[obj_type].pop()
            if hasattr(obj, 'reset'):
                obj.reset()
        else:
            obj = obj_type(*args, **kwargs)

        try:
            yield obj
        finally:
            # å½’è¿˜åˆ°å¯¹è±¡æ± 
            if len(self.object_pools[obj_type]) < 50:  # é™åˆ¶æ± å¤§å°
                self.object_pools[obj_type].append(obj)

    def register_weak_reference(self, key: str, obj: Any) -> None:
        """æ³¨å†Œå¼±å¼•ç”¨é¿å…å¾ªç¯å¼•ç”¨"""
        import weakref
        self.weak_refs[key] = weakref.ref(obj)

    def cleanup_weak_references(self) -> int:
        """æ¸…ç†æ­»äº¡çš„å¼±å¼•ç”¨"""
        dead_refs = []
        for key, ref in self.weak_refs.items():
            if ref() is None:
                dead_refs.append(key)

        for key in dead_refs:
            del self.weak_refs[key]

        return len(dead_refs)

    def get_memory_stats(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ç»Ÿè®¡"""
        process = psutil.Process()
        memory_info = process.memory_info()

        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'percent': process.memory_percent(),
            'gc_stats': self.gc_stats.copy(),
            'object_pools': {str(k): len(v) for k, v in self.object_pools.items()},
            'weak_refs_count': len(self.weak_refs)
        }

class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•ç³»ç»Ÿ"""

    def __init__(self):
        self.benchmarks: Dict[str, List[float]] = defaultdict(list)
        self.baselines: Dict[str, float] = {}
        self.regression_threshold = 0.2  # 20%æ€§èƒ½å›å½’é˜ˆå€¼

        log_info("æ€§èƒ½åŸºå‡†æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def record_benchmark(self, test_name: str, execution_time: float,
                        metadata: Dict[str, Any] = None) -> None:
        """è®°å½•åŸºå‡†æµ‹è¯•ç»“æœ"""
        self.benchmarks[test_name].append(execution_time)

        # ä¿æŒæœ€è¿‘100ä¸ªç»“æœ
        if len(self.benchmarks[test_name]) > 100:
            self.benchmarks[test_name] = self.benchmarks[test_name][-100:]

        log_info(f"åŸºå‡†æµ‹è¯•è®°å½•: {test_name} = {execution_time:.3f}s")

    def establish_baseline(self, test_name: str) -> None:
        """å»ºç«‹æ€§èƒ½åŸºçº¿"""
        if test_name in self.benchmarks and len(self.benchmarks[test_name]) >= 10:
            # ä½¿ç”¨æœ€è¿‘10æ¬¡çš„ä¸­ä½æ•°ä½œä¸ºåŸºçº¿
            recent_results = self.benchmarks[test_name][-10:]
            self.baselines[test_name] = statistics.median(recent_results)
            log_info(f"åŸºçº¿å»ºç«‹: {test_name} = {self.baselines[test_name]:.3f}s")

    def check_regression(self, test_name: str) -> Optional[Dict[str, Any]]:
        """æ£€æŸ¥æ€§èƒ½å›å½’"""
        if test_name not in self.baselines or test_name not in self.benchmarks:
            return None

        current_result = self.benchmarks[test_name][-1]
        baseline = self.baselines[test_name]

        regression_ratio = (current_result - baseline) / baseline

        if regression_ratio > self.regression_threshold:
            return {
                'test_name': test_name,
                'current': current_result,
                'baseline': baseline,
                'regression_ratio': regression_ratio,
                'severity': 'high' if regression_ratio > 0.5 else 'medium'
            }

        return None

    def run_comprehensive_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œå…¨é¢åŸºå‡†æµ‹è¯•"""
        results = {}

        # 1. Agentæ‰§è¡ŒåŸºå‡†æµ‹è¯•
        start_time = time.perf_counter()
        # æ¨¡æ‹ŸAgentæ‰§è¡Œ
        time.sleep(0.1)  # æ¨¡æ‹Ÿ100msæ‰§è¡Œæ—¶é—´
        agent_time = time.perf_counter() - start_time
        self.record_benchmark('agent_execution', agent_time)
        results['agent_execution'] = agent_time

        # 2. ç¼“å­˜æ€§èƒ½åŸºå‡†æµ‹è¯•
        start_time = time.perf_counter()
        # æµ‹è¯•ç¼“å­˜è¯»å†™æ€§èƒ½
        for i in range(100):
            performance_cache.git_cache.cache_result(f'test_key_{i}', f'test_value_{i}')
        for i in range(100):
            performance_cache.git_cache.get_cached_result(f'test_key_{i}')
        cache_time = time.perf_counter() - start_time
        self.record_benchmark('cache_performance', cache_time)
        results['cache_performance'] = cache_time

        # 3. Gitæ“ä½œåŸºå‡†æµ‹è¯•
        start_time = time.perf_counter()
        # æ¨¡æ‹ŸGitæ“ä½œ
        time.sleep(0.05)  # æ¨¡æ‹Ÿ50ms Gitæ“ä½œ
        git_time = time.perf_counter() - start_time
        self.record_benchmark('git_operations', git_time)
        results['git_operations'] = git_time

        # 4. å†…å­˜åˆ†é…åŸºå‡†æµ‹è¯•
        start_time = time.perf_counter()
        # æµ‹è¯•å†…å­˜åˆ†é…æ€§èƒ½
        test_objects = [{'data': f'item_{i}'} for i in range(1000)]
        del test_objects
        memory_time = time.perf_counter() - start_time
        self.record_benchmark('memory_allocation', memory_time)
        results['memory_allocation'] = memory_time

        # æ£€æŸ¥å›å½’
        regressions = []
        for test_name in results.keys():
            regression = self.check_regression(test_name)
            if regression:
                regressions.append(regression)

        return {
            'results': results,
            'regressions': regressions,
            'timestamp': datetime.now().isoformat()
        }

    def get_benchmark_summary(self) -> Dict[str, Any]:
        """è·å–åŸºå‡†æµ‹è¯•æ‘˜è¦"""
        summary = {}

        for test_name, results in self.benchmarks.items():
            if results:
                summary[test_name] = {
                    'count': len(results),
                    'latest': results[-1],
                    'average': statistics.mean(results),
                    'median': statistics.median(results),
                    'min': min(results),
                    'max': max(results),
                    'baseline': self.baselines.get(test_name, 0.0)
                }

        return summary

class EnhancedPerformanceOptimizer:
    """å¢å¼ºæ€§èƒ½ä¼˜åŒ–å™¨ - ç»Ÿä¸€æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½"""

    def __init__(self):
        self.cache_system = IntelligentCacheSystem()
        self.resource_manager = ResourcePoolManager()
        self.git_optimizer = GitOperationOptimizer()
        self.memory_optimizer = MemoryOptimizer()
        self.benchmark_system = PerformanceBenchmark()

        # è‡ªåŠ¨ä¼˜åŒ–é…ç½®
        self.auto_optimization = False
        self.optimization_interval = 300  # 5åˆ†é’Ÿ
        self.optimization_thread = None

        # ä¼˜åŒ–å†å²
        self.optimization_history: List[OptimizationResult] = []

        # æ€§èƒ½æŒ‡æ ‡
        self.performance_metrics = {
            'response_time_p95': deque(maxlen=1000),
            'throughput_rps': deque(maxlen=1000),
            'memory_usage_mb': deque(maxlen=1000),
            'cache_hit_rate': deque(maxlen=1000)
        }

        log_info("å¢å¼ºæ€§èƒ½ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")

    async def optimize_agent_execution(self, agent_type: str, request_params: Dict[str, Any]) -> Any:
        """ä¼˜åŒ–Agentæ‰§è¡Œ"""
        # ç”Ÿæˆè¯·æ±‚å“ˆå¸Œ
        request_hash = hashlib.md5(str(request_params).encode()).hexdigest()

        # å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
        cached_result = await self.cache_system.get_agent_result(agent_type, request_hash, request_params)
        if cached_result:
            return cached_result

        # ä½¿ç”¨èµ„æºæ± è·å–æ‰§è¡Œä¸Šä¸‹æ–‡
        with self.resource_manager.get_resource('execution_context') as context:
            context.agent_id = agent_type
            context.request_id = request_hash
            context.start_time = time.perf_counter()
            context.parameters = request_params

            try:
                # æ¨¡æ‹ŸAgentæ‰§è¡Œ
                await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿ100msæ‰§è¡Œæ—¶é—´
                result = {"status": "success", "data": f"Result from {agent_type}"}

                # è®°å½•æ‰§è¡Œæ—¶é—´
                context.execution_time = time.perf_counter() - context.start_time

                # ç¼“å­˜ç»“æœ
                await self.cache_system.cache_agent_result(agent_type, request_hash, result, request_params)

                # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                self.performance_metrics['response_time_p95'].append(context.execution_time * 1000)  # ms

                return result

            except Exception as e:
                log_error(f"Agentæ‰§è¡Œå¤±è´¥ {agent_type}: {e}")
                raise

    def batch_git_operations(self, operations: List[Tuple[str, List[str]]]) -> List[str]:
        """æ‰¹é‡Gitæ“ä½œ"""
        operation_ids = []

        for operation, args in operations:
            op_id = self.git_optimizer.queue_git_operation(operation, args)
            operation_ids.append(op_id)

        return operation_ids

    async def optimize_memory_usage(self) -> Dict[str, Any]:
        """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        before_stats = self.memory_optimizer.get_memory_stats()

        # æ‰§è¡Œå†…å­˜ä¼˜åŒ–
        gc_result = await self.memory_optimizer.smart_gc()

        # æ¸…ç†å¼±å¼•ç”¨
        dead_refs = self.memory_optimizer.cleanup_weak_references()

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        await self.cache_system._evict_cache()

        after_stats = self.memory_optimizer.get_memory_stats()

        # è®°å½•ä¼˜åŒ–ç»“æœ
        improvement = before_stats['rss_mb'] - after_stats['rss_mb']
        optimization_result = OptimizationResult(
            category='memory',
            before_metric=before_stats['rss_mb'],
            after_metric=after_stats['rss_mb'],
            improvement=improvement,
            description=f"é‡Šæ”¾ {improvement:.2f}MB å†…å­˜, æ¸…ç† {dead_refs} ä¸ªå¼±å¼•ç”¨"
        )

        self.optimization_history.append(optimization_result)

        return {
            'before_stats': before_stats,
            'after_stats': after_stats,
            'gc_result': gc_result,
            'dead_refs_cleaned': dead_refs,
            'improvement_mb': improvement
        }

    def start_auto_optimization(self) -> None:
        """å¯åŠ¨è‡ªåŠ¨ä¼˜åŒ–"""
        if self.auto_optimization:
            return

        self.auto_optimization = True

        def optimization_loop():
            while self.auto_optimization:
                try:
                    # å¼‚æ­¥è¿è¡Œä¼˜åŒ–ä»»åŠ¡
                    asyncio.run(self._run_optimization_cycle())
                    time.sleep(self.optimization_interval)
                except Exception as e:
                    log_error(f"è‡ªåŠ¨ä¼˜åŒ–å¾ªç¯å¼‚å¸¸: {e}")
                    time.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿ

        self.optimization_thread = threading.Thread(target=optimization_loop, daemon=True)
        self.optimization_thread.start()

        log_info("è‡ªåŠ¨æ€§èƒ½ä¼˜åŒ–å·²å¯åŠ¨")

    def stop_auto_optimization(self) -> None:
        """åœæ­¢è‡ªåŠ¨ä¼˜åŒ–"""
        self.auto_optimization = False
        log_info("è‡ªåŠ¨æ€§èƒ½ä¼˜åŒ–å·²åœæ­¢")

    async def _run_optimization_cycle(self) -> None:
        """è¿è¡Œä¼˜åŒ–å‘¨æœŸ"""
        # æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
        current_metrics = performance_monitor.get_current_metrics()

        # å†³å®šæ˜¯å¦éœ€è¦ä¼˜åŒ–
        needs_optimization = False

        if 'memory_usage' in current_metrics:
            memory_usage = current_metrics['memory_usage'].value
            if memory_usage > 80:  # å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡80%
                needs_optimization = True
                await self.optimize_memory_usage()

        if 'cache_hit_rate' in current_metrics:
            hit_rate = current_metrics['cache_hit_rate'].value
            if hit_rate < 70:  # ç¼“å­˜å‘½ä¸­ç‡ä½äº70%
                needs_optimization = True
                await self.cache_system._evict_cache()

        if needs_optimization:
            log_info("è‡ªåŠ¨ä¼˜åŒ–å‘¨æœŸå®Œæˆ")

    def run_performance_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        return self.benchmark_system.run_comprehensive_benchmark()

    def get_comprehensive_report(self) -> Dict[str, Any]:
        """è·å–å…¨é¢æ€§èƒ½æŠ¥å‘Š"""
        return {
            'timestamp': datetime.now().isoformat(),
            'cache_stats': self.cache_system.get_cache_stats(),
            'resource_pool_stats': self.resource_manager.get_pool_stats(),
            'git_optimization_stats': self.git_optimizer.get_optimization_stats(),
            'memory_stats': self.memory_optimizer.get_memory_stats(),
            'benchmark_summary': self.benchmark_system.get_benchmark_summary(),
            'optimization_history': [
                {
                    'category': opt.category,
                    'improvement': opt.improvement,
                    'description': opt.description,
                    'timestamp': opt.timestamp.isoformat()
                }
                for opt in self.optimization_history[-10:]  # æœ€è¿‘10æ¬¡ä¼˜åŒ–
            ],
            'performance_metrics': {
                name: {
                    'count': len(values),
                    'latest': values[-1] if values else 0,
                    'average': statistics.mean(values) if values else 0,
                    'p95': statistics.quantiles(values, n=20)[18] if len(values) > 20 else (values[-1] if values else 0)
                }
                for name, values in self.performance_metrics.items()
            }
        }

# å…¨å±€å¢å¼ºæ€§èƒ½ä¼˜åŒ–å™¨å®ä¾‹
enhanced_performance_optimizer = EnhancedPerformanceOptimizer()

# ä¾¿æ·å‡½æ•°
async def optimize_agent_execution(agent_type: str, params: Dict[str, Any]) -> Any:
    """ä¾¿æ·å‡½æ•°ï¼šä¼˜åŒ–Agentæ‰§è¡Œ"""
    return await enhanced_performance_optimizer.optimize_agent_execution(agent_type, params)

def batch_git_operations(operations: List[Tuple[str, List[str]]]) -> List[str]:
    """ä¾¿æ·å‡½æ•°ï¼šæ‰¹é‡Gitæ“ä½œ"""
    return enhanced_performance_optimizer.batch_git_operations(operations)

async def optimize_memory() -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šä¼˜åŒ–å†…å­˜"""
    return await enhanced_performance_optimizer.optimize_memory_usage()

def start_performance_optimization() -> None:
    """ä¾¿æ·å‡½æ•°ï¼šå¯åŠ¨æ€§èƒ½ä¼˜åŒ–"""
    enhanced_performance_optimizer.start_auto_optimization()

def get_performance_report() -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–æ€§èƒ½æŠ¥å‘Š"""
    return enhanced_performance_optimizer.get_comprehensive_report()

def run_benchmark() -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šè¿è¡ŒåŸºå‡†æµ‹è¯•"""
    return enhanced_performance_optimizer.run_performance_benchmark()

# æ€§èƒ½ä¼˜åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨
@asynccontextmanager
async def optimized_execution():
    """ä¼˜åŒ–æ‰§è¡Œä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    start_time = time.perf_counter()

    # æ‰§è¡Œå‰ä¼˜åŒ–
    await enhanced_performance_optimizer.memory_optimizer.smart_gc()

    try:
        yield enhanced_performance_optimizer
    finally:
        # æ‰§è¡Œåæ¸…ç†
        execution_time = time.perf_counter() - start_time
        enhanced_performance_optimizer.performance_metrics['response_time_p95'].append(execution_time * 1000)

        # å¦‚æœæ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œè§¦å‘ä¼˜åŒ–
        if execution_time > 1.0:  # è¶…è¿‡1ç§’
            log_warning(f"æ‰§è¡Œæ—¶é—´è¿‡é•¿: {execution_time:.3f}sï¼Œè§¦å‘ä¼˜åŒ–")
            await enhanced_performance_optimizer.optimize_memory_usage()

if __name__ == "__main__":
    # æµ‹è¯•æ€§èƒ½ä¼˜åŒ–å™¨
    async def test_optimizer():
        print("ğŸš€ æµ‹è¯•å¢å¼ºæ€§èƒ½ä¼˜åŒ–å™¨")

        # å¯åŠ¨è‡ªåŠ¨ä¼˜åŒ–
        enhanced_performance_optimizer.start_auto_optimization()

        # æµ‹è¯•Agentæ‰§è¡Œä¼˜åŒ–
        result = await optimize_agent_execution('test-agent', {'param1': 'value1'})
        print(f"Agentæ‰§è¡Œç»“æœ: {result}")

        # æµ‹è¯•æ‰¹é‡Gitæ“ä½œ
        git_ops = [
            ('status', []),
            ('log', ['--oneline', '10']),
            ('branch', ['-a'])
        ]
        operation_ids = batch_git_operations(git_ops)
        print(f"Gitæ“ä½œé˜Ÿåˆ—: {operation_ids}")

        # ç­‰å¾…æ‰¹é‡å¤„ç†
        await asyncio.sleep(3)

        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        benchmark_results = run_benchmark()
        print(f"åŸºå‡†æµ‹è¯•ç»“æœ: {benchmark_results}")

        # è·å–å…¨é¢æŠ¥å‘Š
        report = get_performance_report()
        print(f"æ€§èƒ½æŠ¥å‘Šæ‘˜è¦:")
        print(f"  ç¼“å­˜å‘½ä¸­ç‡: {report['cache_stats']['hit_rate']}")
        print(f"  å†…å­˜ä½¿ç”¨: {report['memory_stats']['rss_mb']:.2f}MB")
        print(f"  ä¼˜åŒ–å†å²: {len(report['optimization_history'])} æ¬¡")

        # åœæ­¢è‡ªåŠ¨ä¼˜åŒ–
        enhanced_performance_optimizer.stop_auto_optimization()

    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_optimizer())