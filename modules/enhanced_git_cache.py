#!/usr/bin/env python3
"""
å¢å¼ºGitç¼“å­˜ä¼˜åŒ–å™¨
ä¸“ä¸ºPerfect21ä¼˜åŒ–çš„Gitæ“ä½œç¼“å­˜å’Œæ‰¹é‡å¤„ç†ç³»ç»Ÿ
"""

import os
import sys
import time
import asyncio
import threading
import hashlib
import pickle
from typing import Dict, Any, List, Optional, Callable, Tuple
from datetime import datetime, timedelta
from collections import defaultdict, deque
from dataclasses import dataclass, field
import subprocess
import json

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from modules.logger import log_info, log_error, log_warning
from modules.config import config

@dataclass
class GitCacheEntry:
    """Gitç¼“å­˜æ¡ç›®"""
    command: str
    args: List[str]
    result: Any
    timestamp: float
    ttl: float = 30.0  # 30ç§’é»˜è®¤TTL
    hit_count: int = 0
    last_access: float = 0.0
    project_root: str = "."

@dataclass
class BatchOperation:
    """æ‰¹é‡æ“ä½œ"""
    operation_id: str
    command: str
    args: List[str]
    callback: Optional[Callable] = None
    priority: int = 5
    timestamp: float = field(default_factory=time.time)
    project_root: str = "."

class EnhancedGitCache:
    """å¢å¼ºGitç¼“å­˜ç³»ç»Ÿ"""

    def __init__(self):
        self.cache: Dict[str, GitCacheEntry] = {}
        self.lock = threading.RLock()

        # ç¼“å­˜é…ç½®
        self.max_cache_size = config.get('performance.git_cache.max_size', 1000)
        self.default_ttl = config.get('performance.git_cache.default_ttl', 30)
        self.enable_compression = config.get('performance.git_cache.compression', True)

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0,
            'total_requests': 0
        }

        # æ™ºèƒ½ç¼“å­˜ç­–ç•¥
        self.high_frequency_commands = {'status', 'branch', 'log', 'diff'}
        self.long_cache_commands = {'log', 'blame', 'show'}
        self.short_cache_commands = {'status', 'diff', 'stash'}

        log_info("å¢å¼ºGitç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def _generate_cache_key(self, command: str, args: List[str], project_root: str = ".") -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # æ ‡å‡†åŒ–å‚æ•°
        normalized_args = []
        for arg in args:
            # è·¯å¾„æ ‡å‡†åŒ–
            if os.path.exists(arg):
                normalized_args.append(os.path.abspath(arg))
            else:
                normalized_args.append(arg)

        key_parts = [project_root, command] + normalized_args
        key_str = "|".join(str(part) for part in key_parts)

        # å¯¹é•¿é”®è¿›è¡Œå“ˆå¸Œ
        if len(key_str) > 100:
            return f"{command}:{hashlib.md5(key_str.encode()).hexdigest()}"
        return key_str

    def _determine_ttl(self, command: str, args: List[str]) -> float:
        """æ™ºèƒ½ç¡®å®šTTL"""
        # æ ¹æ®å‘½ä»¤ç±»å‹è®¾ç½®ä¸åŒçš„TTL
        if command in self.long_cache_commands:
            return 300  # 5åˆ†é’Ÿ
        elif command in self.short_cache_commands:
            return 10   # 10ç§’
        elif command == 'log' and any('--since' in arg or '--until' in arg for arg in args):
            return 600  # æ—¶é—´èŒƒå›´æŸ¥è¯¢ç¼“å­˜æ›´é•¿æ—¶é—´
        else:
            return self.default_ttl

    def _should_cache(self, command: str, args: List[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç¼“å­˜"""
        # ä¸ç¼“å­˜çš„å‘½ä»¤
        no_cache_commands = {'add', 'commit', 'push', 'pull', 'merge', 'rebase', 'reset'}
        if command in no_cache_commands:
            return False

        # ä¸ç¼“å­˜åŒ…å«å˜æ›´æ“ä½œçš„å‘½ä»¤
        change_args = {'-f', '--force', '--delete', '--prune'}
        if any(arg in change_args for arg in args):
            return False

        return True

    def _compress_result(self, result: Any) -> bytes:
        """å‹ç¼©ç»“æœ"""
        if self.enable_compression:
            try:
                import gzip
                pickled = pickle.dumps(result)
                return gzip.compress(pickled)
            except:
                return pickle.dumps(result)
        return pickle.dumps(result)

    def _decompress_result(self, compressed_data: bytes) -> Any:
        """è§£å‹ç»“æœ"""
        if self.enable_compression:
            try:
                import gzip
                pickled = gzip.decompress(compressed_data)
                return pickle.loads(pickled)
            except:
                return pickle.loads(compressed_data)
        return pickle.loads(compressed_data)

    def get_cached_result(self, command: str, args: List[str], project_root: str = ".") -> Optional[Any]:
        """è·å–ç¼“å­˜çš„Gitå‘½ä»¤ç»“æœ"""
        if not self._should_cache(command, args):
            return None

        cache_key = self._generate_cache_key(command, args, project_root)

        with self.lock:
            self.stats['total_requests'] += 1

            if cache_key in self.cache:
                entry = self.cache[cache_key]

                # æ£€æŸ¥TTL
                if time.time() - entry.timestamp <= entry.ttl:
                    entry.hit_count += 1
                    entry.last_access = time.time()
                    self.stats['hits'] += 1

                    log_info(f"Gitç¼“å­˜å‘½ä¸­: {command} {' '.join(args[:3])}... (hit_count: {entry.hit_count})")
                    return entry.result
                else:
                    # è¿‡æœŸåˆ é™¤
                    del self.cache[cache_key]
                    self.stats['evictions'] += 1

            self.stats['misses'] += 1
            return None

    def cache_result(self, command: str, args: List[str], result: Any, project_root: str = ".") -> None:
        """ç¼“å­˜Gitå‘½ä»¤ç»“æœ"""
        if not self._should_cache(command, args):
            return

        cache_key = self._generate_cache_key(command, args, project_root)
        ttl = self._determine_ttl(command, args)

        # æ£€æŸ¥ç¼“å­˜å®¹é‡
        if len(self.cache) >= self.max_cache_size:
            self._evict_cache()

        with self.lock:
            entry = GitCacheEntry(
                command=command,
                args=args.copy(),
                result=result,
                timestamp=time.time(),
                ttl=ttl,
                last_access=time.time(),
                project_root=project_root
            )

            self.cache[cache_key] = entry
            log_info(f"Gitç»“æœå·²ç¼“å­˜: {command} (TTL: {ttl}s)")

    def _evict_cache(self) -> None:
        """ç¼“å­˜æ·˜æ±°"""
        with self.lock:
            if not self.cache:
                return

            # LFU + LRU æ··åˆç­–ç•¥
            entries = list(self.cache.items())

            # æŒ‰ç…§è®¿é—®é¢‘ç‡å’Œæ—¶é—´æ’åº
            entries.sort(key=lambda x: (x[1].hit_count, x[1].last_access))

            # æ·˜æ±°æœ€å°‘ä½¿ç”¨çš„25%
            evict_count = max(1, len(entries) // 4)
            for i in range(evict_count):
                key = entries[i][0]
                if key in self.cache:
                    del self.cache[key]
                    self.stats['evictions'] += 1

        log_info(f"Gitç¼“å­˜æ·˜æ±°: ç§»é™¤ {evict_count} ä¸ªæ¡ç›®")

    def invalidate_status_cache(self, project_root: str = ".") -> None:
        """ä½¿çŠ¶æ€ç›¸å…³ç¼“å­˜å¤±æ•ˆ"""
        status_commands = {'status', 'diff', 'log'}

        with self.lock:
            keys_to_remove = []
            for key, entry in self.cache.items():
                if (entry.project_root == project_root and
                    entry.command in status_commands):
                    keys_to_remove.append(key)

            for key in keys_to_remove:
                del self.cache[key]

        if keys_to_remove:
            log_info(f"çŠ¶æ€ç¼“å­˜å¤±æ•ˆ: ç§»é™¤ {len(keys_to_remove)} ä¸ªæ¡ç›®")

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        with self.lock:
            hit_rate = (self.stats['hits'] / max(1, self.stats['total_requests'])) * 100

            return {
                'total_entries': len(self.cache),
                'hit_rate': f"{hit_rate:.1f}%",
                'total_requests': self.stats['total_requests'],
                'hits': self.stats['hits'],
                'misses': self.stats['misses'],
                'evictions': self.stats['evictions'],
                'cache_size_limit': self.max_cache_size
            }

class GitBatchProcessor:
    """Gitæ‰¹é‡æ“ä½œå¤„ç†å™¨"""

    def __init__(self, git_cache: EnhancedGitCache):
        self.git_cache = git_cache
        self.batch_queue = deque()
        self.batch_lock = threading.Lock()
        self.batch_timer: Optional[threading.Timer] = None
        self.batch_interval = 2.0  # 2ç§’æ‰¹é‡é—´éš”
        self.processing = False

        # æ‰¹é‡ç­–ç•¥é…ç½®
        self.batchable_commands = {'status', 'log', 'branch', 'diff', 'show'}
        self.max_batch_size = 50

        log_info("Gitæ‰¹é‡å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def queue_operation(self, command: str, args: List[str], callback: Optional[Callable] = None,
                       priority: int = 5, project_root: str = ".") -> str:
        """é˜Ÿåˆ—Gitæ“ä½œ"""
        operation_id = f"{command}_{int(time.time() * 1000000)}"

        operation = BatchOperation(
            operation_id=operation_id,
            command=command,
            args=args,
            callback=callback,
            priority=priority,
            project_root=project_root
        )

        with self.batch_lock:
            self.batch_queue.append(operation)

        # è°ƒåº¦æ‰¹é‡å¤„ç†
        self._schedule_batch_processing()

        return operation_id

    def _schedule_batch_processing(self):
        """è°ƒåº¦æ‰¹é‡å¤„ç†"""
        if self.batch_timer is None or not self.batch_timer.is_alive():
            self.batch_timer = threading.Timer(self.batch_interval, self._process_batch)
            self.batch_timer.start()

    def _process_batch(self):
        """å¤„ç†æ‰¹é‡æ“ä½œ"""
        with self.batch_lock:
            if not self.batch_queue or self.processing:
                return

            self.processing = True
            current_batch = list(self.batch_queue)
            self.batch_queue.clear()

        try:
            # æŒ‰é¡¹ç›®æ ¹ç›®å½•å’Œå‘½ä»¤ç±»å‹åˆ†ç»„
            operations_by_group = defaultdict(list)
            for op in current_batch:
                group_key = f"{op.project_root}:{op.command}"
                operations_by_group[group_key].append(op)

            # å¤„ç†å„ç»„æ“ä½œ
            for group_key, operations in operations_by_group.items():
                self._process_operation_group(operations)

        except Exception as e:
            log_error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")

        finally:
            self.processing = False
            self.batch_timer = None

    def _process_operation_group(self, operations: List[BatchOperation]):
        """å¤„ç†æ“ä½œç»„"""
        if not operations:
            return

        command = operations[0].command
        project_root = operations[0].project_root

        if command in self.batchable_commands:
            if command == 'status':
                self._batch_status_operations(operations)
            elif command == 'log':
                self._batch_log_operations(operations)
            elif command == 'branch':
                self._batch_branch_operations(operations)
            else:
                # å…¶ä»–å¯æ‰¹é‡å‘½ä»¤
                for op in operations:
                    self._execute_single_operation(op)
        else:
            # ä¸å¯æ‰¹é‡å‘½ä»¤é€ä¸ªæ‰§è¡Œ
            for op in operations:
                self._execute_single_operation(op)

    def _batch_status_operations(self, operations: List[BatchOperation]):
        """æ‰¹é‡çŠ¶æ€æ“ä½œ"""
        if not operations:
            return

        project_root = operations[0].project_root

        try:
            # æ£€æŸ¥ç¼“å­˜
            cached_result = self.git_cache.get_cached_result('status', [], project_root)
            if cached_result:
                # ä½¿ç”¨ç¼“å­˜ç»“æœå›è°ƒæ‰€æœ‰æ“ä½œ
                for op in operations:
                    if op.callback:
                        op.callback(cached_result)
                log_info(f"æ‰¹é‡çŠ¶æ€æŸ¥è¯¢ä½¿ç”¨ç¼“å­˜: {len(operations)} ä¸ªæ“ä½œ")
                return

            # æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„GitçŠ¶æ€æŸ¥è¯¢
            result = self._execute_git_command('status', ['--porcelain', '-b'], project_root)

            if result['success']:
                # è§£æç»“æœ
                status_data = self._parse_status_output(result['output'])

                # ç¼“å­˜ç»“æœ
                self.git_cache.cache_result('status', [], status_data, project_root)

                # ä¸ºæ‰€æœ‰æ“ä½œæä¾›ç»“æœ
                for op in operations:
                    # æ ¹æ®å…·ä½“å‚æ•°ç­›é€‰ç»“æœ
                    filtered_result = self._filter_status_result(status_data, op.args)
                    if op.callback:
                        op.callback(filtered_result)

                log_info(f"æ‰¹é‡çŠ¶æ€æŸ¥è¯¢å®Œæˆ: {len(operations)} ä¸ªæ“ä½œ")

            else:
                log_error(f"æ‰¹é‡çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {result.get('error', 'unknown')}")
                # å›è°ƒé”™è¯¯
                for op in operations:
                    if op.callback:
                        op.callback({'error': result.get('error', 'Git command failed')})

        except Exception as e:
            log_error(f"æ‰¹é‡çŠ¶æ€æ“ä½œå¼‚å¸¸: {e}")

    def _batch_log_operations(self, operations: List[BatchOperation]):
        """æ‰¹é‡æ—¥å¿—æ“ä½œ"""
        if not operations:
            return

        project_root = operations[0].project_root

        try:
            # åˆ†ææ‰€æœ‰æ“ä½œçš„å‚æ•°ï¼Œç¡®å®šæœ€å¤§éœ€æ±‚
            max_count = 50  # é»˜è®¤æœ€å¤§æ•°é‡
            all_files = set()

            for op in operations:
                # è§£æ--max-countæˆ–-nå‚æ•°
                for i, arg in enumerate(op.args):
                    if arg == '--max-count' or arg == '-n':
                        if i + 1 < len(op.args):
                            try:
                                count = int(op.args[i + 1])
                                max_count = max(max_count, count)
                            except ValueError:
                                pass
                    elif arg.startswith('--max-count='):
                        try:
                            count = int(arg.split('=', 1)[1])
                            max_count = max(max_count, count)
                        except ValueError:
                            pass

                # æ”¶é›†æ–‡ä»¶è·¯å¾„
                for arg in op.args:
                    if not arg.startswith('-') and os.path.exists(os.path.join(project_root, arg)):
                        all_files.add(arg)

            # æ„å»ºæ‰¹é‡æŸ¥è¯¢å‚æ•°
            batch_args = ['--oneline', f'--max-count={max_count}']
            if all_files:
                batch_args.extend(['--'] + list(all_files))

            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"log:{':'.join(batch_args)}"
            cached_result = self.git_cache.get_cached_result('log', batch_args, project_root)
            if cached_result:
                # ä¸ºæ¯ä¸ªæ“ä½œç­›é€‰ç»“æœ
                for op in operations:
                    filtered_result = self._filter_log_result(cached_result, op.args)
                    if op.callback:
                        op.callback(filtered_result)
                log_info(f"æ‰¹é‡æ—¥å¿—æŸ¥è¯¢ä½¿ç”¨ç¼“å­˜: {len(operations)} ä¸ªæ“ä½œ")
                return

            # æ‰§è¡Œæ‰¹é‡Gitæ—¥å¿—æŸ¥è¯¢
            result = self._execute_git_command('log', batch_args, project_root)

            if result['success']:
                log_data = self._parse_log_output(result['output'])

                # ç¼“å­˜ç»“æœ
                self.git_cache.cache_result('log', batch_args, log_data, project_root)

                # ä¸ºæ¯ä¸ªæ“ä½œæä¾›ç­›é€‰åçš„ç»“æœ
                for op in operations:
                    filtered_result = self._filter_log_result(log_data, op.args)
                    if op.callback:
                        op.callback(filtered_result)

                log_info(f"æ‰¹é‡æ—¥å¿—æŸ¥è¯¢å®Œæˆ: {len(operations)} ä¸ªæ“ä½œ")

            else:
                log_error(f"æ‰¹é‡æ—¥å¿—æŸ¥è¯¢å¤±è´¥: {result.get('error', 'unknown')}")

        except Exception as e:
            log_error(f"æ‰¹é‡æ—¥å¿—æ“ä½œå¼‚å¸¸: {e}")

    def _batch_branch_operations(self, operations: List[BatchOperation]):
        """æ‰¹é‡åˆ†æ”¯æ“ä½œ"""
        project_root = operations[0].project_root

        try:
            # æ‰§è¡Œå®Œæ•´çš„åˆ†æ”¯æŸ¥è¯¢
            result = self._execute_git_command('branch', ['-a', '-v'], project_root)

            if result['success']:
                branch_data = self._parse_branch_output(result['output'])

                # ç¼“å­˜ç»“æœ
                self.git_cache.cache_result('branch', ['-a', '-v'], branch_data, project_root)

                # ä¸ºæ¯ä¸ªæ“ä½œç­›é€‰ç»“æœ
                for op in operations:
                    filtered_result = self._filter_branch_result(branch_data, op.args)
                    if op.callback:
                        op.callback(filtered_result)

                log_info(f"æ‰¹é‡åˆ†æ”¯æŸ¥è¯¢å®Œæˆ: {len(operations)} ä¸ªæ“ä½œ")

        except Exception as e:
            log_error(f"æ‰¹é‡åˆ†æ”¯æ“ä½œå¼‚å¸¸: {e}")

    def _execute_single_operation(self, operation: BatchOperation):
        """æ‰§è¡Œå•ä¸ªGitæ“ä½œ"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cached_result = self.git_cache.get_cached_result(
                operation.command, operation.args, operation.project_root
            )
            if cached_result:
                if operation.callback:
                    operation.callback(cached_result)
                return

            # æ‰§è¡ŒGitå‘½ä»¤
            result = self._execute_git_command(
                operation.command, operation.args, operation.project_root
            )

            if result['success']:
                # ç¼“å­˜ç»“æœ
                self.git_cache.cache_result(
                    operation.command, operation.args, result['output'], operation.project_root
                )

                if operation.callback:
                    operation.callback(result['output'])
            else:
                if operation.callback:
                    operation.callback({'error': result.get('error', 'Git command failed')})

        except Exception as e:
            log_error(f"å•ä¸ªGitæ“ä½œæ‰§è¡Œå¤±è´¥ {operation.command}: {e}")
            if operation.callback:
                operation.callback({'error': str(e)})

    def _execute_git_command(self, command: str, args: List[str], project_root: str = ".") -> Dict[str, Any]:
        """æ‰§è¡ŒGitå‘½ä»¤"""
        cmd = ['git', command] + args

        try:
            result = subprocess.run(
                cmd,
                cwd=project_root,
                capture_output=True,
                text=True,
                timeout=30
            )

            return {
                'success': result.returncode == 0,
                'output': result.stdout.strip(),
                'error': result.stderr.strip() if result.returncode != 0 else None
            }

        except subprocess.TimeoutExpired:
            return {'success': False, 'error': 'Git command timeout'}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _parse_status_output(self, output: str) -> Dict[str, Any]:
        """è§£æçŠ¶æ€è¾“å‡º"""
        lines = output.split('\n') if output else []
        status_data = {
            'branch': '',
            'staged': [],
            'modified': [],
            'untracked': [],
            'ahead': 0,
            'behind': 0
        }

        for line in lines:
            if line.startswith('##'):
                # åˆ†æ”¯ä¿¡æ¯
                parts = line[3:].split()
                if parts:
                    branch_info = parts[0]
                    if '...' in branch_info:
                        status_data['branch'] = branch_info.split('...')[0]
                    else:
                        status_data['branch'] = branch_info

                    # æ£€æŸ¥ahead/behind
                    if '[ahead' in line:
                        import re
                        ahead_match = re.search(r'ahead (\d+)', line)
                        if ahead_match:
                            status_data['ahead'] = int(ahead_match.group(1))

                    if '[behind' in line or ', behind' in line:
                        import re
                        behind_match = re.search(r'behind (\d+)', line)
                        if behind_match:
                            status_data['behind'] = int(behind_match.group(1))

            elif len(line) >= 3:
                # æ–‡ä»¶çŠ¶æ€
                status = line[:2]
                filename = line[3:]

                if status[0] != ' ':  # æš‚å­˜åŒº
                    status_data['staged'].append(filename)
                elif status[1] != ' ':  # å·¥ä½œåŒº
                    status_data['modified'].append(filename)
                elif status == '??':  # æœªè·Ÿè¸ª
                    status_data['untracked'].append(filename)

        return status_data

    def _parse_log_output(self, output: str) -> List[Dict[str, str]]:
        """è§£ææ—¥å¿—è¾“å‡º"""
        lines = output.split('\n') if output else []
        log_entries = []

        for line in lines:
            if line.strip():
                parts = line.split(' ', 1)
                if len(parts) >= 2:
                    log_entries.append({
                        'hash': parts[0],
                        'message': parts[1]
                    })

        return log_entries

    def _parse_branch_output(self, output: str) -> Dict[str, Any]:
        """è§£æåˆ†æ”¯è¾“å‡º"""
        lines = output.split('\n') if output else []
        branches = {
            'local': [],
            'remote': [],
            'current': ''
        }

        for line in lines:
            line = line.strip()
            if not line:
                continue

            is_current = line.startswith('*')
            branch_line = line[2:] if is_current else line

            if branch_line.startswith('remotes/'):
                # è¿œç¨‹åˆ†æ”¯
                branch_name = branch_line[8:]  # ç§»é™¤"remotes/"å‰ç¼€
                branches['remote'].append(branch_name)
            else:
                # æœ¬åœ°åˆ†æ”¯
                branch_name = branch_line.split()[0]
                branches['local'].append(branch_name)
                if is_current:
                    branches['current'] = branch_name

        return branches

    def _filter_status_result(self, status_data: Dict[str, Any], args: List[str]) -> Dict[str, Any]:
        """ç­›é€‰çŠ¶æ€ç»“æœ"""
        # æ ¹æ®å‚æ•°ç­›é€‰çŠ¶æ€ç»“æœ
        if '--short' in args or '-s' in args:
            # ç®€çŸ­æ ¼å¼
            return {
                'staged': len(status_data['staged']),
                'modified': len(status_data['modified']),
                'untracked': len(status_data['untracked'])
            }
        else:
            return status_data

    def _filter_log_result(self, log_data: List[Dict[str, str]], args: List[str]) -> List[Dict[str, str]]:
        """ç­›é€‰æ—¥å¿—ç»“æœ"""
        # æ ¹æ®å‚æ•°ç­›é€‰æ—¥å¿—ç»“æœ
        count_limit = None

        for i, arg in enumerate(args):
            if arg == '--max-count' or arg == '-n':
                if i + 1 < len(args):
                    try:
                        count_limit = int(args[i + 1])
                    except ValueError:
                        pass
            elif arg.startswith('--max-count='):
                try:
                    count_limit = int(arg.split('=', 1)[1])
                except ValueError:
                    pass

        if count_limit is not None:
            return log_data[:count_limit]
        else:
            return log_data

    def _filter_branch_result(self, branch_data: Dict[str, Any], args: List[str]) -> Dict[str, Any]:
        """ç­›é€‰åˆ†æ”¯ç»“æœ"""
        # æ ¹æ®å‚æ•°ç­›é€‰åˆ†æ”¯ç»“æœ
        if '-r' in args:
            # åªæ˜¾ç¤ºè¿œç¨‹åˆ†æ”¯
            return {'branches': branch_data['remote']}
        elif '-a' not in args:
            # åªæ˜¾ç¤ºæœ¬åœ°åˆ†æ”¯
            return {
                'branches': branch_data['local'],
                'current': branch_data['current']
            }
        else:
            return branch_data

# å…¨å±€å®ä¾‹
enhanced_git_cache = EnhancedGitCache()
git_batch_processor = GitBatchProcessor(enhanced_git_cache)

# ä¾¿æ·å‡½æ•°
def get_cached_git_result(command: str, args: List[str], project_root: str = ".") -> Optional[Any]:
    """è·å–Gitç¼“å­˜ç»“æœ"""
    return enhanced_git_cache.get_cached_result(command, args, project_root)

def cache_git_result(command: str, args: List[str], result: Any, project_root: str = ".") -> None:
    """ç¼“å­˜Gitç»“æœ"""
    enhanced_git_cache.cache_result(command, args, result, project_root)

def queue_git_operation(command: str, args: List[str], callback: Optional[Callable] = None,
                       project_root: str = ".") -> str:
    """é˜Ÿåˆ—Gitæ“ä½œ"""
    return git_batch_processor.queue_operation(command, args, callback, project_root=project_root)

def invalidate_git_status_cache(project_root: str = ".") -> None:
    """ä½¿GitçŠ¶æ€ç¼“å­˜å¤±æ•ˆ"""
    enhanced_git_cache.invalidate_status_cache(project_root)

def get_git_cache_stats() -> Dict[str, Any]:
    """è·å–Gitç¼“å­˜ç»Ÿè®¡"""
    return enhanced_git_cache.get_cache_stats()

if __name__ == "__main__":
    # æµ‹è¯•å¢å¼ºGitç¼“å­˜
    print("ğŸš€ æµ‹è¯•å¢å¼ºGitç¼“å­˜ç³»ç»Ÿ")

    # æµ‹è¯•ç¼“å­˜åŠŸèƒ½
    test_result = "test git output"
    cache_git_result('status', [], test_result)

    cached = get_cached_git_result('status', [])
    print(f"ç¼“å­˜æµ‹è¯•ç»“æœ: {cached == test_result}")

    # æµ‹è¯•æ‰¹é‡æ“ä½œ
    def test_callback(result):
        print(f"æ‰¹é‡æ“ä½œå›è°ƒ: {result}")

    op_id = queue_git_operation('status', [], test_callback)
    print(f"æ“ä½œå·²é˜Ÿåˆ—: {op_id}")

    # ç­‰å¾…æ‰¹é‡å¤„ç†
    time.sleep(3)

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = get_git_cache_stats()
    print(f"ç¼“å­˜ç»Ÿè®¡: {stats}")

    print("âœ… å¢å¼ºGitç¼“å­˜æµ‹è¯•å®Œæˆ")