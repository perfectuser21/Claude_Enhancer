"""
Performance Optimization: Metrics Collector
æŒ‡æ ‡æ”¶é›†å™¨ - ä¼ä¸šçº§æ€§èƒ½ç›‘æ§ä¸æŒ‡æ ‡æ”¶é›†ç³»ç»Ÿ
"""

import asyncio
import time
import psutil
import logging
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import json
from collections import defaultdict, deque
import aiofiles
import threading
from contextlib import asynccontextmanager
import weakref

logger = logging.getLogger(__name__)

class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹"""
    COUNTER = "counter"          # è®¡æ•°å™¨ï¼ˆåªå¢ä¸å‡ï¼‰
    GAUGE = "gauge"             # ä»ªè¡¨ï¼ˆå¯å¢å¯å‡çš„ç¬æ—¶å€¼ï¼‰
    HISTOGRAM = "histogram"     # ç›´æ–¹å›¾ï¼ˆåˆ†å¸ƒç»Ÿè®¡ï¼‰
    SUMMARY = "summary"         # æ‘˜è¦ï¼ˆåˆ†ä½æ•°ç»Ÿè®¡ï¼‰
    TIMER = "timer"            # è®¡æ—¶å™¨ï¼ˆç‰¹æ®Šçš„ç›´æ–¹å›¾ï¼‰

class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class Metric:
    """æŒ‡æ ‡æ•°æ®ç»“æ„"""
    name: str
    value: float
    metric_type: MetricType
    labels: Dict[str, str] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)
    unit: str = ""
    help_text: str = ""

@dataclass
class Alert:
    """å‘Šè­¦æ•°æ®ç»“æ„"""
    id: str
    name: str
    level: AlertLevel
    message: str
    metric_name: str
    threshold: float
    current_value: float
    timestamp: datetime = field(default_factory=datetime.now)
    resolved: bool = False
    resolved_at: Optional[datetime] = None

@dataclass
class MetricsConfig:
    """æŒ‡æ ‡æ”¶é›†å™¨é…ç½®"""
    collection_interval: float = 10.0  # 10ç§’
    retention_period: timedelta = timedelta(hours=24)  # 24å°æ—¶
    max_metrics_per_type: int = 10000
    enable_system_metrics: bool = True
    enable_application_metrics: bool = True
    enable_business_metrics: bool = True
    alert_check_interval: float = 30.0  # 30ç§’
    export_interval: float = 60.0  # 1åˆ†é’Ÿ
    export_format: str = "prometheus"  # prometheus, json
    export_file: Optional[str] = "/tmp/metrics.txt"

class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨ - ä¼ä¸šçº§æ€§èƒ½ç›‘æ§ç³»ç»Ÿ"""

    def __init__(self, service_name: str, config: MetricsConfig = None):
        self.service_name = service_name
        self.config = config or MetricsConfig()

        # æŒ‡æ ‡å­˜å‚¨
        self.counters: Dict[str, float] = defaultdict(float)
        self.gauges: Dict[str, float] = {}
        self.histograms: Dict[str, List[float]] = defaultdict(list)
        self.timers: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))

        # å†å²æ•°æ®å­˜å‚¨
        self.metrics_history: Dict[str, deque] = defaultdict(
            lambda: deque(maxlen=int(self.config.retention_period.total_seconds() / self.config.collection_interval))
        )

        # å‘Šè­¦
        self.alerts: Dict[str, Alert] = {}
        self.alert_rules: Dict[str, Dict[str, Any]] = {}
        self.alert_handlers: List[Callable] = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_metrics_collected': 0,
            'active_alerts': 0,
            'system_uptime': time.time(),
            'last_collection_time': None,
            'collection_errors': 0
        }

        # æ§åˆ¶æ ‡å¿—
        self.running = False
        self._lock = asyncio.Lock()

        # ç³»ç»Ÿèµ„æºç›‘æ§
        self.process = psutil.Process()

    async def initialize(self):
        """åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨"""
        try:
            self.running = True

            # å¯åŠ¨æ”¶é›†ä»»åŠ¡
            asyncio.create_task(self._collection_loop())
            asyncio.create_task(self._alert_check_loop())
            asyncio.create_task(self._export_loop())
            asyncio.create_task(self._cleanup_loop())

            # æ³¨å†Œç³»ç»ŸæŒ‡æ ‡
            if self.config.enable_system_metrics:
                await self._register_system_metrics()

            logger.info(f"âœ… æŒ‡æ ‡æ”¶é›†å™¨åˆå§‹åŒ–æˆåŠŸ - æœåŠ¡: {self.service_name}")

        except Exception as e:
            logger.error(f"âŒ æŒ‡æ ‡æ”¶é›†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def _register_system_metrics(self):
        """æ³¨å†Œç³»ç»ŸæŒ‡æ ‡"""
        # CPUä½¿ç”¨ç‡
        self.add_alert_rule(
            "cpu_usage_high",
            metric_name="system_cpu_percent",
            threshold=80.0,
            level=AlertLevel.WARNING,
            message="CPUä½¿ç”¨ç‡è¿‡é«˜"
        )

        # å†…å­˜ä½¿ç”¨ç‡
        self.add_alert_rule(
            "memory_usage_high",
            metric_name="system_memory_percent",
            threshold=85.0,
            level=AlertLevel.ERROR,
            message="å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
        )

        # ç£ç›˜ä½¿ç”¨ç‡
        self.add_alert_rule(
            "disk_usage_high",
            metric_name="system_disk_percent",
            threshold=90.0,
            level=AlertLevel.CRITICAL,
            message="ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜"
        )

    def increment_counter(self, name: str, value: float = 1.0, labels: Dict[str, str] = None):
        """é€’å¢è®¡æ•°å™¨"""
        key = self._make_key(name, labels)
        self.counters[key] += value
        self._record_metric(name, self.counters[key], MetricType.COUNTER, labels)

    def set_gauge(self, name: str, value: float, labels: Dict[str, str] = None):
        """è®¾ç½®ä»ªè¡¨å€¼"""
        key = self._make_key(name, labels)
        self.gauges[key] = value
        self._record_metric(name, value, MetricType.GAUGE, labels)

    def observe_histogram(self, name: str, value: float, labels: Dict[str, str] = None):
        """è§‚å¯Ÿç›´æ–¹å›¾å€¼"""
        key = self._make_key(name, labels)
        self.histograms[key].append(value)

        # é™åˆ¶å†å²æ•°æ®æ•°é‡
        if len(self.histograms[key]) > 1000:
            self.histograms[key] = self.histograms[key][-1000:]

        self._record_metric(name, value, MetricType.HISTOGRAM, labels)

    def time_function(self, name: str, labels: Dict[str, str] = None):
        """å‡½æ•°æ‰§è¡Œæ—¶é—´è£…é¥°å™¨"""
        def decorator(func):
            if asyncio.iscoroutinefunction(func):
                async def async_wrapper(*args, **kwargs):
                    start_time = time.time()
                    try:
                        result = await func(*args, **kwargs)
                        return result
                    finally:
                        duration = time.time() - start_time
                        self.record_timer(name, duration, labels)
                return async_wrapper
            else:
                def sync_wrapper(*args, **kwargs):
                    start_time = time.time()
                    try:
                        result = func(*args, **kwargs)
                        return result
                    finally:
                        duration = time.time() - start_time
                        self.record_timer(name, duration, labels)
                return sync_wrapper
        return decorator

    def record_timer(self, name: str, duration: float, labels: Dict[str, str] = None):
        """è®°å½•è®¡æ—¶å™¨"""
        key = self._make_key(name, labels)
        self.timers[key].append(duration)
        self._record_metric(name, duration, MetricType.TIMER, labels)

    @asynccontextmanager
    async def timer_context(self, name: str, labels: Dict[str, str] = None):
        """è®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        start_time = time.time()
        try:
            yield
        finally:
            duration = time.time() - start_time
            self.record_timer(name, duration, labels)

    def _make_key(self, name: str, labels: Dict[str, str] = None) -> str:
        """ç”ŸæˆæŒ‡æ ‡é”®"""
        if not labels:
            return name

        label_str = ",".join(f"{k}={v}" for k, v in sorted(labels.items()))
        return f"{name}{{{label_str}}}"

    def _record_metric(self, name: str, value: float, metric_type: MetricType,
                      labels: Dict[str, str] = None):
        """è®°å½•æŒ‡æ ‡åˆ°å†å²æ•°æ®"""
        key = self._make_key(name, labels)
        metric = Metric(
            name=name,
            value=value,
            metric_type=metric_type,
            labels=labels or {},
            timestamp=datetime.now()
        )

        self.metrics_history[key].append(metric)
        self.stats['total_metrics_collected'] += 1

    async def _collection_loop(self):
        """æŒ‡æ ‡æ”¶é›†å¾ªç¯"""
        while self.running:
            try:
                await self._collect_system_metrics()
                await self._collect_application_metrics()

                self.stats['last_collection_time'] = datetime.now()

            except Exception as e:
                logger.error(f"âŒ æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
                self.stats['collection_errors'] += 1

            await asyncio.sleep(self.config.collection_interval)

    async def _collect_system_metrics(self):
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        if not self.config.enable_system_metrics:
            return

        try:
            # CPUæŒ‡æ ‡
            cpu_percent = psutil.cpu_percent(interval=None)
            self.set_gauge("system_cpu_percent", cpu_percent)

            cpu_count = psutil.cpu_count()
            self.set_gauge("system_cpu_count", cpu_count)

            # å†…å­˜æŒ‡æ ‡
            memory = psutil.virtual_memory()
            self.set_gauge("system_memory_total", memory.total)
            self.set_gauge("system_memory_used", memory.used)
            self.set_gauge("system_memory_percent", memory.percent)
            self.set_gauge("system_memory_available", memory.available)

            # ç£ç›˜æŒ‡æ ‡
            disk = psutil.disk_usage('/')
            self.set_gauge("system_disk_total", disk.total)
            self.set_gauge("system_disk_used", disk.used)
            self.set_gauge("system_disk_percent", disk.used / disk.total * 100)

            # ç½‘ç»œæŒ‡æ ‡
            network = psutil.net_io_counters()
            self.increment_counter("system_network_bytes_sent", network.bytes_sent)
            self.increment_counter("system_network_bytes_recv", network.bytes_recv)
            self.increment_counter("system_network_packets_sent", network.packets_sent)
            self.increment_counter("system_network_packets_recv", network.packets_recv)

            # è¿›ç¨‹æŒ‡æ ‡
            process_memory = self.process.memory_info()
            self.set_gauge("process_memory_rss", process_memory.rss)
            self.set_gauge("process_memory_vms", process_memory.vms)
            self.set_gauge("process_cpu_percent", self.process.cpu_percent())
            self.set_gauge("process_threads", self.process.num_threads())

            # æ–‡ä»¶æè¿°ç¬¦
            try:
                self.set_gauge("process_open_fds", self.process.num_fds())
            except:
                pass  # Windowsä¸æ”¯æŒ

        except Exception as e:
            logger.error(f"âŒ ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")

    async def _collect_application_metrics(self):
        """æ”¶é›†åº”ç”¨æŒ‡æ ‡"""
        if not self.config.enable_application_metrics:
            return

        try:
            # æœåŠ¡è¿è¡Œæ—¶é—´
            uptime = time.time() - self.stats['system_uptime']
            self.set_gauge("service_uptime_seconds", uptime)

            # æŒ‡æ ‡ç»Ÿè®¡
            self.set_gauge("metrics_total_collected", self.stats['total_metrics_collected'])
            self.set_gauge("metrics_collection_errors", self.stats['collection_errors'])
            self.set_gauge("alerts_active", len([a for a in self.alerts.values() if not a.resolved]))

            # é˜Ÿåˆ—é•¿åº¦ç»Ÿè®¡
            self.set_gauge("metrics_counters_count", len(self.counters))
            self.set_gauge("metrics_gauges_count", len(self.gauges))
            self.set_gauge("metrics_histograms_count", len(self.histograms))
            self.set_gauge("metrics_timers_count", len(self.timers))

        except Exception as e:
            logger.error(f"âŒ åº”ç”¨æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")

    def add_alert_rule(self, rule_id: str, metric_name: str, threshold: float,
                      level: AlertLevel = AlertLevel.WARNING,
                      message: str = "", operator: str = "gt"):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        self.alert_rules[rule_id] = {
            'metric_name': metric_name,
            'threshold': threshold,
            'level': level,
            'message': message,
            'operator': operator  # gt, lt, eq, gte, lte
        }

        logger.info(f"ğŸ“‹ æ·»åŠ å‘Šè­¦è§„åˆ™: {rule_id} - {metric_name} {operator} {threshold}")

    def add_alert_handler(self, handler: Callable[[Alert], None]):
        """æ·»åŠ å‘Šè­¦å¤„ç†å™¨"""
        self.alert_handlers.append(handler)

    async def _alert_check_loop(self):
        """å‘Šè­¦æ£€æŸ¥å¾ªç¯"""
        while self.running:
            try:
                await self._check_alerts()
            except Exception as e:
                logger.error(f"âŒ å‘Šè­¦æ£€æŸ¥å¤±è´¥: {e}")

            await asyncio.sleep(self.config.alert_check_interval)

    async def _check_alerts(self):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        for rule_id, rule in self.alert_rules.items():
            metric_name = rule['metric_name']
            threshold = rule['threshold']
            operator = rule['operator']

            # è·å–å½“å‰æŒ‡æ ‡å€¼
            current_value = None
            for key, value in self.gauges.items():
                if key.startswith(metric_name):
                    current_value = value
                    break

            if current_value is None:
                continue

            # æ£€æŸ¥å‘Šè­¦æ¡ä»¶
            alert_triggered = False
            if operator == "gt" and current_value > threshold:
                alert_triggered = True
            elif operator == "lt" and current_value < threshold:
                alert_triggered = True
            elif operator == "eq" and current_value == threshold:
                alert_triggered = True
            elif operator == "gte" and current_value >= threshold:
                alert_triggered = True
            elif operator == "lte" and current_value <= threshold:
                alert_triggered = True

            # å¤„ç†å‘Šè­¦
            if alert_triggered:
                if rule_id not in self.alerts or self.alerts[rule_id].resolved:
                    # æ–°å‘Šè­¦
                    alert = Alert(
                        id=rule_id,
                        name=rule_id,
                        level=rule['level'],
                        message=rule['message'] or f"{metric_name} {operator} {threshold}",
                        metric_name=metric_name,
                        threshold=threshold,
                        current_value=current_value
                    )

                    self.alerts[rule_id] = alert
                    await self._trigger_alert(alert)

            else:
                # å‘Šè­¦æ¢å¤
                if rule_id in self.alerts and not self.alerts[rule_id].resolved:
                    self.alerts[rule_id].resolved = True
                    self.alerts[rule_id].resolved_at = datetime.now()
                    await self._resolve_alert(self.alerts[rule_id])

    async def _trigger_alert(self, alert: Alert):
        """è§¦å‘å‘Šè­¦"""
        logger.warning(f"ğŸš¨ å‘Šè­¦è§¦å‘: {alert.name} - {alert.message} (å½“å‰å€¼: {alert.current_value})")

        # è°ƒç”¨å‘Šè­¦å¤„ç†å™¨
        for handler in self.alert_handlers:
            try:
                if asyncio.iscoroutinefunction(handler):
                    await handler(alert)
                else:
                    handler(alert)
            except Exception as e:
                logger.error(f"âŒ å‘Šè­¦å¤„ç†å™¨å¤±è´¥: {e}")

    async def _resolve_alert(self, alert: Alert):
        """è§£å†³å‘Šè­¦"""
        logger.info(f"âœ… å‘Šè­¦æ¢å¤: {alert.name}")

        # å¯ä»¥åœ¨è¿™é‡Œå‘é€æ¢å¤é€šçŸ¥

    async def _export_loop(self):
        """æŒ‡æ ‡å¯¼å‡ºå¾ªç¯"""
        while self.running:
            try:
                await self._export_metrics()
            except Exception as e:
                logger.error(f"âŒ æŒ‡æ ‡å¯¼å‡ºå¤±è´¥: {e}")

            await asyncio.sleep(self.config.export_interval)

    async def _export_metrics(self):
        """å¯¼å‡ºæŒ‡æ ‡"""
        if not self.config.export_file:
            return

        try:
            if self.config.export_format == "prometheus":
                content = await self._generate_prometheus_format()
            else:
                content = await self._generate_json_format()

            async with aiofiles.open(self.config.export_file, 'w') as f:
                await f.write(content)

        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºæŒ‡æ ‡åˆ°æ–‡ä»¶å¤±è´¥: {e}")

    async def _generate_prometheus_format(self) -> str:
        """ç”ŸæˆPrometheusæ ¼å¼çš„æŒ‡æ ‡"""
        lines = []

        # è®¡æ•°å™¨
        for key, value in self.counters.items():
            name, labels = self._parse_key(key)
            labels_str = self._format_prometheus_labels(labels)
            lines.append(f'# TYPE {name} counter')
            lines.append(f'{name}{labels_str} {value}')

        # ä»ªè¡¨
        for key, value in self.gauges.items():
            name, labels = self._parse_key(key)
            labels_str = self._format_prometheus_labels(labels)
            lines.append(f'# TYPE {name} gauge')
            lines.append(f'{name}{labels_str} {value}')

        # ç›´æ–¹å›¾æ‘˜è¦
        for key, values in self.histograms.items():
            if not values:
                continue

            name, labels = self._parse_key(key)
            labels_str = self._format_prometheus_labels(labels)

            sorted_values = sorted(values)
            count = len(sorted_values)
            total = sum(sorted_values)

            lines.append(f'# TYPE {name} histogram')
            lines.append(f'{name}_count{labels_str} {count}')
            lines.append(f'{name}_sum{labels_str} {total}')

            # åˆ†ä½æ•°
            percentiles = [0.5, 0.95, 0.99]
            for p in percentiles:
                index = int(count * p)
                if index < count:
                    value = sorted_values[index]
                    labels_with_quantile = {**labels, 'quantile': str(p)}
                    labels_str = self._format_prometheus_labels(labels_with_quantile)
                    lines.append(f'{name}{labels_str} {value}')

        return '\n'.join(lines) + '\n'

    async def _generate_json_format(self) -> str:
        """ç”ŸæˆJSONæ ¼å¼çš„æŒ‡æ ‡"""
        data = {
            'timestamp': datetime.now().isoformat(),
            'service': self.service_name,
            'counters': dict(self.counters),
            'gauges': dict(self.gauges),
            'histograms': {k: list(v) for k, v in self.histograms.items()},
            'timers': {k: list(v) for k, v in self.timers.items()},
            'stats': self.stats.copy(),
            'alerts': {k: {
                'id': v.id,
                'name': v.name,
                'level': v.level.value,
                'message': v.message,
                'resolved': v.resolved,
                'timestamp': v.timestamp.isoformat()
            } for k, v in self.alerts.items()}
        }

        return json.dumps(data, indent=2, default=str)

    def _parse_key(self, key: str) -> Tuple[str, Dict[str, str]]:
        """è§£ææŒ‡æ ‡é”®"""
        if '{' not in key:
            return key, {}

        name, labels_str = key.split('{', 1)
        labels_str = labels_str.rstrip('}')

        labels = {}
        if labels_str:
            for label_pair in labels_str.split(','):
                k, v = label_pair.split('=', 1)
                labels[k] = v

        return name, labels

    def _format_prometheus_labels(self, labels: Dict[str, str]) -> str:
        """æ ¼å¼åŒ–Prometheusæ ‡ç­¾"""
        if not labels:
            return ''

        label_pairs = [f'{k}="{v}"' for k, v in sorted(labels.items())]
        return '{' + ','.join(label_pairs) + '}'

    async def _cleanup_loop(self):
        """æ¸…ç†å¾ªç¯"""
        while self.running:
            try:
                await asyncio.sleep(3600)  # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡

                # æ¸…ç†è¿‡æœŸçš„å†å²æ•°æ®
                cutoff_time = datetime.now() - self.config.retention_period

                for key, history in self.metrics_history.items():
                    # ç§»é™¤è¿‡æœŸæ•°æ®
                    while history and history[0].timestamp < cutoff_time:
                        history.popleft()

                # æ¸…ç†å·²è§£å†³çš„æ—§å‘Šè­¦
                resolved_alerts = [
                    alert_id for alert_id, alert in self.alerts.items()
                    if alert.resolved and alert.resolved_at and
                    datetime.now() - alert.resolved_at > timedelta(hours=24)
                ]

                for alert_id in resolved_alerts:
                    del self.alerts[alert_id]

                if resolved_alerts:
                    logger.info(f"ğŸ§¹ æ¸…ç†å·²è§£å†³å‘Šè­¦: {len(resolved_alerts)}ä¸ª")

            except Exception as e:
                logger.error(f"âŒ æ¸…ç†ä»»åŠ¡å¤±è´¥: {e}")

    async def get_metrics_summary(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        return {
            'service': self.service_name,
            'stats': self.stats.copy(),
            'counters_count': len(self.counters),
            'gauges_count': len(self.gauges),
            'histograms_count': len(self.histograms),
            'timers_count': len(self.timers),
            'active_alerts': len([a for a in self.alerts.values() if not a.resolved]),
            'total_alerts': len(self.alerts),
            'uptime_seconds': time.time() - self.stats['system_uptime']
        }

    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        return self.running and self.stats['last_collection_time'] is not None

    async def shutdown(self):
        """å…³é—­æŒ‡æ ‡æ”¶é›†å™¨"""
        logger.info("ğŸ›‘ æ­£åœ¨å…³é—­æŒ‡æ ‡æ”¶é›†å™¨...")
        self.running = False

        # æœ€åä¸€æ¬¡å¯¼å‡º
        try:
            await self._export_metrics()
        except Exception as e:
            logger.error(f"âŒ æœ€ç»ˆå¯¼å‡ºå¤±è´¥: {e}")

        logger.info("âœ… æŒ‡æ ‡æ”¶é›†å™¨å·²å…³é—­")

# å‘Šè­¦å¤„ç†å™¨ç¤ºä¾‹
async def email_alert_handler(alert: Alert):
    """é‚®ä»¶å‘Šè­¦å¤„ç†å™¨"""
    logger.info(f"ğŸ“§ å‘é€å‘Šè­¦é‚®ä»¶: {alert.name} - {alert.message}")
    # è¿™é‡Œå®ç°é‚®ä»¶å‘é€é€»è¾‘

def slack_alert_handler(alert: Alert):
    """Slackå‘Šè­¦å¤„ç†å™¨"""
    logger.info(f"ğŸ’¬ å‘é€Slackå‘Šè­¦: {alert.name} - {alert.message}")
    # è¿™é‡Œå®ç°Slackæ¶ˆæ¯å‘é€é€»è¾‘

# ä½¿ç”¨ç¤ºä¾‹
async def example_usage():
    """æŒ‡æ ‡æ”¶é›†å™¨ä½¿ç”¨ç¤ºä¾‹"""
    config = MetricsConfig(
        collection_interval=5.0,
        enable_system_metrics=True,
        export_file="/tmp/perfect21_metrics.txt"
    )

    collector = MetricsCollector("perfect21-auth", config)

    # æ·»åŠ å‘Šè­¦å¤„ç†å™¨
    collector.add_alert_handler(email_alert_handler)
    collector.add_alert_handler(slack_alert_handler)

    await collector.initialize()

    # ä½¿ç”¨æŒ‡æ ‡
    collector.increment_counter("requests_total", labels={"method": "GET", "endpoint": "/api/users"})
    collector.set_gauge("active_connections", 45)
    collector.observe_histogram("request_duration", 0.234)

    # ä½¿ç”¨è®¡æ—¶å™¨è£…é¥°å™¨
    @collector.time_function("database_query_duration")
    async def query_database():
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        return "result"

    # ä½¿ç”¨è®¡æ—¶å™¨ä¸Šä¸‹æ–‡
    async with collector.timer_context("complex_operation"):
        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿå¤æ‚æ“ä½œ

    # è·å–æ‘˜è¦
    summary = await collector.get_metrics_summary()
    print(f"Metrics Summary: {json.dumps(summary, indent=2)}")