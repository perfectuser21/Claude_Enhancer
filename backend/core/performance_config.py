"""
Performance Optimization: Configuration Management
æ€§èƒ½é…ç½®ç®¡ç†å™¨ - ç»Ÿä¸€çš„æ€§èƒ½ä¼˜åŒ–é…ç½®ä¸­å¿ƒ
"""

import os
import yaml
import json
import logging
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, field
from pathlib import Path
from datetime import timedelta
import asyncio
from enum import Enum

logger = logging.getLogger(__name__)


class CacheStrategy(Enum):
    """ç¼“å­˜ç­–ç•¥"""

    LRU = "lru"
    LFU = "lfu"
    TTL = "ttl"
    WRITE_THROUGH = "write_through"
    WRITE_BACK = "write_back"


class LoadBalanceAlgorithm(Enum):
    """è´Ÿè½½å‡è¡¡ç®—æ³•"""

    ROUND_ROBIN = "round_robin"
    WEIGHTED_ROUND_ROBIN = "weighted_round_robin"
    LEAST_CONNECTIONS = "least_connections"
    IP_HASH = "ip_hash"
    HEALTH_BASED = "health_based"


@dataclass
class RedisConfig:
    """Redisé…ç½®"""

    host: str = "localhost"
    port: int = 6379
    password: Optional[str] = None
    db: int = 0
    pool_size: int = 50
    timeout: int = 5
    retry_on_timeout: bool = True
    compression_enabled: bool = True
    compression_threshold: int = 1024
    default_ttl: int = 300
    max_connections: int = 100


@dataclass
class DatabaseConfig:
    """æ•°æ®åº“ä¼˜åŒ–é…ç½®"""

    url: str = ""
    pool_size: int = 20
    max_overflow: int = 30
    pool_timeout: int = 30
    pool_recycle: int = 3600
    slow_query_threshold: float = 1.0
    enable_query_cache: bool = True
    query_cache_ttl: int = 300
    enable_prepared_statements: bool = True
    statement_cache_size: int = 100
    connection_timeout: float = 10.0
    query_timeout: float = 30.0


@dataclass
class AsyncProcessorConfig:
    """å¼‚æ­¥å¤„ç†å™¨é…ç½®"""

    max_workers: int = 10
    max_queue_size: int = 1000
    worker_timeout: float = 300.0
    health_check_interval: float = 30.0
    stats_report_interval: float = 60.0
    cleanup_interval: float = 3600.0
    task_retention_hours: int = 24

    # é‚®ä»¶é…ç½®
    smtp_host: str = "localhost"
    smtp_port: int = 587
    smtp_username: Optional[str] = None
    smtp_password: Optional[str] = None
    smtp_use_tls: bool = True
    email_from: str = "noreply@claude-enhancer.com"

    # æ¶ˆæ¯é˜Ÿåˆ—é…ç½®
    rabbitmq_url: str = "amqp://localhost"

    # APIé…ç½®
    api_timeout: float = 30.0
    api_retries: int = 3


@dataclass
class LoadBalancerConfig:
    """è´Ÿè½½å‡è¡¡å™¨é…ç½®"""

    algorithm: LoadBalanceAlgorithm = LoadBalanceAlgorithm.WEIGHTED_ROUND_ROBIN
    health_check_enabled: bool = True
    health_check_interval: int = 30
    session_affinity: bool = False
    session_timeout: int = 3600
    max_retries: int = 3
    retry_delay: float = 0.1
    circuit_breaker_enabled: bool = True
    circuit_breaker_threshold: int = 5
    circuit_breaker_timeout: int = 60
    connection_timeout: float = 10.0
    read_timeout: float = 30.0


@dataclass
class MetricsConfig:
    """æŒ‡æ ‡æ”¶é›†é…ç½®"""

    collection_interval: float = 10.0
    retention_period_hours: int = 24
    max_metrics_per_type: int = 10000
    enable_system_metrics: bool = True
    enable_application_metrics: bool = True
    enable_business_metrics: bool = True
    alert_check_interval: float = 30.0
    export_interval: float = 60.0
    export_format: str = "prometheus"
    export_file: Optional[str] = "/tmp/metrics.txt"


@dataclass
class PerformanceThresholds:
    """æ€§èƒ½é˜ˆå€¼é…ç½®"""

    # å“åº”æ—¶é—´é˜ˆå€¼ (æ¯«ç§’)
    response_time_warning: float = 500.0
    response_time_critical: float = 1000.0

    # CPUä½¿ç”¨ç‡é˜ˆå€¼ (%)
    cpu_usage_warning: float = 70.0
    cpu_usage_critical: float = 85.0

    # å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼ (%)
    memory_usage_warning: float = 75.0
    memory_usage_critical: float = 90.0

    # ç£ç›˜ä½¿ç”¨ç‡é˜ˆå€¼ (%)
    disk_usage_warning: float = 80.0
    disk_usage_critical: float = 95.0

    # ç½‘ç»œå»¶è¿Ÿé˜ˆå€¼ (æ¯«ç§’)
    network_latency_warning: float = 100.0
    network_latency_critical: float = 500.0

    # é”™è¯¯ç‡é˜ˆå€¼ (%)
    error_rate_warning: float = 1.0
    error_rate_critical: float = 5.0

    # å¹¶å‘è¿æ¥æ•°é˜ˆå€¼
    connection_count_warning: int = 1000
    connection_count_critical: int = 5000


@dataclass
class OptimizationSettings:
    """ä¼˜åŒ–è®¾ç½®"""

    # ç¼“å­˜è®¾ç½®
    enable_l1_cache: bool = True
    enable_l2_cache: bool = True
    cache_strategy: CacheStrategy = CacheStrategy.LRU

    # è¿æ¥æ± è®¾ç½®
    enable_connection_pooling: bool = True
    connection_pool_preconnect: bool = True

    # æŸ¥è¯¢ä¼˜åŒ–
    enable_query_optimization: bool = True
    enable_batch_operations: bool = True

    # å‹ç¼©è®¾ç½®
    enable_response_compression: bool = True
    compression_min_size: int = 1024

    # å¼‚æ­¥å¤„ç†
    enable_async_processing: bool = True
    async_queue_prioritization: bool = True

    # è´Ÿè½½å‡è¡¡
    enable_load_balancing: bool = True
    enable_health_checks: bool = True

    # ç›‘æ§è®¾ç½®
    enable_detailed_monitoring: bool = True
    enable_real_time_alerts: bool = True


@dataclass
class PerformanceConfig:
    """æ€§èƒ½ä¼˜åŒ–æ€»é…ç½®"""

    # ç»„ä»¶é…ç½®
    redis: RedisConfig = field(default_factory=RedisConfig)
    database: DatabaseConfig = field(default_factory=DatabaseConfig)
    async_processor: AsyncProcessorConfig = field(default_factory=AsyncProcessorConfig)
    load_balancer: LoadBalancerConfig = field(default_factory=LoadBalancerConfig)
    metrics: MetricsConfig = field(default_factory=MetricsConfig)

    # æ€§èƒ½é…ç½®
    thresholds: PerformanceThresholds = field(default_factory=PerformanceThresholds)
    optimization: OptimizationSettings = field(default_factory=OptimizationSettings)

    # å…¨å±€è®¾ç½®
    service_name: str = "claude-enhancer"
    environment: str = "production"  # development, staging, production
    debug_mode: bool = False
    log_level: str = "INFO"

    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_file: Optional[str] = None
    config_refresh_interval: int = 300  # 5åˆ†é’Ÿ


class PerformanceConfigManager:
    """æ€§èƒ½é…ç½®ç®¡ç†å™¨"""

    def __init__(self, config_file: Optional[str] = None):
        self.config_file = config_file or os.getenv(
            "PERFORMANCE_CONFIG_FILE", "performance.yaml"
        )
        self.config = PerformanceConfig()
        self._file_watcher_task = None
        self._last_modified = None

    async def initialize(self) -> PerformanceConfig:
        """åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨"""
        try:
            pass  # Auto-fixed empty block
            # åŠ è½½é…ç½®æ–‡ä»¶
            await self.load_config()

            # å¯åŠ¨é…ç½®æ–‡ä»¶ç›‘æ§
            if self.config.config_refresh_interval > 0:
                self._file_watcher_task = asyncio.create_task(self._watch_config_file())

            logger.info(f"âœ… æ€§èƒ½é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ - ç¯å¢ƒ: {self.config.environment}")
            return self.config

        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_path = Path(self.config_file)

        if not config_path.exists():
            logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {self.config_file}")
            await self._create_default_config_file()
            return

        try:
            with open(config_path, "r", encoding="utf-8") as f:
                if config_path.suffix.lower() in [".yaml", ".yml"]:
                    config_data = yaml.safe_load(f)
                else:
                    config_data = json.load(f)

            # åˆå¹¶é…ç½®
            self._merge_config(config_data)

            # éªŒè¯é…ç½®
            self._validate_config()

            # æ›´æ–°ä¿®æ”¹æ—¶é—´
            self._last_modified = config_path.stat().st_mtime

            logger.info(f"ğŸ“‹ é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_file}")

        except Exception as e:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            raise

    def _merge_config(self, config_data: Dict[str, Any]):
        """åˆå¹¶é…ç½®æ•°æ®"""
        # Redisé…ç½®
        if "redis" in config_data:
            redis_data = config_data["redis"]
            for key, value in redis_data.items():
                if hasattr(self.config.redis, key):
                    setattr(self.config.redis, key, value)

        # æ•°æ®åº“é…ç½®
        if "database" in config_data:
            db_data = config_data["database"]
            for key, value in db_data.items():
                if hasattr(self.config.database, key):
                    setattr(self.config.database, key, value)

        # å¼‚æ­¥å¤„ç†å™¨é…ç½®
        if "async_processor" in config_data:
            async_data = config_data["async_processor"]
            for key, value in async_data.items():
                if hasattr(self.config.async_processor, key):
                    setattr(self.config.async_processor, key, value)

        # è´Ÿè½½å‡è¡¡å™¨é…ç½®
        if "load_balancer" in config_data:
            lb_data = config_data["load_balancer"]
            for key, value in lb_data.items():
                if hasattr(self.config.load_balancer, key):
                    if key == "algorithm" and isinstance(value, str):
                        setattr(
                            self.config.load_balancer, key, LoadBalanceAlgorithm(value)
                        )
                    else:
                        setattr(self.config.load_balancer, key, value)

        # æŒ‡æ ‡é…ç½®
        if "metrics" in config_data:
            metrics_data = config_data["metrics"]
            for key, value in metrics_data.items():
                if hasattr(self.config.metrics, key):
                    setattr(self.config.metrics, key, value)

        # é˜ˆå€¼é…ç½®
        if "thresholds" in config_data:
            threshold_data = config_data["thresholds"]
            for key, value in threshold_data.items():
                if hasattr(self.config.thresholds, key):
                    setattr(self.config.thresholds, key, value)

        # ä¼˜åŒ–è®¾ç½®
        if "optimization" in config_data:
            opt_data = config_data["optimization"]
            for key, value in opt_data.items():
                if hasattr(self.config.optimization, key):
                    if key == "cache_strategy" and isinstance(value, str):
                        setattr(self.config.optimization, key, CacheStrategy(value))
                    else:
                        setattr(self.config.optimization, key, value)

        # å…¨å±€è®¾ç½®
        global_keys = [
            "service_name",
            "environment",
            "debug_mode",
            "log_level",
            "config_refresh_interval",
        ]
        for key in global_keys:
            if key in config_data:
                setattr(self.config, key, config_data[key])

    def _validate_config(self):
        """éªŒè¯é…ç½®åˆæ³•æ€§"""
        errors = []

        # éªŒè¯Redisé…ç½®
        if self.config.redis.port <= 0 or self.config.redis.port > 65535:
            errors.append("Redisç«¯å£å¿…é¡»åœ¨1-65535èŒƒå›´å†…")

        if self.config.redis.pool_size <= 0:
            errors.append("Redisè¿æ¥æ± å¤§å°å¿…é¡»å¤§äº0")

        # éªŒè¯æ•°æ®åº“é…ç½®
        if not self.config.database.url:
            errors.append("æ•°æ®åº“URLä¸èƒ½ä¸ºç©º")

        if self.config.database.pool_size <= 0:
            errors.append("æ•°æ®åº“è¿æ¥æ± å¤§å°å¿…é¡»å¤§äº0")

        # éªŒè¯å¼‚æ­¥å¤„ç†å™¨é…ç½®
        if self.config.async_processor.max_workers <= 0:
            errors.append("å¼‚æ­¥å¤„ç†å™¨å·¥ä½œè¿›ç¨‹æ•°å¿…é¡»å¤§äº0")

        # éªŒè¯é˜ˆå€¼é…ç½®
        if (
            self.config.thresholds.response_time_warning
            >= self.config.thresholds.response_time_critical
        ):
            errors.append("å“åº”æ—¶é—´è­¦å‘Šé˜ˆå€¼å¿…é¡»å°äºä¸¥é‡é˜ˆå€¼")

        if (
            self.config.thresholds.cpu_usage_warning
            >= self.config.thresholds.cpu_usage_critical
        ):
            errors.append("CPUä½¿ç”¨ç‡è­¦å‘Šé˜ˆå€¼å¿…é¡»å°äºä¸¥é‡é˜ˆå€¼")

        if errors:
            raise ValueError(f"é…ç½®éªŒè¯å¤±è´¥:\n" + "\n".join(f"- {error}" for error in errors))

    async def _create_default_config_file(self):
        """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
        default_config = {
            "service_name": "claude-enhancer",
            "environment": "production",
            "debug_mode": False,
            "log_level": "INFO",
            "config_refresh_interval": 300,
            "redis": {
                "host": "localhost",
                "port": 6379,
                "db": 0,
                "pool_size": 50,
                "timeout": 5,
                "compression_enabled": True,
                "default_ttl": 300,
            },
            "database": {
                "pool_size": 20,
                "max_overflow": 30,
                "pool_timeout": 30,
                "slow_query_threshold": 1.0,
                "enable_query_cache": True,
                "query_cache_ttl": 300,
            },
            "async_processor": {
                "max_workers": 10,
                "max_queue_size": 1000,
                "worker_timeout": 300.0,
                "smtp_host": "localhost",
                "smtp_port": 587,
                "api_timeout": 30.0,
            },
            "load_balancer": {
                "algorithm": "weighted_round_robin",
                "health_check_enabled": True,
                "health_check_interval": 30,
                "circuit_breaker_enabled": True,
                "connection_timeout": 10.0,
            },
            "metrics": {
                "collection_interval": 10.0,
                "retention_period_hours": 24,
                "enable_system_metrics": True,
                "export_format": "prometheus",
            },
            "thresholds": {
                "response_time_warning": 500.0,
                "response_time_critical": 1000.0,
                "cpu_usage_warning": 70.0,
                "cpu_usage_critical": 85.0,
                "memory_usage_warning": 75.0,
                "memory_usage_critical": 90.0,
                "error_rate_warning": 1.0,
                "error_rate_critical": 5.0,
            },
            "optimization": {
                "enable_l1_cache": True,
                "enable_l2_cache": True,
                "cache_strategy": "lru",
                "enable_connection_pooling": True,
                "enable_query_optimization": True,
                "enable_response_compression": True,
                "enable_async_processing": True,
                "enable_load_balancing": True,
                "enable_detailed_monitoring": True,
            },
        }

        try:
            config_path = Path(self.config_file)
            config_path.parent.mkdir(parents=True, exist_ok=True)

            with open(config_path, "w", encoding="utf-8") as f:
                if config_path.suffix.lower() in [".yaml", ".yml"]:
                    yaml.dump(default_config, f, default_flow_style=False, indent=2)
                else:
                    json.dump(default_config, f, indent=2)

            logger.info(f"ğŸ“ åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {self.config_file}")

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    async def _watch_config_file(self):
        """ç›‘æ§é…ç½®æ–‡ä»¶å˜åŒ–"""
        while True:
            try:
                await asyncio.sleep(self.config.config_refresh_interval)

                config_path = Path(self.config_file)
                if not config_path.exists():
                    continue

                current_modified = config_path.stat().st_mtime
                if (
                    self._last_modified is None
                    or current_modified > self._last_modified
                ):
                    logger.info("ğŸ”„ æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å˜åŒ–ï¼Œé‡æ–°åŠ è½½...")
                    await self.load_config()
                    logger.info("âœ… é…ç½®æ–‡ä»¶é‡æ–°åŠ è½½å®Œæˆ")

            except Exception as e:
                logger.error(f"âŒ é…ç½®æ–‡ä»¶ç›‘æ§å¤±è´¥: {e}")

    def get_config(self) -> PerformanceConfig:
        """è·å–å½“å‰é…ç½®"""
        return self.config

    async def update_config(self, updates: Dict[str, Any]):
        """æ›´æ–°é…ç½®"""
        try:
            pass  # Auto-fixed empty block
            # å¤‡ä»½å½“å‰é…ç½®
            backup_config = self.config

            # åº”ç”¨æ›´æ–°
            self._merge_config(updates)

            # éªŒè¯é…ç½®
            self._validate_config()

            # ä¿å­˜åˆ°æ–‡ä»¶
            await self._save_config_to_file()

            logger.info("âœ… é…ç½®æ›´æ–°æˆåŠŸ")

        except Exception as e:
            pass  # Auto-fixed empty block
            # æ¢å¤å¤‡ä»½é…ç½®
            self.config = backup_config
            logger.error(f"âŒ é…ç½®æ›´æ–°å¤±è´¥ï¼Œå·²æ¢å¤: {e}")
            raise

    async def _save_config_to_file(self):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        config_data = {
            "service_name": self.config.service_name,
            "environment": self.config.environment,
            "debug_mode": self.config.debug_mode,
            "log_level": self.config.log_level,
            "config_refresh_interval": self.config.config_refresh_interval,
            "redis": {
                "host": self.config.redis.host,
                "port": self.config.redis.port,
                "db": self.config.redis.db,
                "pool_size": self.config.redis.pool_size,
                "timeout": self.config.redis.timeout,
                "compression_enabled": self.config.redis.compression_enabled,
                "default_ttl": self.config.redis.default_ttl,
            },
            "database": {
                "pool_size": self.config.database.pool_size,
                "max_overflow": self.config.database.max_overflow,
                "pool_timeout": self.config.database.pool_timeout,
                "slow_query_threshold": self.config.database.slow_query_threshold,
                "enable_query_cache": self.config.database.enable_query_cache,
                "query_cache_ttl": self.config.database.query_cache_ttl,
            },
            "thresholds": {
                "response_time_warning": self.config.thresholds.response_time_warning,
                "response_time_critical": self.config.thresholds.response_time_critical,
                "cpu_usage_warning": self.config.thresholds.cpu_usage_warning,
                "cpu_usage_critical": self.config.thresholds.cpu_usage_critical,
                "memory_usage_warning": self.config.thresholds.memory_usage_warning,
                "memory_usage_critical": self.config.thresholds.memory_usage_critical,
                "error_rate_warning": self.config.thresholds.error_rate_warning,
                "error_rate_critical": self.config.thresholds.error_rate_critical,
            },
            "optimization": {
                "enable_l1_cache": self.config.optimization.enable_l1_cache,
                "enable_l2_cache": self.config.optimization.enable_l2_cache,
                "cache_strategy": self.config.optimization.cache_strategy.value,
                "enable_connection_pooling": self.config.optimization.enable_connection_pooling,
                "enable_query_optimization": self.config.optimization.enable_query_optimization,
                "enable_response_compression": self.config.optimization.enable_response_compression,
                "enable_async_processing": self.config.optimization.enable_async_processing,
                "enable_load_balancing": self.config.optimization.enable_load_balancing,
                "enable_detailed_monitoring": self.config.optimization.enable_detailed_monitoring,
            },
        }

        config_path = Path(self.config_file)
        with open(config_path, "w", encoding="utf-8") as f:
            if config_path.suffix.lower() in [".yaml", ".yml"]:
                yaml.dump(config_data, f, default_flow_style=False, indent=2)
            else:
                json.dump(config_data, f, indent=2)

    def get_environment_specific_config(self) -> Dict[str, Any]:
        """è·å–ç¯å¢ƒç‰¹å®šé…ç½®"""
        env_config = {
            "development": {
                "debug_mode": True,
                "log_level": "DEBUG",
                "redis": {"pool_size": 10},
                "database": {"pool_size": 5},
                "metrics": {"collection_interval": 5.0},
            },
            "staging": {
                "debug_mode": False,
                "log_level": "INFO",
                "redis": {"pool_size": 20},
                "database": {"pool_size": 10},
                "metrics": {"collection_interval": 10.0},
            },
            "production": {
                "debug_mode": False,
                "log_level": "WARNING",
                "redis": {"pool_size": 50},
                "database": {"pool_size": 20},
                "metrics": {"collection_interval": 10.0},
            },
        }

        return env_config.get(self.config.environment, {})

    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            config_path = Path(self.config_file)
            return config_path.exists() and self.config is not None
        except:
            return False

    async def shutdown(self):
        """å…³é—­é…ç½®ç®¡ç†å™¨"""
        if self._file_watcher_task:
            self._file_watcher_task.cancel()
            try:
                await self._file_watcher_task
            except asyncio.CancelledError:
                pass

        logger.info("âœ… æ€§èƒ½é…ç½®ç®¡ç†å™¨å·²å…³é—­")


# å…¨å±€é…ç½®ç®¡ç†å™¨å®ä¾‹
_config_manager: Optional[PerformanceConfigManager] = None


async def get_performance_config(
    config_file: Optional[str] = None,
) -> PerformanceConfig:
    """è·å–æ€§èƒ½é…ç½®ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _config_manager

    if _config_manager is None:
        _config_manager = PerformanceConfigManager(config_file)
        await _config_manager.initialize()

    return _config_manager.get_config()


def get_config_manager() -> Optional[PerformanceConfigManager]:
    """è·å–é…ç½®ç®¡ç†å™¨å®ä¾‹"""
    return _config_manager


# ç¯å¢ƒå˜é‡æ”¯æŒ
def load_config_from_env() -> Dict[str, Any]:
    """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
    env_config = {}

    # Redisé…ç½®
    if os.getenv("REDIS_HOST"):
        env_config.setdefault("redis", {})["host"] = os.getenv("REDIS_HOST")
    if os.getenv("REDIS_PORT"):
        env_config.setdefault("redis", {})["port"] = int(os.getenv("REDIS_PORT"))
    if os.getenv("REDIS_PASSWORD"):
        env_config.setdefault("redis", {})["password"] = os.getenv("REDIS_PASSWORD")

    # æ•°æ®åº“é…ç½®
    if os.getenv("DATABASE_URL"):
        env_config.setdefault("database", {})["url"] = os.getenv("DATABASE_URL")

    # æœåŠ¡é…ç½®
    if os.getenv("SERVICE_NAME"):
        env_config["service_name"] = os.getenv("SERVICE_NAME")
    if os.getenv("ENVIRONMENT"):
        env_config["environment"] = os.getenv("ENVIRONMENT")
    if os.getenv("DEBUG_MODE"):
        env_config["debug_mode"] = os.getenv("DEBUG_MODE").lower() == "true"

    return env_config
