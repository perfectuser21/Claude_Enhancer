#!/usr/bin/env python3
"""
Perfect21 Git Hooks Integration Test
ä¸“é—¨æµ‹è¯•Gitå·¥ä½œæµä¸å¤šAgentåè°ƒæœºåˆ¶

é‡ç‚¹æµ‹è¯•:
- Gité’©å­è§¦å‘æœºåˆ¶
- å¤šAgentå¹¶è¡Œè°ƒç”¨
- åˆ†æ”¯ä¿æŠ¤ç­–ç•¥
- SubAgentè·¯ç”±é€‰æ‹©
"""

import os
import sys
import json
import subprocess
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

class GitHooksIntegrationTest:
    """Git Hooksé›†æˆæµ‹è¯•"""

    def __init__(self):
        self.project_root = Path(__file__).parent
        self.test_results = {
            'timestamp': datetime.now().isoformat(),
            'test_summary': {},
            'hooks_tests': {},
            'agent_coordination': {},
            'performance': {}
        }
        print("ğŸ”§ Perfect21 Git Hooksé›†æˆæµ‹è¯•åˆå§‹åŒ–")

    def test_hooks_configuration(self):
        """æµ‹è¯•é’©å­é…ç½®"""
        print("ğŸ“‹ æµ‹è¯•Gité’©å­é…ç½®...")

        try:
            from features.git_workflow.hooks_manager import GitHooksManager
            hooks_manager = GitHooksManager()

            config_test = {
                'hooks_manager_init': True,
                'total_hooks': len(hooks_manager.hooks_config),
                'hook_groups': list(hooks_manager.hook_groups.keys()),
                'required_hooks': [],
                'subagent_mapping': {}
            }

            # æ£€æŸ¥å¿…éœ€é’©å­
            for hook_name, config in hooks_manager.hooks_config.items():
                if config.get('required'):
                    config_test['required_hooks'].append(hook_name)

                # è®°å½•SubAgentæ˜ å°„
                if 'subagent' in config:
                    config_test['subagent_mapping'][hook_name] = config['subagent']

            self.test_results['hooks_tests']['configuration'] = config_test
            print(f"âœ… é…ç½®æµ‹è¯•å®Œæˆ - å…±{config_test['total_hooks']}ä¸ªé’©å­")
            return True

        except Exception as e:
            self.test_results['hooks_tests']['configuration'] = {
                'success': False,
                'error': str(e)
            }
            print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_hook_installation(self):
        """æµ‹è¯•é’©å­å®‰è£…æœºåˆ¶"""
        print("âš™ï¸ æµ‹è¯•é’©å­å®‰è£…...")

        try:
            from features.git_workflow.hooks_manager import GitHooksManager
            hooks_manager = GitHooksManager()

            # æ£€æŸ¥Gitç›®å½•
            git_hooks_dir = Path('.git/hooks')
            git_exists = git_hooks_dir.exists()

            install_test = {
                'git_hooks_dir_exists': git_exists,
                'install_capability': True,
                'hook_groups_available': list(hooks_manager.hook_groups.keys()),
                'installation_methods': ['single', 'group', 'all']
            }

            if git_exists:
                # æ£€æŸ¥ç°æœ‰é’©å­
                existing_hooks = [f.name for f in git_hooks_dir.iterdir()
                                if f.is_file() and not f.name.endswith('.sample')]
                install_test['existing_hooks'] = existing_hooks
                install_test['perfect21_hooks'] = [
                    hook for hook in existing_hooks
                    if self.is_perfect21_hook(git_hooks_dir / hook)
                ]

            self.test_results['hooks_tests']['installation'] = install_test
            print(f"âœ… å®‰è£…æµ‹è¯•å®Œæˆ - Gitç›®å½•: {'å­˜åœ¨' if git_exists else 'ä¸å­˜åœ¨'}")
            return True

        except Exception as e:
            self.test_results['hooks_tests']['installation'] = {
                'success': False,
                'error': str(e)
            }
            print(f"âŒ å®‰è£…æµ‹è¯•å¤±è´¥: {e}")
            return False

    def is_perfect21_hook(self, hook_file: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºPerfect21é’©å­"""
        try:
            content = hook_file.read_text()
            return 'Perfect21' in content or 'perfect21' in content
        except:
            return False

    def test_hook_execution_simulation(self):
        """æµ‹è¯•é’©å­æ‰§è¡Œæ¨¡æ‹Ÿ"""
        print("ğŸš€ æµ‹è¯•é’©å­æ‰§è¡Œæ¨¡æ‹Ÿ...")

        try:
            from main.perfect21 import Perfect21
            p21 = Perfect21()

            execution_test = {
                'perfect21_init': True,
                'hook_simulations': {},
                'agent_calls_generated': {},
                'branch_routing': {}
            }

            # æµ‹è¯•ä¸åŒé’©å­çš„æ‰§è¡Œ
            test_hooks = [
                ('pre-commit', []),
                ('pre-push', ['origin']),
                ('post-checkout', ['old_ref', 'new_ref', '1']),
                ('commit-msg', ['.git/COMMIT_EDITMSG'])
            ]

            for hook_name, args in test_hooks:
                try:
                    print(f"  ğŸ” æ¨¡æ‹Ÿæ‰§è¡Œ: {hook_name}")
                    result = p21.git_hook_handler(hook_name, *args)

                    execution_test['hook_simulations'][hook_name] = {
                        'success': result.get('success', False),
                        'has_call_info': 'call_info' in result,
                        'message': result.get('message', '')
                    }

                    # è®°å½•Agentè°ƒç”¨ä¿¡æ¯
                    if 'call_info' in result:
                        call_info = result['call_info']
                        execution_test['agent_calls_generated'][hook_name] = {
                            'command': call_info.get('command', ''),
                            'context_provided': 'context' in call_info
                        }

                except Exception as e:
                    execution_test['hook_simulations'][hook_name] = {
                        'success': False,
                        'error': str(e)
                    }

            self.test_results['hooks_tests']['execution'] = execution_test
            print(f"âœ… æ‰§è¡Œæ¨¡æ‹Ÿå®Œæˆ - æµ‹è¯•{len(test_hooks)}ä¸ªé’©å­")
            return True

        except Exception as e:
            self.test_results['hooks_tests']['execution'] = {
                'success': False,
                'error': str(e)
            }
            print(f"âŒ æ‰§è¡Œæ¨¡æ‹Ÿå¤±è´¥: {e}")
            return False

    def test_branch_based_routing(self):
        """æµ‹è¯•åŸºäºåˆ†æ”¯çš„Agentè·¯ç”±"""
        print("ğŸŒ¿ æµ‹è¯•åˆ†æ”¯è·¯ç”±ç­–ç•¥...")

        try:
            from main.perfect21 import Perfect21
            p21 = Perfect21()

            # è·å–å½“å‰åˆ†æ”¯ä¿¡æ¯
            current_branch = self.get_current_branch()

            routing_test = {
                'current_branch': current_branch,
                'routing_logic': {},
                'protection_levels': {},
                'agent_selection': {}
            }

            # æµ‹è¯•ä¸åŒåˆ†æ”¯ç±»å‹çš„è·¯ç”±
            branch_scenarios = [
                ('main', 'main'),
                ('feature/test', 'feature'),
                ('release/1.0.0', 'release'),
                ('hotfix/critical', 'hotfix')
            ]

            for branch_name, expected_type in branch_scenarios:
                try:
                    # æ¨¡æ‹Ÿåˆ†æ”¯åˆ†æ
                    branch_info = self.analyze_branch_type(branch_name)
                    routing_test['routing_logic'][branch_name] = branch_info

                    # åŸºäºåˆ†æ”¯ç±»å‹çš„Agenté€‰æ‹©é€»è¾‘
                    expected_agent = self.get_expected_agent_for_branch(expected_type)
                    routing_test['agent_selection'][branch_name] = expected_agent

                except Exception as e:
                    routing_test['routing_logic'][branch_name] = {'error': str(e)}

            self.test_results['agent_coordination']['branch_routing'] = routing_test
            print(f"âœ… åˆ†æ”¯è·¯ç”±æµ‹è¯•å®Œæˆ - å½“å‰åˆ†æ”¯: {current_branch}")
            return True

        except Exception as e:
            self.test_results['agent_coordination']['branch_routing'] = {
                'success': False,
                'error': str(e)
            }
            print(f"âŒ åˆ†æ”¯è·¯ç”±æµ‹è¯•å¤±è´¥: {e}")
            return False

    def get_current_branch(self) -> str:
        """è·å–å½“å‰Gitåˆ†æ”¯"""
        try:
            result = subprocess.run(['git', 'branch', '--show-current'],
                                  capture_output=True, text=True)
            return result.stdout.strip() if result.returncode == 0 else 'unknown'
        except:
            return 'unknown'

    def analyze_branch_type(self, branch_name: str) -> Dict[str, Any]:
        """åˆ†æåˆ†æ”¯ç±»å‹"""
        if branch_name.startswith('main') or branch_name == 'master':
            return {
                'type': 'main',
                'protection_level': 'strict',
                'requires_review': True,
                'suggested_agent': '@orchestrator'
            }
        elif branch_name.startswith('feature/'):
            return {
                'type': 'feature',
                'protection_level': 'standard',
                'requires_review': False,
                'suggested_agent': '@code-reviewer'
            }
        elif branch_name.startswith('release/'):
            return {
                'type': 'release',
                'protection_level': 'strict',
                'requires_review': True,
                'suggested_agent': '@deployment-manager'
            }
        elif branch_name.startswith('hotfix/'):
            return {
                'type': 'hotfix',
                'protection_level': 'expedited',
                'requires_review': True,
                'suggested_agent': '@test-engineer'
            }
        else:
            return {
                'type': 'unknown',
                'protection_level': 'standard',
                'requires_review': False,
                'suggested_agent': '@code-reviewer'
            }

    def get_expected_agent_for_branch(self, branch_type: str) -> str:
        """è·å–åˆ†æ”¯ç±»å‹å¯¹åº”çš„é¢„æœŸAgent"""
        agent_mapping = {
            'main': '@orchestrator',
            'feature': '@code-reviewer',
            'release': '@deployment-manager',
            'hotfix': '@test-engineer'
        }
        return agent_mapping.get(branch_type, '@code-reviewer')

    def test_multi_agent_coordination(self):
        """æµ‹è¯•å¤šAgentåè°ƒæœºåˆ¶"""
        print("ğŸ¤ æµ‹è¯•å¤šAgentåè°ƒ...")

        try:
            coordination_test = {
                'parallel_capability': True,
                'agent_workflows': {},
                'coordination_scenarios': {}
            }

            # æµ‹è¯•ä¸åŒåè°ƒåœºæ™¯
            scenarios = {
                'main_branch_commit': {
                    'primary_agent': '@orchestrator',
                    'supporting_agents': ['@code-reviewer', '@security-auditor', '@test-engineer'],
                    'execution_mode': 'sequential_with_gates'
                },
                'feature_development': {
                    'primary_agent': '@code-reviewer',
                    'supporting_agents': ['@test-engineer'],
                    'execution_mode': 'parallel'
                },
                'security_focused': {
                    'primary_agent': '@security-auditor',
                    'supporting_agents': ['@code-reviewer'],
                    'execution_mode': 'security_first'
                },
                'performance_critical': {
                    'primary_agent': '@performance-engineer',
                    'supporting_agents': ['@test-engineer', '@devops-engineer'],
                    'execution_mode': 'performance_gated'
                }
            }

            for scenario_name, scenario_config in scenarios.items():
                coordination_test['coordination_scenarios'][scenario_name] = {
                    'agents_count': len(scenario_config['supporting_agents']) + 1,
                    'coordination_complexity': self.calculate_coordination_complexity(scenario_config),
                    'expected_execution_time': self.estimate_execution_time(scenario_config),
                    'config': scenario_config
                }

            # æµ‹è¯•Agentå¯ç”¨æ€§
            available_agents = self.check_available_agents()
            coordination_test['available_agents'] = available_agents

            self.test_results['agent_coordination']['multi_agent'] = coordination_test
            print(f"âœ… å¤šAgentåè°ƒæµ‹è¯•å®Œæˆ - å¯ç”¨Agent: {len(available_agents)}ä¸ª")
            return True

        except Exception as e:
            self.test_results['agent_coordination']['multi_agent'] = {
                'success': False,
                'error': str(e)
            }
            print(f"âŒ å¤šAgentåè°ƒæµ‹è¯•å¤±è´¥: {e}")
            return False

    def calculate_coordination_complexity(self, scenario_config: Dict) -> str:
        """è®¡ç®—åè°ƒå¤æ‚åº¦"""
        agent_count = len(scenario_config['supporting_agents']) + 1
        execution_mode = scenario_config['execution_mode']

        if agent_count <= 2:
            return 'simple'
        elif agent_count <= 4 and 'parallel' in execution_mode:
            return 'moderate'
        else:
            return 'complex'

    def estimate_execution_time(self, scenario_config: Dict) -> str:
        """ä¼°ç®—æ‰§è¡Œæ—¶é—´"""
        agent_count = len(scenario_config['supporting_agents']) + 1
        execution_mode = scenario_config['execution_mode']

        if 'parallel' in execution_mode:
            return f"{agent_count * 2}-{agent_count * 3}ç§’"
        elif 'sequential' in execution_mode:
            return f"{agent_count * 5}-{agent_count * 8}ç§’"
        else:
            return f"{agent_count * 3}-{agent_count * 5}ç§’"

    def check_available_agents(self) -> list:
        """æ£€æŸ¥å¯ç”¨çš„Agent"""
        agents_dir = self.project_root / 'core' / 'claude-code-unified-agents' / '.claude' / 'agents'

        if not agents_dir.exists():
            return []

        # æ‰«ææ‰€æœ‰Agentæ–‡ä»¶
        agent_files = list(agents_dir.rglob('*.md'))
        return [f.stem for f in agent_files if f.is_file()]

    def test_performance_benchmarks(self):
        """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
        print("âš¡ æµ‹è¯•æ€§èƒ½åŸºå‡†...")

        import time

        try:
            performance_test = {
                'hook_execution_times': {},
                'agent_call_preparation': {},
                'parallel_processing': {}
            }

            # æµ‹è¯•é’©å­æ‰§è¡Œæ—¶é—´
            from main.perfect21 import Perfect21
            p21 = Perfect21()

            test_hooks = ['pre-commit', 'pre-push', 'post-checkout']

            for hook_name in test_hooks:
                start_time = time.time()
                result = p21.git_hook_handler(hook_name)
                execution_time = time.time() - start_time

                performance_test['hook_execution_times'][hook_name] = {
                    'time_seconds': execution_time,
                    'success': result.get('success', False),
                    'performance_rating': 'fast' if execution_time < 1 else 'moderate' if execution_time < 3 else 'slow'
                }

            # æµ‹è¯•Agentè°ƒç”¨å‡†å¤‡æ—¶é—´
            from features.auto_capability_injection import get_global_injector

            injector = get_global_injector()
            start_time = time.time()
            result = injector.inject_and_call_orchestrator("æ€§èƒ½æµ‹è¯•è¯·æ±‚")
            injection_time = time.time() - start_time

            performance_test['agent_call_preparation'] = {
                'injection_time': injection_time,
                'success': result.get('success', False),
                'context_size': len(result.get('orchestrator_context', '')),
                'performance_rating': 'fast' if injection_time < 2 else 'moderate' if injection_time < 5 else 'slow'
            }

            self.test_results['performance'] = performance_test
            print(f"âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ - å¹³å‡é’©å­æ‰§è¡Œæ—¶é—´: {sum(t['time_seconds'] for t in performance_test['hook_execution_times'].values()) / len(performance_test['hook_execution_times']):.3f}ç§’")
            return True

        except Exception as e:
            self.test_results['performance'] = {
                'success': False,
                'error': str(e)
            }
            print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            return False

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ Perfect21 Git Hooks Integration Test Suite")
        print("=" * 60)
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        print("=" * 60)

        test_methods = [
            ('é…ç½®æµ‹è¯•', self.test_hooks_configuration),
            ('å®‰è£…æµ‹è¯•', self.test_hook_installation),
            ('æ‰§è¡Œæ¨¡æ‹Ÿ', self.test_hook_execution_simulation),
            ('åˆ†æ”¯è·¯ç”±', self.test_branch_based_routing),
            ('å¤šAgentåè°ƒ', self.test_multi_agent_coordination),
            ('æ€§èƒ½åŸºå‡†', self.test_performance_benchmarks)
        ]

        results = []
        for test_name, test_method in test_methods:
            print(f"\nğŸ” å¼€å§‹{test_name}...")
            try:
                success = test_method()
                results.append((test_name, success))
                if success:
                    print(f"âœ… {test_name}å®Œæˆ")
                else:
                    print(f"âŒ {test_name}å¤±è´¥")
            except Exception as e:
                print(f"ğŸ’¥ {test_name}å¼‚å¸¸: {e}")
                results.append((test_name, False))

        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_test_report(results)

        return results

    def generate_test_report(self, results):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")

        # è®¡ç®—æ€»ä½“ç»“æœ
        total_tests = len(results)
        passed_tests = sum(1 for _, success in results if success)
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0

        # æ›´æ–°æµ‹è¯•æ‘˜è¦
        self.test_results['test_summary'] = {
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'failed_tests': total_tests - passed_tests,
            'success_rate': success_rate,
            'overall_status': 'é€šè¿‡' if passed_tests == total_tests else 'éƒ¨åˆ†å¤±è´¥'
        }

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report_content = self._generate_markdown_report()

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.project_root / 'git_hooks_integration_test_report.md'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)

        # ä¿å­˜JSONæ•°æ®
        json_file = self.project_root / 'git_hooks_integration_test_results.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)

        # æ˜¾ç¤ºç»“æœ
        print(f"ğŸ“‹ æµ‹è¯•æŠ¥å‘Š: {report_file}")
        print(f"ğŸ“Š è¯¦ç»†æ•°æ®: {json_file}")
        print(f"ğŸ¯ æµ‹è¯•ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡ ({success_rate:.1f}%)")

        if passed_tests == total_tests:
            print("ğŸ‰ Perfect21 Git Hooksé›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡!")
            print("   âœ… Gitå·¥ä½œæµæœºåˆ¶æ­£å¸¸")
            print("   âœ… å¤šAgentåè°ƒå°±ç»ª")
            print("   âœ… åˆ†æ”¯ä¿æŠ¤ç­–ç•¥æœ‰æ•ˆ")
            print("   âœ… æ€§èƒ½æŒ‡æ ‡è¾¾æ ‡")
        else:
            failed_count = total_tests - passed_tests
            print(f"âš ï¸ {failed_count}ä¸ªæµ‹è¯•éœ€è¦å…³æ³¨")

            # æ˜¾ç¤ºå¤±è´¥çš„æµ‹è¯•
            for test_name, success in results:
                if not success:
                    print(f"   âŒ {test_name}")

        print("=" * 60)

    def _generate_markdown_report(self) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        summary = self.test_results['test_summary']

        report = f"""# Perfect21 Git Hooks Integration Test Report

**æµ‹è¯•æ—¶é—´**: {self.test_results['timestamp']}
**æ€»ä½“çŠ¶æ€**: {summary['overall_status']}
**æˆåŠŸç‡**: {summary['success_rate']:.1f}%

## ğŸ“‹ æµ‹è¯•æ¦‚è§ˆ

- **æ€»æµ‹è¯•æ•°**: {summary['total_tests']}
- **é€šè¿‡æ•°**: {summary['passed_tests']}
- **å¤±è´¥æ•°**: {summary['failed_tests']}

## ğŸ”§ Git Hooksæµ‹è¯•ç»“æœ

### é…ç½®æµ‹è¯•
"""

        # æ·»åŠ å…·ä½“æµ‹è¯•ç»“æœ
        if 'configuration' in self.test_results['hooks_tests']:
            config = self.test_results['hooks_tests']['configuration']
            if not config.get('success', True):
                report += f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {config.get('error', 'æœªçŸ¥é”™è¯¯')}\n"
            else:
                report += f"âœ… å‘ç°{config.get('total_hooks', 0)}ä¸ªé’©å­é…ç½®\n"
                report += f"âœ… {len(config.get('hook_groups', []))}ä¸ªé’©å­ç»„å¯ç”¨\n"

        if 'execution' in self.test_results['hooks_tests']:
            execution = self.test_results['hooks_tests']['execution']
            if execution.get('success', True):
                simulations = execution.get('hook_simulations', {})
                successful_sims = sum(1 for s in simulations.values() if s.get('success'))
                report += f"âœ… é’©å­æ‰§è¡Œæ¨¡æ‹Ÿ: {successful_sims}/{len(simulations)}æˆåŠŸ\n"

        # æ·»åŠ Agentåè°ƒç»“æœ
        report += "\n## ğŸ¤ å¤šAgentåè°ƒæµ‹è¯•\n\n"

        if 'multi_agent' in self.test_results['agent_coordination']:
            multi_agent = self.test_results['agent_coordination']['multi_agent']
            if not multi_agent.get('success', True):
                report += f"âŒ å¤šAgentåè°ƒæµ‹è¯•å¤±è´¥: {multi_agent.get('error')}\n"
            else:
                scenarios = multi_agent.get('coordination_scenarios', {})
                report += f"âœ… æµ‹è¯•{len(scenarios)}ä¸ªåè°ƒåœºæ™¯\n"
                available_agents = len(multi_agent.get('available_agents', []))
                report += f"âœ… {available_agents}ä¸ªAgentå¯ç”¨\n"

        # æ·»åŠ æ€§èƒ½æµ‹è¯•ç»“æœ
        report += "\n## âš¡ æ€§èƒ½æµ‹è¯•ç»“æœ\n\n"

        if self.test_results.get('performance'):
            perf = self.test_results['performance']
            if not perf.get('success', True):
                report += f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {perf.get('error')}\n"
            else:
                hook_times = perf.get('hook_execution_times', {})
                if hook_times:
                    avg_time = sum(t['time_seconds'] for t in hook_times.values()) / len(hook_times)
                    report += f"âœ… å¹³å‡é’©å­æ‰§è¡Œæ—¶é—´: {avg_time:.3f}ç§’\n"

                injection = perf.get('agent_call_preparation', {})
                if injection:
                    report += f"âœ… Agentè°ƒç”¨å‡†å¤‡æ—¶é—´: {injection.get('injection_time', 0):.3f}ç§’\n"

        report += "\n## ğŸ’¡ å»ºè®®\n\n"

        if summary['success_rate'] == 100:
            report += "ğŸ‰ Perfect21 Gitå·¥ä½œæµç³»ç»Ÿå®Œå…¨å°±ç»ªï¼Œå¯ä»¥æŠ•å…¥ç”Ÿäº§ä½¿ç”¨ï¼\n\n"
            report += "- æ‰€æœ‰Gité’©å­åŠŸèƒ½æ­£å¸¸\n"
            report += "- å¤šAgentåè°ƒæœºåˆ¶å¯é \n"
            report += "- æ€§èƒ½æŒ‡æ ‡æ»¡è¶³è¦æ±‚\n"
        else:
            report += "éœ€è¦ä¿®å¤çš„é—®é¢˜ï¼š\n\n"
            # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„ä¿®å¤å»ºè®®
            report += "- æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹\n"
            report += "- éªŒè¯Agenté…ç½®å®Œæ•´æ€§\n"
            report += "- ä¼˜åŒ–æ€§èƒ½ç“¶é¢ˆ\n"

        return report

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    test_suite = GitHooksIntegrationTest()
    results = test_suite.run_all_tests()

    # è¿”å›é€€å‡ºç 
    all_passed = all(success for _, success in results)
    return 0 if all_passed else 1

if __name__ == '__main__':
    exit_code = main()
    exit(exit_code)