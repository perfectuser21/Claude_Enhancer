# Perfect21 CI/CD测试流水线配置
# GitHub Actions / GitLab CI / Jenkins通用配置

name: Perfect21 Test Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # 每日凌晨2点运行完整测试
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.10'
  TESTING: 'true'
  LOG_LEVEL: 'INFO'

jobs:
  # 代码质量检查
  quality-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black isort mypy
          pip install -r tests/requirements.txt
      
      - name: Lint with flake8
        run: |
          flake8 api config features main --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 api config features main --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: Check code formatting with black
        run: black --check api config features main
      
      - name: Check import sorting with isort
        run: isort --check-only api config features main
      
      - name: Type check with mypy
        run: mypy api config features main --ignore-missing-imports
  
  # 单元测试
  unit-tests:
    runs-on: ubuntu-latest
    needs: quality-check
    
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11']
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install -e .
      
      - name: Run unit tests
        run: |
          pytest tests/ -m "unit" \
            --cov=api --cov=config --cov=features --cov=main \
            --cov-report=xml --cov-report=term-missing \
            --junitxml=junit-unit-${{ matrix.python-version }}.xml
      
      - name: Upload unit test results
        uses: actions/upload-artifact@v3
        with:
          name: unit-test-results-${{ matrix.python-version }}
          path: |
            junit-unit-${{ matrix.python-version }}.xml
            coverage.xml
  
  # 集成测试
  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: --health-cmd "redis-cli ping" --health-interval 10s --health-timeout 5s --health-retries 5
      
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: perfect21_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test123
        ports:
          - 5432:5432
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install -e .
      
      - name: Wait for services
        run: |
          sleep 10
          redis-cli -h localhost ping
          pg_isready -h localhost -p 5432 -U test
      
      - name: Run integration tests
        env:
          DB_URL: postgresql://test:test123@localhost:5432/perfect21_test
          REDIS_URL: redis://localhost:6379/1
        run: |
          pytest tests/ -m "integration" \
            --cov=api --cov=config --cov=features --cov=main \
            --cov-report=xml --cov-report=term-missing \
            --junitxml=junit-integration.xml
      
      - name: Upload integration test results
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results
          path: |
            junit-integration.xml
            coverage.xml
  
  # 安全测试
  security-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install bandit safety
          pip install -e .
      
      - name: Run security tests
        run: |
          pytest tests/ -m "security" \
            --junitxml=junit-security.xml
      
      - name: Run bandit security scan
        run: bandit -r api config features main -f json -o bandit-report.json
      
      - name: Check dependencies for security issues
        run: safety check --json --output safety-report.json
      
      - name: Upload security test results
        uses: actions/upload-artifact@v3
        with:
          name: security-test-results
          path: |
            junit-security.xml
            bandit-report.json
            safety-report.json
  
  # E2E测试
  e2e-tests:
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install -e .
      
      - name: Start Perfect21 API server
        run: |
          python api/rest_server.py --host 0.0.0.0 --port 8000 &
          sleep 10
      
      - name: Run E2E tests
        run: |
          pytest tests/ -m "e2e" \
            --junitxml=junit-e2e.xml
      
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        with:
          name: e2e-test-results
          path: junit-e2e.xml
  
  # 性能测试
  performance-tests:
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[perf]')
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install -e .
      
      - name: Start Perfect21 API server
        run: |
          python api/rest_server.py --host 0.0.0.0 --port 8000 &
          sleep 10
      
      - name: Run performance tests
        run: |
          pytest tests/ -m "performance" \
            --benchmark-json=benchmark-results.json \
            --junitxml=junit-performance.xml
      
      - name: Run load tests
        run: |
          python tests/load_test_auth_api.py
      
      - name: Upload performance test results
        uses: actions/upload-artifact@v3
        with:
          name: performance-test-results
          path: |
            junit-performance.xml
            benchmark-results.json
            load_test_report_*.md
  
  # 测试报告生成
  test-report:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, security-tests, e2e-tests]
    if: always()
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Download all test results
        uses: actions/download-artifact@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install report dependencies
        run: |
          python -m pip install --upgrade pip
          pip install allure-pytest jinja2 coverage
      
      - name: Generate combined coverage report
        run: |
          coverage combine **/coverage.xml || true
          coverage report --format=markdown > coverage-report.md || true
          coverage html -d coverage-html || true
      
      - name: Generate test summary
        run: |
          python -c "
          import json
          import glob
          import xml.etree.ElementTree as ET
          from datetime import datetime
          
          # 收集所有测试结果
          summary = {
              'timestamp': datetime.now().isoformat(),
              'total_tests': 0,
              'passed': 0,
              'failed': 0,
              'skipped': 0,
              'test_suites': []
          }
          
          for junit_file in glob.glob('**/*junit*.xml', recursive=True):
              try:
                  tree = ET.parse(junit_file)
                  root = tree.getroot()
                  
                  suite_info = {
                      'name': root.get('name', junit_file),
                      'tests': int(root.get('tests', 0)),
                      'failures': int(root.get('failures', 0)),
                      'errors': int(root.get('errors', 0)),
                      'skipped': int(root.get('skipped', 0))
                  }
                  
                  summary['total_tests'] += suite_info['tests']
                  summary['failed'] += suite_info['failures'] + suite_info['errors']
                  summary['skipped'] += suite_info['skipped']
                  summary['passed'] += suite_info['tests'] - suite_info['failures'] - suite_info['errors'] - suite_info['skipped']
                  summary['test_suites'].append(suite_info)
                  
              except Exception as e:
                  print(f'Error parsing {junit_file}: {e}')
          
          with open('test-summary.json', 'w') as f:
              json.dump(summary, f, indent=2)
          
          # 生成Markdown报告
          with open('test-summary.md', 'w') as f:
              f.write(f'''# Perfect21 测试结果报告\n\n')
              f.write(f'**测试时间**: {summary[\"timestamp\"]}\n\n')
              f.write(f'## 测试统计\n\n')
              f.write(f'- **总测试数**: {summary[\"total_tests\"]}\n')
              f.write(f'- **通过**: {summary[\"passed\"]}\n')
              f.write(f'- **失败**: {summary[\"failed\"]}\n')
              f.write(f'- **跳过**: {summary[\"skipped\"]}\n')
              f.write(f'- **成功率**: {(summary[\"passed\"]/summary[\"total_tests\"]*100):.2f}%\n\n' if summary[\"total_tests\"] > 0 else '- **成功率**: N/A\n\n')
              
              f.write('## 测试套件详情\n\n')
              for suite in summary['test_suites']:
                  f.write(f'### {suite[\"name\"]}\n')
                  f.write(f'- 测试数: {suite[\"tests\"]}\n')
                  f.write(f'- 通过: {suite[\"tests\"] - suite[\"failures\"] - suite[\"errors\"] - suite[\"skipped\"]}\n')
                  f.write(f'- 失败: {suite[\"failures\"]}\n')
                  f.write(f'- 错误: {suite[\"errors\"]}\n')
                  f.write(f'- 跳过: {suite[\"skipped\"]}\n\n')
          "
      
      - name: Upload test report
        uses: actions/upload-artifact@v3
        with:
          name: test-report
          path: |
            test-summary.json
            test-summary.md
            coverage-report.md
            coverage-html/
      
      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            try {
              const summary = JSON.parse(fs.readFileSync('test-summary.json', 'utf8'));
              const coverage = fs.readFileSync('coverage-report.md', 'utf8').substring(0, 1000);
              
              const body = `## 🧪 测试结果
              
              ### 📊 统计信息
              - **总测试数**: ${summary.total_tests}
              - **通过**: ${summary.passed} ✅
              - **失败**: ${summary.failed} ❌
              - **跳过**: ${summary.skipped} ⏭️
              - **成功率**: ${summary.total_tests > 0 ? (summary.passed/summary.total_tests*100).toFixed(2) : 'N/A'}%
              
              ### 📈 覆盖率
              ${coverage}
              
              <details>
              <summary>📄 查看详细报告</summary>
              
              ${summary.test_suites.map(suite => 
                `**${suite.name}**: ${suite.tests} 测试, ${suite.tests - suite.failures - suite.errors - suite.skipped} 通过`
              ).join('\n')}
              
              </details>
              `;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            } catch (error) {
              console.error('Failed to post test results:', error);
            }

  # 部署到测试环境
  deploy-test:
    runs-on: ubuntu-latest
    needs: [test-report]
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Deploy to test environment
        run: |
          echo "🚀 Deploying to test environment..."
          # 这里添加实际的部署命令
          # 例如: kubectl apply -f k8s/test/
          # 或: docker-compose -f docker-compose.test.yml up -d
