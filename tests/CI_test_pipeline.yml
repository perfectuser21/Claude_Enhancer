# Perfect21 CI/CDæµ‹è¯•æµæ°´çº¿é…ç½®
# GitHub Actions / GitLab CI / Jenkinsé€šç”¨é…ç½®

name: Perfect21 Test Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # æ¯æ—¥å‡Œæ™¨2ç‚¹è¿è¡Œå®Œæ•´æµ‹è¯•
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.10'
  TESTING: 'true'
  LOG_LEVEL: 'INFO'

jobs:
  # ä»£ç è´¨é‡æ£€æŸ¥
  quality-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black isort mypy
          pip install -r tests/requirements.txt
      
      - name: Lint with flake8
        run: |
          flake8 api config features main --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 api config features main --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: Check code formatting with black
        run: black --check api config features main
      
      - name: Check import sorting with isort
        run: isort --check-only api config features main
      
      - name: Type check with mypy
        run: mypy api config features main --ignore-missing-imports
  
  # å•å…ƒæµ‹è¯•
  unit-tests:
    runs-on: ubuntu-latest
    needs: quality-check
    
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11']
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install -e .
      
      - name: Run unit tests
        run: |
          pytest tests/ -m "unit" \
            --cov=api --cov=config --cov=features --cov=main \
            --cov-report=xml --cov-report=term-missing \
            --junitxml=junit-unit-${{ matrix.python-version }}.xml
      
      - name: Upload unit test results
        uses: actions/upload-artifact@v3
        with:
          name: unit-test-results-${{ matrix.python-version }}
          path: |
            junit-unit-${{ matrix.python-version }}.xml
            coverage.xml
  
  # é›†æˆæµ‹è¯•
  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: --health-cmd "redis-cli ping" --health-interval 10s --health-timeout 5s --health-retries 5
      
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: perfect21_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test123
        ports:
          - 5432:5432
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install -e .
      
      - name: Wait for services
        run: |
          sleep 10
          redis-cli -h localhost ping
          pg_isready -h localhost -p 5432 -U test
      
      - name: Run integration tests
        env:
          DB_URL: postgresql://test:test123@localhost:5432/perfect21_test
          REDIS_URL: redis://localhost:6379/1
        run: |
          pytest tests/ -m "integration" \
            --cov=api --cov=config --cov=features --cov=main \
            --cov-report=xml --cov-report=term-missing \
            --junitxml=junit-integration.xml
      
      - name: Upload integration test results
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results
          path: |
            junit-integration.xml
            coverage.xml
  
  # å®‰å…¨æµ‹è¯•
  security-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install bandit safety
          pip install -e .
      
      - name: Run security tests
        run: |
          pytest tests/ -m "security" \
            --junitxml=junit-security.xml
      
      - name: Run bandit security scan
        run: bandit -r api config features main -f json -o bandit-report.json
      
      - name: Check dependencies for security issues
        run: safety check --json --output safety-report.json
      
      - name: Upload security test results
        uses: actions/upload-artifact@v3
        with:
          name: security-test-results
          path: |
            junit-security.xml
            bandit-report.json
            safety-report.json
  
  # E2Eæµ‹è¯•
  e2e-tests:
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install -e .
      
      - name: Start Perfect21 API server
        run: |
          python api/rest_server.py --host 0.0.0.0 --port 8000 &
          sleep 10
      
      - name: Run E2E tests
        run: |
          pytest tests/ -m "e2e" \
            --junitxml=junit-e2e.xml
      
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        with:
          name: e2e-test-results
          path: junit-e2e.xml
  
  # æ€§èƒ½æµ‹è¯•
  performance-tests:
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[perf]')
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt
          pip install -e .
      
      - name: Start Perfect21 API server
        run: |
          python api/rest_server.py --host 0.0.0.0 --port 8000 &
          sleep 10
      
      - name: Run performance tests
        run: |
          pytest tests/ -m "performance" \
            --benchmark-json=benchmark-results.json \
            --junitxml=junit-performance.xml
      
      - name: Run load tests
        run: |
          python tests/load_test_auth_api.py
      
      - name: Upload performance test results
        uses: actions/upload-artifact@v3
        with:
          name: performance-test-results
          path: |
            junit-performance.xml
            benchmark-results.json
            load_test_report_*.md
  
  # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
  test-report:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, security-tests, e2e-tests]
    if: always()
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Download all test results
        uses: actions/download-artifact@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install report dependencies
        run: |
          python -m pip install --upgrade pip
          pip install allure-pytest jinja2 coverage
      
      - name: Generate combined coverage report
        run: |
          coverage combine **/coverage.xml || true
          coverage report --format=markdown > coverage-report.md || true
          coverage html -d coverage-html || true
      
      - name: Generate test summary
        run: |
          python -c "
          import json
          import glob
          import xml.etree.ElementTree as ET
          from datetime import datetime
          
          # æ”¶é›†æ‰€æœ‰æµ‹è¯•ç»“æžœ
          summary = {
              'timestamp': datetime.now().isoformat(),
              'total_tests': 0,
              'passed': 0,
              'failed': 0,
              'skipped': 0,
              'test_suites': []
          }
          
          for junit_file in glob.glob('**/*junit*.xml', recursive=True):
              try:
                  tree = ET.parse(junit_file)
                  root = tree.getroot()
                  
                  suite_info = {
                      'name': root.get('name', junit_file),
                      'tests': int(root.get('tests', 0)),
                      'failures': int(root.get('failures', 0)),
                      'errors': int(root.get('errors', 0)),
                      'skipped': int(root.get('skipped', 0))
                  }
                  
                  summary['total_tests'] += suite_info['tests']
                  summary['failed'] += suite_info['failures'] + suite_info['errors']
                  summary['skipped'] += suite_info['skipped']
                  summary['passed'] += suite_info['tests'] - suite_info['failures'] - suite_info['errors'] - suite_info['skipped']
                  summary['test_suites'].append(suite_info)
                  
              except Exception as e:
                  print(f'Error parsing {junit_file}: {e}')
          
          with open('test-summary.json', 'w') as f:
              json.dump(summary, f, indent=2)
          
          # ç”ŸæˆMarkdownæŠ¥å‘Š
          with open('test-summary.md', 'w') as f:
              f.write(f'''# Perfect21 æµ‹è¯•ç»“æžœæŠ¥å‘Š\n\n')
              f.write(f'**æµ‹è¯•æ—¶é—´**: {summary[\"timestamp\"]}\n\n')
              f.write(f'## æµ‹è¯•ç»Ÿè®¡\n\n')
              f.write(f'- **æ€»æµ‹è¯•æ•°**: {summary[\"total_tests\"]}\n')
              f.write(f'- **é€šè¿‡**: {summary[\"passed\"]}\n')
              f.write(f'- **å¤±è´¥**: {summary[\"failed\"]}\n')
              f.write(f'- **è·³è¿‡**: {summary[\"skipped\"]}\n')
              f.write(f'- **æˆåŠŸçŽ‡**: {(summary[\"passed\"]/summary[\"total_tests\"]*100):.2f}%\n\n' if summary[\"total_tests\"] > 0 else '- **æˆåŠŸçŽ‡**: N/A\n\n')
              
              f.write('## æµ‹è¯•å¥—ä»¶è¯¦æƒ…\n\n')
              for suite in summary['test_suites']:
                  f.write(f'### {suite[\"name\"]}\n')
                  f.write(f'- æµ‹è¯•æ•°: {suite[\"tests\"]}\n')
                  f.write(f'- é€šè¿‡: {suite[\"tests\"] - suite[\"failures\"] - suite[\"errors\"] - suite[\"skipped\"]}\n')
                  f.write(f'- å¤±è´¥: {suite[\"failures\"]}\n')
                  f.write(f'- é”™è¯¯: {suite[\"errors\"]}\n')
                  f.write(f'- è·³è¿‡: {suite[\"skipped\"]}\n\n')
          "
      
      - name: Upload test report
        uses: actions/upload-artifact@v3
        with:
          name: test-report
          path: |
            test-summary.json
            test-summary.md
            coverage-report.md
            coverage-html/
      
      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            try {
              const summary = JSON.parse(fs.readFileSync('test-summary.json', 'utf8'));
              const coverage = fs.readFileSync('coverage-report.md', 'utf8').substring(0, 1000);
              
              const body = `## ðŸ§ª æµ‹è¯•ç»“æžœ
              
              ### ðŸ“Š ç»Ÿè®¡ä¿¡æ¯
              - **æ€»æµ‹è¯•æ•°**: ${summary.total_tests}
              - **é€šè¿‡**: ${summary.passed} âœ…
              - **å¤±è´¥**: ${summary.failed} âŒ
              - **è·³è¿‡**: ${summary.skipped} â­ï¸
              - **æˆåŠŸçŽ‡**: ${summary.total_tests > 0 ? (summary.passed/summary.total_tests*100).toFixed(2) : 'N/A'}%
              
              ### ðŸ“ˆ è¦†ç›–çŽ‡
              ${coverage}
              
              <details>
              <summary>ðŸ“„ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š</summary>
              
              ${summary.test_suites.map(suite => 
                `**${suite.name}**: ${suite.tests} æµ‹è¯•, ${suite.tests - suite.failures - suite.errors - suite.skipped} é€šè¿‡`
              ).join('\n')}
              
              </details>
              `;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            } catch (error) {
              console.error('Failed to post test results:', error);
            }

  # éƒ¨ç½²åˆ°æµ‹è¯•çŽ¯å¢ƒ
  deploy-test:
    runs-on: ubuntu-latest
    needs: [test-report]
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Deploy to test environment
        run: |
          echo "ðŸš€ Deploying to test environment..."
          # è¿™é‡Œæ·»åŠ å®žé™…çš„éƒ¨ç½²å‘½ä»¤
          # ä¾‹å¦‚: kubectl apply -f k8s/test/
          # æˆ–: docker-compose -f docker-compose.test.yml up -d
