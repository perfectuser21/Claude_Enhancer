#!/usr/bin/env python3
"""
Perfect21 æµ‹è¯•è¿è¡Œå™¨
ç»Ÿä¸€è¿è¡Œæ‰€æœ‰æµ‹è¯•å¹¶ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•æŠ¥å‘Š
"""

import os
import sys
import pytest
import json
import time
import subprocess
from datetime import datetime
from pathlib import Path
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

class Perfect21TestRunner:
    """Perfect21 æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self, project_root=None):
        self.project_root = Path(project_root or os.path.dirname(__file__)).parent
        self.test_dir = self.project_root / "tests"
        self.results = {}
        self.start_time = None
        self.end_time = None

    def run_unit_tests(self, verbose=False):
        """è¿è¡Œå•å…ƒæµ‹è¯•"""
        print("ğŸ§ª è¿è¡Œå•å…ƒæµ‹è¯•...")

        cmd = [
            sys.executable, "-m", "pytest",
            str(self.test_dir / "unit"),
            "--tb=short",
            "--junit-xml=junit-unit.xml",
            "--cov=features",
            "--cov-report=xml:coverage-unit.xml",
            "--cov-report=term-missing"
        ]

        if verbose:
            cmd.append("-v")

        result = subprocess.run(cmd, capture_output=True, text=True, cwd=str(self.project_root))

        self.results['unit_tests'] = {
            'returncode': result.returncode,
            'stdout': result.stdout,
            'stderr': result.stderr,
            'success': result.returncode == 0
        }

        print(f"âœ… å•å…ƒæµ‹è¯•å®Œæˆ (è¿”å›ç : {result.returncode})")
        return result.returncode == 0

    def run_integration_tests(self, verbose=False):
        """è¿è¡Œé›†æˆæµ‹è¯•"""
        print("ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•...")

        cmd = [
            sys.executable, "-m", "pytest",
            str(self.test_dir / "integration"),
            "--tb=short",
            "--junit-xml=junit-integration.xml"
        ]

        if verbose:
            cmd.append("-v")

        result = subprocess.run(cmd, capture_output=True, text=True, cwd=str(self.project_root))

        self.results['integration_tests'] = {
            'returncode': result.returncode,
            'stdout': result.stdout,
            'stderr': result.stderr,
            'success': result.returncode == 0
        }

        print(f"âœ… é›†æˆæµ‹è¯•å®Œæˆ (è¿”å›ç : {result.returncode})")
        return result.returncode == 0

    def run_performance_tests(self, verbose=False):
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        print("âš¡ è¿è¡Œæ€§èƒ½æµ‹è¯•...")

        cmd = [
            sys.executable, "-m", "pytest",
            str(self.test_dir / "performance"),
            "--tb=short",
            "--junit-xml=junit-performance.xml",
            "-m", "not slow"  # è·³è¿‡è€—æ—¶æµ‹è¯•
        ]

        if verbose:
            cmd.append("-v")

        result = subprocess.run(cmd, capture_output=True, text=True, cwd=str(self.project_root))

        self.results['performance_tests'] = {
            'returncode': result.returncode,
            'stdout': result.stdout,
            'stderr': result.stderr,
            'success': result.returncode == 0
        }

        print(f"âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ (è¿”å›ç : {result.returncode})")
        return result.returncode == 0

    def run_security_tests(self, verbose=False):
        """è¿è¡Œå®‰å…¨æµ‹è¯•"""
        print("ğŸ”’ è¿è¡Œå®‰å…¨æµ‹è¯•...")

        # è¿è¡Œè´¨é‡é—¨å®‰å…¨æ£€æŸ¥
        from features.preventive_quality.quality_gate import QualityGate

        quality_gate = QualityGate(str(self.project_root))
        security_results = quality_gate.run_checks(categories=['security'])

        security_passed = all(r.status.value != 'failed' for r in security_results)

        self.results['security_tests'] = {
            'returncode': 0 if security_passed else 1,
            'results': [
                {
                    'check_name': r.check_name,
                    'status': r.status.value,
                    'severity': r.severity.value,
                    'message': r.message,
                    'suggestions': r.suggestions
                }
                for r in security_results
            ],
            'success': security_passed
        }

        print(f"âœ… å®‰å…¨æµ‹è¯•å®Œæˆ ({'é€šè¿‡' if security_passed else 'å¤±è´¥'})")
        return security_passed

    def run_quality_checks(self):
        """è¿è¡Œè´¨é‡æ£€æŸ¥"""
        print("ğŸ¯ è¿è¡Œè´¨é‡æ£€æŸ¥...")

        from features.preventive_quality.quality_gate import QualityGate

        quality_gate = QualityGate(str(self.project_root))
        all_results = quality_gate.run_checks()
        summary = quality_gate.get_check_summary(all_results)

        # è®¡ç®—è´¨é‡åˆ†æ•°
        total_checks = summary['æ€»æ£€æŸ¥æ•°']
        passed_checks = summary['é€šè¿‡']
        quality_score = (passed_checks / total_checks * 100) if total_checks > 0 else 0

        self.results['quality_checks'] = {
            'summary': summary,
            'quality_score': quality_score,
            'detailed_results': [
                {
                    'check_name': r.check_name,
                    'status': r.status.value,
                    'severity': r.severity.value,
                    'message': r.message,
                    'execution_time': r.execution_time,
                    'suggestions': r.suggestions
                }
                for r in all_results
            ],
            'success': quality_score >= 80  # 80%ä»¥ä¸Šç®—é€šè¿‡
        }

        print(f"âœ… è´¨é‡æ£€æŸ¥å®Œæˆ (è´¨é‡åˆ†æ•°: {quality_score:.1f}%)")
        return quality_score >= 80

    def calculate_coverage(self):
        """è®¡ç®—æµ‹è¯•è¦†ç›–ç‡"""
        coverage_file = self.project_root / "coverage-unit.xml"
        if not coverage_file.exists():
            return {"error": "Coverage file not found"}

        try:
            import xml.etree.ElementTree as ET
            tree = ET.parse(coverage_file)
            root = tree.getroot()

            # è§£æè¦†ç›–ç‡æ•°æ®
            coverage_data = {}
            for package in root.findall(".//package"):
                package_name = package.get("name")
                line_rate = float(package.get("line-rate", 0)) * 100
                branch_rate = float(package.get("branch-rate", 0)) * 100

                coverage_data[package_name] = {
                    "line_coverage": line_rate,
                    "branch_coverage": branch_rate
                }

            # è®¡ç®—æ€»ä½“è¦†ç›–ç‡
            overall_line_rate = float(root.get("line-rate", 0)) * 100
            overall_branch_rate = float(root.get("branch-rate", 0)) * 100

            return {
                "overall_line_coverage": overall_line_rate,
                "overall_branch_coverage": overall_branch_rate,
                "package_coverage": coverage_data,
                "target_coverage": 90.0,
                "meets_target": overall_line_coverage >= 90.0
            }

        except Exception as e:
            return {"error": f"Failed to parse coverage: {str(e)}"}

    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        coverage_info = self.calculate_coverage()

        report = {
            "test_run_info": {
                "timestamp": datetime.now().isoformat(),
                "start_time": self.start_time.isoformat() if self.start_time else None,
                "end_time": self.end_time.isoformat() if self.end_time else None,
                "duration_seconds": (self.end_time - self.start_time).total_seconds() if (self.start_time and self.end_time) else None,
                "project_root": str(self.project_root)
            },
            "test_results": self.results,
            "coverage": coverage_info,
            "summary": self._generate_summary()
        }

        return report

    def _generate_summary(self):
        """ç”Ÿæˆæµ‹è¯•æ‘˜è¦"""
        total_success = 0
        total_tests = 0

        test_categories = ['unit_tests', 'integration_tests', 'performance_tests', 'security_tests', 'quality_checks']

        for category in test_categories:
            if category in self.results:
                total_tests += 1
                if self.results[category].get('success', False):
                    total_success += 1

        success_rate = (total_success / total_tests * 100) if total_tests > 0 else 0

        return {
            "total_test_categories": total_tests,
            "successful_categories": total_success,
            "success_rate": success_rate,
            "overall_status": "PASS" if success_rate >= 80 else "FAIL",
            "quality_gate_status": "PASS" if self.results.get('quality_checks', {}).get('success', False) else "FAIL"
        }

    def save_report(self, filename=None):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"perfect21_test_report_{timestamp}.json"

        report = self.generate_report()

        report_path = self.project_root / filename
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“Š æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return str(report_path)

    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        summary = self._generate_summary()

        print("\n" + "="*60)
        print("ğŸ¯ Perfect21 æµ‹è¯•æ‘˜è¦")
        print("="*60)

        print(f"ğŸ“Š æ€»ä½“çŠ¶æ€: {summary['overall_status']}")
        print(f"âœ… æµ‹è¯•ç±»åˆ«: {summary['successful_categories']}/{summary['total_test_categories']}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"ğŸ›¡ï¸  è´¨é‡é—¨: {summary['quality_gate_status']}")

        if 'quality_checks' in self.results:
            quality_score = self.results['quality_checks'].get('quality_score', 0)
            print(f"ğŸ¯ è´¨é‡åˆ†æ•°: {quality_score:.1f}%")

        # è¦†ç›–ç‡ä¿¡æ¯
        coverage_info = self.calculate_coverage()
        if 'overall_line_coverage' in coverage_info:
            line_coverage = coverage_info['overall_line_coverage']
            print(f"ğŸ“‹ ä»£ç è¦†ç›–ç‡: {line_coverage:.1f}%")

            if coverage_info.get('meets_target', False):
                print("âœ… è¾¾åˆ°è¦†ç›–ç‡ç›®æ ‡ (90%)")
            else:
                print("âŒ æœªè¾¾åˆ°è¦†ç›–ç‡ç›®æ ‡ (90%)")

        print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for category, result in self.results.items():
            status = "âœ… é€šè¿‡" if result.get('success', False) else "âŒ å¤±è´¥"
            print(f"  {category}: {status}")

        print("="*60)

    def run_all_tests(self, verbose=False, skip_slow=True):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ Perfect21 å®Œæ•´æµ‹è¯•å¥—ä»¶")
        print("="*60)

        self.start_time = datetime.now()

        try:
            # è¿è¡Œå„ç±»æµ‹è¯•
            unit_success = self.run_unit_tests(verbose)
            integration_success = self.run_integration_tests(verbose)

            if not skip_slow:
                performance_success = self.run_performance_tests(verbose)
            else:
                print("â© è·³è¿‡æ€§èƒ½æµ‹è¯• (ä½¿ç”¨ --include-slow æ¥è¿è¡Œ)")
                performance_success = True

            security_success = self.run_security_tests(verbose)
            quality_success = self.run_quality_checks()

            self.end_time = datetime.now()

            # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
            report_path = self.save_report()

            # æ‰“å°æ‘˜è¦
            self.print_summary()

            # æ€»ä½“æˆåŠŸåˆ¤æ–­
            overall_success = all([
                unit_success,
                integration_success,
                performance_success,
                security_success,
                quality_success
            ])

            if overall_success:
                print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Perfect21 ç³»ç»ŸçŠ¶æ€è‰¯å¥½ã€‚")
            else:
                print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¯¦ç»†æŠ¥å‘Šã€‚")

            return overall_success

        except Exception as e:
            self.end_time = datetime.now()
            print(f"\nâŒ æµ‹è¯•è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Perfect21 æµ‹è¯•è¿è¡Œå™¨")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")
    parser.add_argument("--include-slow", action="store_true", help="åŒ…å«è€—æ—¶æµ‹è¯•")
    parser.add_argument("--unit-only", action="store_true", help="åªè¿è¡Œå•å…ƒæµ‹è¯•")
    parser.add_argument("--integration-only", action="store_true", help="åªè¿è¡Œé›†æˆæµ‹è¯•")
    parser.add_argument("--performance-only", action="store_true", help="åªè¿è¡Œæ€§èƒ½æµ‹è¯•")
    parser.add_argument("--quality-only", action="store_true", help="åªè¿è¡Œè´¨é‡æ£€æŸ¥")
    parser.add_argument("--project-root", help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")

    args = parser.parse_args()

    runner = Perfect21TestRunner(args.project_root)

    try:
        if args.unit_only:
            success = runner.run_unit_tests(args.verbose)
        elif args.integration_only:
            success = runner.run_integration_tests(args.verbose)
        elif args.performance_only:
            success = runner.run_performance_tests(args.verbose)
        elif args.quality_only:
            success = runner.run_quality_checks()
        else:
            success = runner.run_all_tests(args.verbose, not args.include_slow)

        if not success:
            sys.exit(1)

    except KeyboardInterrupt:
        print("\nğŸ›‘ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()