#!/usr/bin/env python3
"""
Perfect21 å¹¶è¡Œæ‰§è¡Œæ§åˆ¶å™¨
å®é™…è°ƒç”¨Claude Codeçš„Taskå·¥å…·å®ç°çœŸæ­£å¹¶è¡Œ
"""

import logging
import json
import time
import asyncio
import traceback
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass

# Import error handling system
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from modules.exceptions import (
    AgentExecutionError, WorkflowError, TimeoutError, ErrorAggregator,
    ErrorSeverity, ErrorCategory, ErrorContext, retry_on_failure,
    RetryConfig, handle_exceptions, safe_execute
)

from .smart_decomposer import TaskAnalysis, AgentTask
from .parallel_manager import ParallelManager, ExecutionResult, ParallelExecutionSummary

logger = logging.getLogger("ParallelExecutor")

class ParallelExecutor:
    """å¹¶è¡Œæ‰§è¡Œæ§åˆ¶å™¨ - æ¡¥æ¥Perfect21ä¸Claude Codeï¼Œé›†æˆé”™è¯¯å¤„ç†"""

    def __init__(self):
        self.parallel_manager = ParallelManager()
        self.execution_log = []
        self.error_aggregator = ErrorAggregator()
        self.retry_config = RetryConfig(
            max_attempts=3,
            base_delay=2.0,
            max_delay=30.0,
            retry_on_exceptions=(AgentExecutionError, TimeoutError)
        )

    async def execute_parallel_task_async(self, task_description: str, analysis: TaskAnalysis) -> Dict[str, Any]:
        """
        å¼‚æ­¥æ‰§è¡Œå¹¶è¡Œä»»åŠ¡çš„ä¸»å…¥å£
        """
        logger.info(f"å¼€å§‹å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œ: {task_description}")

        # æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’
        self._display_execution_plan(analysis)

        # ç”ŸæˆTaskå·¥å…·è°ƒç”¨é…ç½®
        task_calls = self._generate_task_calls(analysis)

        # åˆ›å»ºæ‰§è¡Œè®°å½•
        execution_record = {
            "task_description": task_description,
            "timestamp": datetime.now().isoformat(),
            "analysis": {
                "project_type": analysis.project_type,
                "complexity": analysis.complexity.value,
                "execution_mode": analysis.execution_mode,
                "estimated_time": analysis.estimated_total_time,
                "agent_count": len(analysis.agent_tasks)
            },
            "task_calls": task_calls,
            "status": "prepared"
        }

        self.execution_log.append(execution_record)

        # è¿”å›ç»™è°ƒç”¨è€…çš„æ‰§è¡Œä¿¡æ¯
        return {
            "ready_for_execution": True,
            "execution_mode": analysis.execution_mode,
            "task_calls": task_calls,
            "expected_agents": len(analysis.agent_tasks),
            "execution_instructions": self._create_execution_instructions(analysis),
            "monitoring_config": self._create_monitoring_config(analysis)
        }

    @handle_exceptions(
        exceptions=(Exception,),
        category=ErrorCategory.AGENT_EXECUTION,
        severity=ErrorSeverity.HIGH,
        recovery_suggestions=[
            "Check task analysis validity",
            "Verify agent availability",
            "Review task parameters"
        ]
    )
    def execute_parallel_task(self, task_description: str, analysis: TaskAnalysis) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¹¶è¡Œä»»åŠ¡çš„ä¸»å…¥å£

        è¿™ä¸ªæ–¹æ³•ä¼šï¼š
        1. æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’
        2. ç”Ÿæˆå¹¶è¡ŒTaskè°ƒç”¨æŒ‡ä»¤
        3. è¿”å›è°ƒç”¨ä¿¡æ¯ä¾›ä¸»Claude Codeä½¿ç”¨

        Args:
            task_description: åŸå§‹ä»»åŠ¡æè¿°
            analysis: ä»»åŠ¡åˆ†æç»“æœ

        Returns:
            åŒ…å«æ‰§è¡ŒæŒ‡ä»¤å’Œé…ç½®çš„å­—å…¸
        """
        logger.info(f"å¼€å§‹å‡†å¤‡å¹¶è¡Œæ‰§è¡Œ: {task_description}")

        # æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’
        self._display_execution_plan(analysis)

        # ç”ŸæˆTaskå·¥å…·è°ƒç”¨é…ç½®
        task_calls = self._generate_task_calls(analysis)

        # åˆ›å»ºæ‰§è¡Œè®°å½•
        execution_record = {
            "task_description": task_description,
            "timestamp": datetime.now().isoformat(),
            "analysis": {
                "project_type": analysis.project_type,
                "complexity": analysis.complexity.value,
                "execution_mode": analysis.execution_mode,
                "estimated_time": analysis.estimated_total_time,
                "agent_count": len(analysis.agent_tasks)
            },
            "task_calls": task_calls,
            "status": "prepared"
        }

        self.execution_log.append(execution_record)

        # è¿”å›ç»™è°ƒç”¨è€…çš„æ‰§è¡Œä¿¡æ¯
        return {
            "ready_for_execution": True,
            "execution_mode": analysis.execution_mode,
            "task_calls": task_calls,
            "expected_agents": len(analysis.agent_tasks),
            "execution_instructions": self._create_execution_instructions(analysis),
            "monitoring_config": self._create_monitoring_config(analysis)
        }

    def _display_execution_plan(self, analysis: TaskAnalysis):
        """æ˜¾ç¤ºè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’"""
        print(f"\nğŸš€ Perfect21 å¹¶è¡Œæ‰§è¡Œè®¡åˆ’")
        print(f"=" * 60)
        print(f"ğŸ“‹ åŸå§‹ä»»åŠ¡: {analysis.original_task}")
        print(f"ğŸ¯ é¡¹ç›®ç±»å‹: {analysis.project_type}")
        print(f"ğŸ“Š å¤æ‚åº¦ç­‰çº§: {analysis.complexity.value}")
        print(f"âš¡ æ‰§è¡Œæ¨¡å¼: {analysis.execution_mode}")
        print(f"â±ï¸ é¢„ä¼°æ€»æ—¶é—´: {analysis.estimated_total_time}åˆ†é’Ÿ")
        print(f"ğŸ¤– æ¶‰åŠagents: {len(analysis.agent_tasks)}ä¸ª")
        print(f"=" * 60)

        print(f"\nğŸ‘¥ Agentæ‰§è¡Œæ¸…å•:")
        for i, task in enumerate(analysis.agent_tasks, 1):
            priority_emoji = "ğŸ”¥" if task.priority <= 2 else "ğŸ“‹"
            print(f"  {priority_emoji} {i}. @{task.agent_name}")
            print(f"      ä»»åŠ¡: {task.task_description}")
            print(f"      é¢„ä¼°: {task.estimated_time}åˆ†é’Ÿ")
            print(f"      ä¼˜å…ˆçº§: P{task.priority}")
            if task.dependencies:
                deps = ", ".join([f"@{dep}" for dep in task.dependencies])
                print(f"      ä¾èµ–: {deps}")
            print()

        print(f"âš¡ **å…³é”®æç¤º**: æ¥ä¸‹æ¥å°†åœ¨å•ä¸ªæ¶ˆæ¯ä¸­å¹¶è¡Œè°ƒç”¨æ‰€æœ‰Taskå·¥å…·!")
        print(f"ğŸ¯ è¿™å°†å®ç°çœŸæ­£çš„å¤šagentå¹¶è¡Œåä½œï¼Œç»•è¿‡orchestratoré™åˆ¶")
        print(f"=" * 60)

    def _generate_task_calls(self, analysis: TaskAnalysis) -> List[Dict[str, Any]]:
        """ç”ŸæˆTaskå·¥å…·è°ƒç”¨é…ç½®"""
        task_calls = []

        for task in analysis.agent_tasks:
            task_call = {
                "tool_name": "Task",
                "parameters": {
                    "subagent_type": task.agent_name,
                    "description": task.task_description,
                    "prompt": task.detailed_prompt
                },
                "expected_duration": task.estimated_time,
                "priority": task.priority,
                "dependencies": task.dependencies if task.dependencies else []
            }
            task_calls.append(task_call)

        return task_calls

    def _create_execution_instructions(self, analysis: TaskAnalysis) -> str:
        """åˆ›å»ºæ‰§è¡ŒæŒ‡ä»¤"""
        instructions = f"""
ğŸš€ Perfect21 å¹¶è¡Œæ‰§è¡ŒæŒ‡ä»¤

âš¡ **å…³é”®æ“ä½œ**: è¯·åœ¨**å•ä¸ªæ¶ˆæ¯**ä¸­è°ƒç”¨ä»¥ä¸‹æ‰€æœ‰Taskå·¥å…·ä»¥å®ç°çœŸæ­£å¹¶è¡Œæ‰§è¡Œ

ğŸ“‹ åŸå§‹ä»»åŠ¡: {analysis.original_task}
ğŸ¯ æ‰§è¡Œæ¨¡å¼: {analysis.execution_mode}
ğŸ¤– Agentæ€»æ•°: {len(analysis.agent_tasks)}

### ğŸ“ Taskå·¥å…·è°ƒç”¨æ¸…å•:

"""

        for i, task in enumerate(analysis.agent_tasks, 1):
            instructions += f"""
**Agent {i}: @{task.agent_name}**
```
Task(
    subagent_type="{task.agent_name}",
    description="{task.task_description}",
    prompt=\"\"\"{task.detailed_prompt}\"\"\"
)
```
"""

        instructions += f"""

### ğŸ¯ æ‰§è¡Œè¦ç‚¹:
1. **å¹¶è¡Œè°ƒç”¨**: å¿…é¡»åœ¨åŒä¸€æ¶ˆæ¯ä¸­è°ƒç”¨æ‰€æœ‰{len(analysis.agent_tasks)}ä¸ªTaskå·¥å…·
2. **æ— éœ€ç­‰å¾…**: ä¸è¦ç­‰å¾…å•ä¸ªagentå®Œæˆå†è°ƒç”¨ä¸‹ä¸€ä¸ª
3. **ç›‘æ§è¿›åº¦**: è§‚å¯Ÿæ‰€æœ‰agentsçš„æ‰§è¡ŒçŠ¶æ€å’Œè¾“å‡º
4. **æ•´åˆç»“æœ**: æ”¶é›†æ‰€æœ‰agentsçš„è¾“å‡ºå¹¶æ•´åˆæˆæœ€ç»ˆè§£å†³æ–¹æ¡ˆ

### ğŸ“Š é¢„æœŸç»“æœ:
- æ‰€æœ‰agentså°†å¹¶è¡Œå¯åŠ¨å’Œæ‰§è¡Œ
- æ€»æ‰§è¡Œæ—¶é—´: ~{analysis.estimated_total_time}åˆ†é’Ÿ
- æœ€ç»ˆè¾“å‡º: å®Œæ•´çš„{analysis.project_type}é¡¹ç›®è§£å†³æ–¹æ¡ˆ

ğŸ‰ **å¼€å§‹æ‰§è¡Œ!**
"""

        return instructions

    def _create_monitoring_config(self, analysis: TaskAnalysis) -> Dict[str, Any]:
        """åˆ›å»ºç›‘æ§é…ç½®"""
        return {
            "total_agents": len(analysis.agent_tasks),
            "expected_completion_time": analysis.estimated_total_time,
            "agent_names": [task.agent_name for task in analysis.agent_tasks],
            "critical_agents": [
                task.agent_name for task in analysis.agent_tasks
                if task.priority <= 2
            ],
            "monitoring_intervals": 30,  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
            "timeout_threshold": analysis.estimated_total_time * 60 * 2  # 2å€é¢„ä¼°æ—¶é—´
        }

    async def process_execution_results_async(self, agent_results: List[Dict[str, Any]]) -> ParallelExecutionSummary:
        """
        å¼‚æ­¥å¤„ç†æ‰§è¡Œç»“æœ
        """
        logger.info(f"å¼‚æ­¥å¤„ç†{len(agent_results)}ä¸ªagentçš„æ‰§è¡Œç»“æœ")

        # è½¬æ¢ä¸ºExecutionResultæ ¼å¼
        execution_results = []
        successful_count = 0

        for result in agent_results:
            agent_name = result.get("agent_name", "unknown")
            success = result.get("success", False)

            if success:
                successful_count += 1

            exec_result = ExecutionResult(
                agent_name=agent_name,
                task_description=result.get("task_description", ""),
                success=success,
                result=result.get("output"),
                error_message=result.get("error"),
                execution_time=result.get("execution_time", 0.0),
                start_time=datetime.fromisoformat(result.get("start_time", datetime.now().isoformat())),
                end_time=datetime.fromisoformat(result.get("end_time", datetime.now().isoformat()))
            )
            execution_results.append(exec_result)

        # åˆ›å»ºæ‰§è¡Œæ‘˜è¦
        summary = ParallelExecutionSummary(
            task_description=self.execution_log[-1]["task_description"] if self.execution_log else "Unknown",
            total_agents=len(agent_results),
            successful_agents=successful_count,
            failed_agents=len(agent_results) - successful_count,
            total_execution_time=sum(r.execution_time for r in execution_results),
            results=execution_results
        )

        # å¼‚æ­¥æ•´åˆç»“æœ
        summary.integrated_output = await self._integrate_agent_outputs_async(execution_results)

        # æ›´æ–°æ‰§è¡Œæ—¥å¿—
        if self.execution_log:
            self.execution_log[-1]["status"] = "completed"
            self.execution_log[-1]["results"] = summary

        return summary

    def process_execution_results(self, agent_results: List[Dict[str, Any]]) -> ParallelExecutionSummary:
        """
        å¤„ç†æ‰§è¡Œç»“æœ

        è¿™ä¸ªæ–¹æ³•åœ¨æ‰€æœ‰Taskå·¥å…·æ‰§è¡Œå®Œæˆåè¢«è°ƒç”¨
        ç”¨äºåˆ†æå’Œæ•´åˆæ‰€æœ‰agentsçš„è¾“å‡º
        """
        logger.info(f"å¤„ç†{len(agent_results)}ä¸ªagentçš„æ‰§è¡Œç»“æœ")

        # è½¬æ¢ä¸ºExecutionResultæ ¼å¼
        execution_results = []
        successful_count = 0

        for result in agent_results:
            agent_name = result.get("agent_name", "unknown")
            success = result.get("success", False)

            if success:
                successful_count += 1

            exec_result = ExecutionResult(
                agent_name=agent_name,
                task_description=result.get("task_description", ""),
                success=success,
                result=result.get("output"),
                error_message=result.get("error"),
                execution_time=result.get("execution_time", 0.0),
                start_time=datetime.fromisoformat(result.get("start_time", datetime.now().isoformat())),
                end_time=datetime.fromisoformat(result.get("end_time", datetime.now().isoformat()))
            )
            execution_results.append(exec_result)

        # åˆ›å»ºæ‰§è¡Œæ‘˜è¦
        summary = ParallelExecutionSummary(
            task_description=self.execution_log[-1]["task_description"] if self.execution_log else "Unknown",
            total_agents=len(agent_results),
            successful_agents=successful_count,
            failed_agents=len(agent_results) - successful_count,
            total_execution_time=sum(r.execution_time for r in execution_results),
            results=execution_results
        )

        # æ•´åˆç»“æœ
        summary.integrated_output = self._integrate_agent_outputs(execution_results)

        # æ›´æ–°æ‰§è¡Œæ—¥å¿—
        if self.execution_log:
            self.execution_log[-1]["status"] = "completed"
            self.execution_log[-1]["results"] = summary

        return summary

    async def _integrate_agent_outputs_async(self, results: List[ExecutionResult]) -> Dict[str, Any]:
        """å¼‚æ­¥æ•´åˆæ‰€æœ‰agentçš„è¾“å‡º"""
        integration = {
            "execution_summary": {
                "total_agents": len(results),
                "successful_agents": sum(1 for r in results if r.success),
                "total_execution_time": sum(r.execution_time for r in results),
                "timestamp": datetime.now().isoformat()
            },
            "agent_contributions": {},
            "project_assets": [],
            "quality_metrics": {},
            "deployment_readiness": {},
            "next_actions": []
        }

        # åˆ†ææ¯ä¸ªagentçš„è´¡çŒ®
        for result in results:
            if result.success and result.result:
                integration["agent_contributions"][result.agent_name] = {
                    "task_completed": result.task_description,
                    "execution_time": result.execution_time,
                    "output_summary": self._summarize_agent_output(result),
                    "assets_created": self._extract_assets(result),
                    "quality_score": self._calculate_quality_score(result)
                }

        # å¹¶è¡Œç”Ÿæˆå…¶ä»–æ•°æ®
        tasks = [
            self._compile_project_assets_async(results),
            self._calculate_overall_quality_async(results),
            self._assess_deployment_readiness_async(results),
            self._generate_next_actions_async(results)
        ]

        assets, quality, deployment, actions = await asyncio.gather(*tasks)

        integration["project_assets"] = assets
        integration["quality_metrics"] = quality
        integration["deployment_readiness"] = deployment
        integration["next_actions"] = actions

        return integration

    def _integrate_agent_outputs(self, results: List[ExecutionResult]) -> Dict[str, Any]:
        """æ•´åˆæ‰€æœ‰agentçš„è¾“å‡º"""
        integration = {
            "execution_summary": {
                "total_agents": len(results),
                "successful_agents": sum(1 for r in results if r.success),
                "total_execution_time": sum(r.execution_time for r in results),
                "timestamp": datetime.now().isoformat()
            },
            "agent_contributions": {},
            "project_assets": [],
            "quality_metrics": {},
            "deployment_readiness": {},
            "next_actions": []
        }

        # åˆ†ææ¯ä¸ªagentçš„è´¡çŒ®
        for result in results:
            if result.success and result.result:
                integration["agent_contributions"][result.agent_name] = {
                    "task_completed": result.task_description,
                    "execution_time": result.execution_time,
                    "output_summary": self._summarize_agent_output(result),
                    "assets_created": self._extract_assets(result),
                    "quality_score": self._calculate_quality_score(result)
                }

        # ç”Ÿæˆé¡¹ç›®èµ„äº§æ¸…å•
        integration["project_assets"] = self._compile_project_assets(results)

        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        integration["quality_metrics"] = self._calculate_overall_quality(results)

        # è¯„ä¼°éƒ¨ç½²å°±ç»ªçŠ¶æ€
        integration["deployment_readiness"] = self._assess_deployment_readiness(results)

        # ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®
        integration["next_actions"] = self._generate_next_actions(results)

        return integration

    def _summarize_agent_output(self, result: ExecutionResult) -> str:
        """æ€»ç»“agentè¾“å‡º"""
        if not result.result:
            return "æ— è¾“å‡ºå†…å®¹"

        # ç®€å•çš„è¾“å‡ºæ‘˜è¦é€»è¾‘
        output_str = str(result.result)
        if len(output_str) > 200:
            return output_str[:200] + "..."
        return output_str

    def _extract_assets(self, result: ExecutionResult) -> List[str]:
        """æå–agentåˆ›å»ºçš„èµ„äº§"""
        assets = []

        # åŸºäºagentç±»å‹æ¨æ–­èµ„äº§ç±»å‹
        if "backend" in result.agent_name:
            assets.extend(["APIæœåŠ¡ä»£ç ", "æ•°æ®åº“æ¶æ„", "æ¥å£æ–‡æ¡£"])
        elif "frontend" in result.agent_name:
            assets.extend(["ç”¨æˆ·ç•Œé¢", "ç»„ä»¶åº“", "æ ·å¼æ–‡ä»¶"])
        elif "test" in result.agent_name:
            assets.extend(["æµ‹è¯•å¥—ä»¶", "æµ‹è¯•æŠ¥å‘Š", "è´¨é‡è¯„ä¼°"])
        elif "devops" in result.agent_name:
            assets.extend(["éƒ¨ç½²é…ç½®", "CI/CDç®¡é“", "å®¹å™¨åŒ–é…ç½®"])
        elif "security" in result.agent_name:
            assets.extend(["å®‰å…¨è¯„ä¼°", "æ¼æ´æŠ¥å‘Š", "åˆè§„æ£€æŸ¥"])

        return assets

    def _calculate_quality_score(self, result: ExecutionResult) -> float:
        """è®¡ç®—agentè¾“å‡ºçš„è´¨é‡åˆ†æ•°"""
        if not result.success:
            return 0.0

        # åŸºäºæ‰§è¡Œæ—¶é—´å’ŒæˆåŠŸçŠ¶æ€çš„ç®€å•è¯„åˆ†
        base_score = 0.8
        time_bonus = min(0.2, result.execution_time / 300.0)  # æœ€å¤š0.2åˆ†æ—¶é—´å¥–åŠ±

        return min(1.0, base_score + time_bonus)

    async def _compile_project_assets_async(self, results: List[ExecutionResult]) -> List[str]:
        """å¼‚æ­¥ç¼–è¯‘é¡¹ç›®èµ„äº§æ¸…å•"""
        all_assets = []
        for result in results:
            if result.success:
                # åœ¨è¿™é‡Œå¯ä»¥æ·»åŠ å¼‚æ­¥å¤„ç†é€»è¾‘
                await asyncio.sleep(0)  # è®©å‡ºæ‰§è¡Œæƒ
                all_assets.extend(self._extract_assets(result))

        return list(set(all_assets))  # å»é‡

    def _compile_project_assets(self, results: List[ExecutionResult]) -> List[str]:
        """ç¼–è¯‘é¡¹ç›®èµ„äº§æ¸…å•"""
        all_assets = []
        for result in results:
            if result.success:
                all_assets.extend(self._extract_assets(result))

        return list(set(all_assets))  # å»é‡

    async def _calculate_overall_quality_async(self, results: List[ExecutionResult]) -> Dict[str, Any]:
        """å¼‚æ­¥è®¡ç®—æ•´ä½“è´¨é‡æŒ‡æ ‡"""
        successful_results = [r for r in results if r.success]

        if not successful_results:
            return {"overall_score": 0.0, "quality_level": "Poor"}

        # å¼‚æ­¥è®¡ç®—è´¨é‡åˆ†æ•°
        quality_scores = []
        for result in successful_results:
            await asyncio.sleep(0)  # è®©å‡ºæ‰§è¡Œæƒ
            quality_scores.append(self._calculate_quality_score(result))

        avg_quality = sum(quality_scores) / len(quality_scores)
        success_rate = len(successful_results) / len(results)

        overall_score = (avg_quality * 0.7) + (success_rate * 0.3)

        if overall_score >= 0.9:
            quality_level = "Excellent"
        elif overall_score >= 0.7:
            quality_level = "Good"
        elif overall_score >= 0.5:
            quality_level = "Fair"
        else:
            quality_level = "Poor"

        return {
            "overall_score": overall_score,
            "quality_level": quality_level,
            "success_rate": success_rate,
            "agent_count": len(results),
            "successful_agents": len(successful_results)
        }

    def _calculate_overall_quality(self, results: List[ExecutionResult]) -> Dict[str, Any]:
        """è®¡ç®—æ•´ä½“è´¨é‡æŒ‡æ ‡"""
        successful_results = [r for r in results if r.success]

        if not successful_results:
            return {"overall_score": 0.0, "quality_level": "Poor"}

        avg_quality = sum(self._calculate_quality_score(r) for r in successful_results) / len(successful_results)
        success_rate = len(successful_results) / len(results)

        overall_score = (avg_quality * 0.7) + (success_rate * 0.3)

        if overall_score >= 0.9:
            quality_level = "Excellent"
        elif overall_score >= 0.7:
            quality_level = "Good"
        elif overall_score >= 0.5:
            quality_level = "Fair"
        else:
            quality_level = "Poor"

        return {
            "overall_score": overall_score,
            "quality_level": quality_level,
            "success_rate": success_rate,
            "agent_count": len(results),
            "successful_agents": len(successful_results)
        }

    async def _assess_deployment_readiness_async(self, results: List[ExecutionResult]) -> Dict[str, Any]:
        """å¼‚æ­¥è¯„ä¼°éƒ¨ç½²å°±ç»ªçŠ¶æ€"""
        required_components = ["backend", "frontend", "test", "security"]
        available_components = []

        for result in results:
            if result.success:
                await asyncio.sleep(0)  # è®©å‡ºæ‰§è¡Œæƒ
                for component in required_components:
                    if component in result.agent_name:
                        available_components.append(component)

        readiness_score = len(set(available_components)) / len(required_components)

        return {
            "readiness_score": readiness_score,
            "available_components": list(set(available_components)),
            "missing_components": list(set(required_components) - set(available_components)),
            "deployment_ready": readiness_score >= 0.75
        }

    def _assess_deployment_readiness(self, results: List[ExecutionResult]) -> Dict[str, Any]:
        """è¯„ä¼°éƒ¨ç½²å°±ç»ªçŠ¶æ€"""
        required_components = ["backend", "frontend", "test", "security"]
        available_components = []

        for result in results:
            if result.success:
                for component in required_components:
                    if component in result.agent_name:
                        available_components.append(component)

        readiness_score = len(set(available_components)) / len(required_components)

        return {
            "readiness_score": readiness_score,
            "available_components": list(set(available_components)),
            "missing_components": list(set(required_components) - set(available_components)),
            "deployment_ready": readiness_score >= 0.75
        }

    async def _generate_next_actions_async(self, results: List[ExecutionResult]) -> List[str]:
        """å¼‚æ­¥ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®"""
        actions = []

        successful_agents = [r.agent_name for r in results if r.success]
        failed_agents = [r.agent_name for r in results if not r.success]

        if failed_agents:
            actions.append(f"ğŸ”§ ä¿®å¤å¤±è´¥çš„agents: {', '.join(failed_agents)}")

        # å¼‚æ­¥æ£€æŸ¥å’Œç”Ÿæˆå»ºè®®
        await asyncio.sleep(0)  # è®©å‡ºæ‰§è¡Œæƒ

        if "test-engineer" in successful_agents:
            actions.append("ğŸ§ª æ‰§è¡Œé›†æˆæµ‹è¯•å’Œç³»ç»ŸéªŒè¯")
        else:
            actions.append("ğŸ§ª æ·»åŠ æµ‹è¯•å·¥ç¨‹å¸ˆè¿›è¡Œè´¨é‡ä¿è¯")

        if "security-auditor" in successful_agents:
            actions.append("ğŸ”’ è¿›è¡Œå®‰å…¨å®¡è®¡å’Œæ¼æ´æ‰«æ")
        else:
            actions.append("ğŸ”’ æ·»åŠ å®‰å…¨ä¸“å®¶è¿›è¡Œå®‰å…¨è¯„ä¼°")

        if "devops-engineer" in successful_agents:
            actions.append("ğŸš€ å‡†å¤‡ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²")
        else:
            actions.append("ğŸš€ é…ç½®DevOpsæµç¨‹å’Œéƒ¨ç½²ç®¡é“")

        actions.append("ğŸ“Š ç”Ÿæˆé¡¹ç›®æ–‡æ¡£å’Œç”¨æˆ·æ‰‹å†Œ")
        actions.append("ğŸ¯ è¿›è¡Œç”¨æˆ·éªŒæ”¶æµ‹è¯•")

        return actions

    def _generate_next_actions(self, results: List[ExecutionResult]) -> List[str]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®"""
        actions = []

        successful_agents = [r.agent_name for r in results if r.success]
        failed_agents = [r.agent_name for r in results if not r.success]

        if failed_agents:
            actions.append(f"ğŸ”§ ä¿®å¤å¤±è´¥çš„agents: {', '.join(failed_agents)}")

        if "test-engineer" in successful_agents:
            actions.append("ğŸ§ª æ‰§è¡Œé›†æˆæµ‹è¯•å’Œç³»ç»ŸéªŒè¯")
        else:
            actions.append("ğŸ§ª æ·»åŠ æµ‹è¯•å·¥ç¨‹å¸ˆè¿›è¡Œè´¨é‡ä¿è¯")

        if "security-auditor" in successful_agents:
            actions.append("ğŸ”’ è¿›è¡Œå®‰å…¨å®¡è®¡å’Œæ¼æ´æ‰«æ")
        else:
            actions.append("ğŸ”’ æ·»åŠ å®‰å…¨ä¸“å®¶è¿›è¡Œå®‰å…¨è¯„ä¼°")

        if "devops-engineer" in successful_agents:
            actions.append("ğŸš€ å‡†å¤‡ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²")
        else:
            actions.append("ğŸš€ é…ç½®DevOpsæµç¨‹å’Œéƒ¨ç½²ç®¡é“")

        actions.append("ğŸ“Š ç”Ÿæˆé¡¹ç›®æ–‡æ¡£å’Œç”¨æˆ·æ‰‹å†Œ")
        actions.append("ğŸ¯ è¿›è¡Œç”¨æˆ·éªŒæ”¶æµ‹è¯•")

        return actions

    def get_execution_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ‰§è¡ŒçŠ¶æ€"""
        if not self.execution_log:
            return {"status": "idle", "message": "æ²¡æœ‰æ´»è·ƒçš„æ‰§è¡Œä»»åŠ¡"}

        latest = self.execution_log[-1]
        return {
            "status": latest["status"],
            "task_description": latest["task_description"],
            "timestamp": latest["timestamp"],
            "agent_count": latest["analysis"]["agent_count"],
            "execution_mode": latest["analysis"]["execution_mode"]
        }

    def save_execution_report(self, summary: ParallelExecutionSummary,
                            filename: Optional[str] = None) -> str:
        """ä¿å­˜æ‰§è¡ŒæŠ¥å‘Š"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"perfect21_execution_report_{timestamp}.json"

        report_data = {
            "execution_summary": {
                "task_description": summary.task_description,
                "total_agents": summary.total_agents,
                "successful_agents": summary.successful_agents,
                "failed_agents": summary.failed_agents,
                "execution_time": summary.total_execution_time,
                "timestamp": datetime.now().isoformat()
            },
            "agent_results": [
                {
                    "agent_name": result.agent_name,
                    "task_description": result.task_description,
                    "success": result.success,
                    "execution_time": result.execution_time,
                    "error_message": result.error_message
                }
                for result in summary.results
            ],
            "integrated_output": summary.integrated_output
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        logger.info(f"æ‰§è¡ŒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename

# å…¨å±€æ‰§è¡Œå™¨å®ä¾‹
_parallel_executor = None

def get_parallel_executor() -> ParallelExecutor:
    """è·å–å¹¶è¡Œæ‰§è¡Œæ§åˆ¶å™¨å®ä¾‹"""
    global _parallel_executor
    if _parallel_executor is None:
        _parallel_executor = ParallelExecutor()
    return _parallel_executor

# ä¸ºæµ‹è¯•æ·»åŠ ç®€åŒ–çš„æ¨¡æ‹Ÿæ‰§è¡Œæ–¹æ³•
async def execute_parallel_tasks(tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
    """ç®€åŒ–çš„å¹¶è¡Œä»»åŠ¡æ‰§è¡Œæ–¹æ³•ï¼ˆä¸ºæµ‹è¯•ä½¿ç”¨ï¼‰"""
    import asyncio
    import random

    start_time = time.time()

    async def mock_task_execution(task):
        task_id = task.get('id', 'unknown')
        execution_time = task.get('execution_time', 1.0)

        # æ¨¡æ‹Ÿå¼‚æ­¥æ‰§è¡Œ
        await asyncio.sleep(execution_time)

        # æ¨¡æ‹ŸæˆåŠŸç‡ï¼ˆ90%ï¼‰
        success = random.random() > 0.1

        return {
            'task_id': task_id,
            'success': success,
            'result': f'Mock result for {task_id}' if success else None,
            'error': f'Mock error for {task_id}' if not success else None,
            'execution_time': execution_time
        }

    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*[mock_task_execution(task) for task in tasks], return_exceptions=True)

    execution_time = time.time() - start_time
    successful_tasks = sum(1 for r in results if isinstance(r, dict) and r.get('success', False))

    return {
        'success': successful_tasks == len(tasks),
        'total_tasks': len(tasks),
        'completed_tasks': successful_tasks,
        'failed_tasks': len(tasks) - successful_tasks,
        'execution_time': execution_time,
        'task_results': results
    }