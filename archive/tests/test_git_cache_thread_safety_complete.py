#!/usr/bin/env python3
"""
Gitç¼“å­˜çº¿ç¨‹å®‰å…¨å®Œæ•´æµ‹è¯•
æµ‹è¯•ä¿®å¤åçš„modules/git_cache.pyçš„çº¿ç¨‹å®‰å…¨ç‰¹æ€§
"""

import asyncio
import threading
import time
import random
import concurrent.futures
from pathlib import Path
from typing import List, Dict, Any
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("ThreadSafetyTest")

# å¯¼å…¥ä¿®å¤åçš„Gitç¼“å­˜
from modules.git_cache import (
    get_git_cache,
    reset_git_cache,
    get_cache_stats,
    GitCacheManager,
    get_cache_health_report,
    force_refresh_cache,
    is_cache_healthy
)


class ComprehensiveThreadSafetyTest:
    """Gitç¼“å­˜çº¿ç¨‹å®‰å…¨ç»¼åˆæµ‹è¯•"""

    def __init__(self, project_root: str = None):
        self.project_root = project_root or str(Path.cwd())
        self.test_results = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'test_details': [],
            'performance_metrics': {},
            'thread_safety_violations': [],
            'data_consistency_issues': []
        }
        self.result_lock = threading.Lock()

    def record_test_result(self, test_name: str, passed: bool, details: str = ""):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        with self.result_lock:
            self.test_results['total_tests'] += 1
            if passed:
                self.test_results['passed_tests'] += 1
                status = "âœ… PASS"
            else:
                self.test_results['failed_tests'] += 1
                status = "âŒ FAIL"

            self.test_results['test_details'].append({
                'test': test_name,
                'status': status,
                'details': details,
                'timestamp': time.time()
            })
            print(f"{status}: {test_name} - {details}")

    def test_concurrent_cache_access(self, num_threads: int = 20, requests_per_thread: int = 10):
        """æµ‹è¯•å¹¶å‘ç¼“å­˜è®¿é—®"""
        print(f"\nğŸ§ª æµ‹è¯•å¹¶å‘ç¼“å­˜è®¿é—®: {num_threads} çº¿ç¨‹, æ¯çº¿ç¨‹ {requests_per_thread} è¯·æ±‚")

        cache = get_git_cache(self.project_root, cache_timeout=5)
        results = []
        errors = []

        def worker(thread_id: int):
            """å·¥ä½œçº¿ç¨‹"""
            thread_results = []
            for i in range(requests_per_thread):
                try:
                    start_time = time.time()

                    # éšæœºé€‰æ‹©æ“ä½œ
                    operation = random.choice(['status', 'diff', 'git_cmd'])

                    if operation == 'status':
                        result = cache.batch_git_status()
                        thread_results.append({
                            'thread_id': thread_id,
                            'operation': 'batch_git_status',
                            'success': True,
                            'response_time': time.time() - start_time,
                            'result_type': type(result).__name__
                        })
                    elif operation == 'diff':
                        result = cache.batch_get_file_diff(['README.md', 'main/cli.py'])
                        thread_results.append({
                            'thread_id': thread_id,
                            'operation': 'batch_get_file_diff',
                            'success': True,
                            'response_time': time.time() - start_time,
                            'result_type': type(result).__name__
                        })
                    else:
                        result = cache.get_cached_git_result(['git', 'rev-parse', 'HEAD'])
                        thread_results.append({
                            'thread_id': thread_id,
                            'operation': 'get_cached_git_result',
                            'success': result is not None,
                            'response_time': time.time() - start_time,
                            'result_type': type(result).__name__
                        })

                    # éšæœºå»¶è¿Ÿ
                    time.sleep(random.uniform(0.01, 0.1))

                except Exception as e:
                    errors.append(f"Thread {thread_id}: {str(e)}")
                    thread_results.append({
                        'thread_id': thread_id,
                        'operation': 'error',
                        'success': False,
                        'error': str(e)
                    })

            results.extend(thread_results)

        # å¯åŠ¨æ‰€æœ‰çº¿ç¨‹
        threads = []
        for i in range(num_threads):
            thread = threading.Thread(target=worker, args=(i,))
            threads.append(thread)
            thread.start()

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()

        # åˆ†æç»“æœ
        successful_operations = [r for r in results if r.get('success', False)]
        failed_operations = [r for r in results if not r.get('success', True)]

        success_rate = len(successful_operations) / len(results) * 100 if results else 0
        avg_response_time = sum(r.get('response_time', 0) for r in successful_operations) / len(successful_operations) if successful_operations else 0

        self.test_results['performance_metrics']['concurrent_access'] = {
            'total_operations': len(results),
            'successful_operations': len(successful_operations),
            'failed_operations': len(failed_operations),
            'success_rate': success_rate,
            'avg_response_time': avg_response_time,
            'errors': errors[:5]  # ä¿ç•™å‰5ä¸ªé”™è¯¯
        }

        passed = success_rate >= 95 and len(errors) == 0
        self.record_test_result(
            "concurrent_cache_access",
            passed,
            f"æˆåŠŸç‡: {success_rate:.1f}%, å¹³å‡å“åº”æ—¶é—´: {avg_response_time*1000:.1f}ms"
        )

    def test_double_checked_locking(self):
        """æµ‹è¯•åŒé‡æ£€æŸ¥é”å®š"""
        print("\nğŸ”’ æµ‹è¯•åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼")

        cache = get_git_cache(self.project_root, cache_timeout=10)
        cache.clear_cache()  # æ¸…ç©ºç¼“å­˜å¼€å§‹æµ‹è¯•

        results = {}
        execution_times = []

        def worker(thread_id: int):
            """å·¥ä½œçº¿ç¨‹"""
            start_time = time.time()
            result = cache.batch_git_status()
            end_time = time.time()

            results[thread_id] = {
                'result': result,
                'execution_time': end_time - start_time,
                'timestamp': end_time
            }
            execution_times.append(end_time - start_time)

        # åŒæ—¶å¯åŠ¨å¤šä¸ªçº¿ç¨‹
        threads = []
        for i in range(10):
            thread = threading.Thread(target=worker, args=(i,))
            threads.append(thread)

        # å‡ ä¹åŒæ—¶å¯åŠ¨æ‰€æœ‰çº¿ç¨‹
        start_time = time.time()
        for thread in threads:
            thread.start()

        for thread in threads:
            thread.join()
        total_time = time.time() - start_time

        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        first_result = list(results.values())[0]['result']
        data_consistent = all(
            r['result'].get('current_branch') == first_result.get('current_branch')
            for r in results.values()
        )

        # éªŒè¯æ€§èƒ½ - åº”è¯¥æœ‰ç¼“å­˜æ•ˆæœ
        cache_stats = cache.get_stats()
        cache_hits = cache_stats.get('cache_hits', 0)

        passed = data_consistent and cache_hits > 0
        self.record_test_result(
            "double_checked_locking",
            passed,
            f"æ•°æ®ä¸€è‡´æ€§: {'âœ…' if data_consistent else 'âŒ'}, ç¼“å­˜å‘½ä¸­: {cache_hits}, æ€»è€—æ—¶: {total_time:.3f}s"
        )

    def test_cache_invalidation_strategy(self):
        """æµ‹è¯•ç¼“å­˜å¤±æ•ˆç­–ç•¥"""
        print("\nğŸ”„ æµ‹è¯•ç¼“å­˜å¤±æ•ˆç­–ç•¥")

        cache = get_git_cache(self.project_root, cache_timeout=2)  # çŸ­TTL
        cache.clear_cache()

        # ç¬¬ä¸€æ¬¡è¯·æ±‚ - ç¼“å­˜å¤±æ•ˆ
        result1 = cache.batch_git_status()
        stats1 = cache.get_stats()

        # ç¬¬äºŒæ¬¡è¯·æ±‚ - ç¼“å­˜å‘½ä¸­
        result2 = cache.batch_git_status()
        stats2 = cache.get_stats()

        # ç­‰å¾…ç¼“å­˜è¿‡æœŸ
        time.sleep(3)

        # ç¬¬ä¸‰æ¬¡è¯·æ±‚ - ç¼“å­˜åº”è¯¥å·²è¿‡æœŸ
        result3 = cache.batch_git_status()
        stats3 = cache.get_stats()

        # å¼ºåˆ¶åˆ·æ–°æµ‹è¯•
        cache.force_refresh_cache()
        result4 = cache.batch_git_status()
        stats4 = cache.get_stats()

        # éªŒè¯ç¼“å­˜è¡Œä¸º
        cache_hit_increase = stats2['cache_hits'] > stats1['cache_hits']
        cache_miss_after_expire = stats3['cache_misses'] > stats2['cache_misses']
        invalidation_count = stats4.get('cache_invalidations', 0)

        passed = cache_hit_increase and cache_miss_after_expire and invalidation_count > 0
        self.record_test_result(
            "cache_invalidation_strategy",
            passed,
            f"ç¼“å­˜å‘½ä¸­å¢åŠ : {'âœ…' if cache_hit_increase else 'âŒ'}, "
            f"è¿‡æœŸåå¤±æ•ˆ: {'âœ…' if cache_miss_after_expire else 'âŒ'}, "
            f"å¼ºåˆ¶å¤±æ•ˆ: {invalidation_count}"
        )

    def test_error_recovery_mechanism(self):
        """æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶"""
        print("\nğŸ”§ æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶")

        cache = get_git_cache("/invalid/path", cache_timeout=5)  # æ— æ•ˆè·¯å¾„

        error_count = 0
        successful_fallback = 0

        # è¿ç»­æ‰§è¡Œå¤šæ¬¡ä¼šå‡ºé”™çš„æ“ä½œ
        for i in range(5):
            try:
                result = cache.batch_git_status()
                if 'error' in str(result).lower() or result.get('current_branch') == 'unknown':
                    successful_fallback += 1
                else:
                    # å¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œè¯´æ˜å¯èƒ½æœ‰å¤‡ç”¨æœºåˆ¶
                    successful_fallback += 1
            except Exception:
                error_count += 1

        # æµ‹è¯•é”™è¯¯è®¡æ•°æœºåˆ¶
        stats = cache.get_stats()

        # éªŒè¯å¥åº·æ£€æŸ¥
        health_report = cache.get_cache_health_report()

        passed = successful_fallback > 0 and health_report is not None
        self.record_test_result(
            "error_recovery_mechanism",
            passed,
            f"é”™è¯¯æ•°: {error_count}, æˆåŠŸå›é€€: {successful_fallback}, "
            f"å¥åº·åˆ†æ•°: {health_report.get('health_score', 0)}"
        )

    def test_cache_manager_singleton(self):
        """æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨å•ä¾‹æ¨¡å¼"""
        print("\nğŸ—ï¸ æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨å•ä¾‹æ¨¡å¼")

        managers = []

        def get_manager_worker():
            manager = GitCacheManager.get_instance()
            managers.append(id(manager))

        threads = []
        for i in range(10):
            thread = threading.Thread(target=get_manager_worker)
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        # æ‰€æœ‰ç®¡ç†å™¨åº”è¯¥æ˜¯åŒä¸€ä¸ªå®ä¾‹
        unique_managers = set(managers)

        passed = len(unique_managers) == 1
        self.record_test_result(
            "cache_manager_singleton",
            passed,
            f"å”¯ä¸€ç®¡ç†å™¨å®ä¾‹: {len(unique_managers) == 1}, å®ä¾‹IDæ•°: {len(unique_managers)}"
        )

    def test_fine_grained_locking(self):
        """æµ‹è¯•ç»†ç²’åº¦é”å®š"""
        print("\nğŸ” æµ‹è¯•ç»†ç²’åº¦é”å®šæœºåˆ¶")

        cache = get_git_cache(self.project_root, cache_timeout=10)
        cache.clear_cache()

        lock_wait_counts = []

        def concurrent_different_operations(thread_id: int):
            """æ‰§è¡Œä¸åŒç±»å‹çš„æ“ä½œ"""
            start_time = time.time()

            if thread_id % 3 == 0:
                cache.batch_git_status()
            elif thread_id % 3 == 1:
                cache.get_cached_git_result(['git', 'rev-parse', 'HEAD'])
            else:
                cache.batch_get_file_diff(['README.md'])

            end_time = time.time()

            # è·å–é”ç­‰å¾…ç»Ÿè®¡
            stats = cache.get_stats()
            lock_wait_counts.append(stats.get('lock_waits', 0))

        # å¯åŠ¨å¤šçº¿ç¨‹æ‰§è¡Œä¸åŒæ“ä½œ
        threads = []
        for i in range(15):
            thread = threading.Thread(target=concurrent_different_operations, args=(i,))
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        # åˆ†æé”ç«äº‰æƒ…å†µ
        final_stats = cache.get_stats()
        total_lock_waits = final_stats.get('lock_waits', 0)
        total_requests = final_stats.get('cache_hits', 0) + final_stats.get('cache_misses', 0)

        lock_contention_ratio = total_lock_waits / max(total_requests, 1)

        # ç»†ç²’åº¦é”åº”è¯¥é™ä½é”ç«äº‰
        passed = lock_contention_ratio < 2.0  # åˆç†çš„é”ç«äº‰æ¯”ä¾‹
        self.record_test_result(
            "fine_grained_locking",
            passed,
            f"é”ç«äº‰æ¯”ä¾‹: {lock_contention_ratio:.2f}, æ€»é”ç­‰å¾…: {total_lock_waits}"
        )

    def test_cache_size_limits_and_eviction(self):
        """æµ‹è¯•ç¼“å­˜å¤§å°é™åˆ¶å’Œé©±é€ç­–ç•¥"""
        print("\nğŸ“¦ æµ‹è¯•ç¼“å­˜å¤§å°é™åˆ¶å’Œé©±é€ç­–ç•¥")

        cache = get_git_cache(self.project_root, cache_timeout=60)  # é•¿TTL
        cache.clear_cache()

        # å¼ºåˆ¶ç¼“å­˜å¾ˆå¤šä¸åŒçš„æ¡ç›®
        commands = [
            ['git', 'rev-parse', 'HEAD'],
            ['git', 'status', '--porcelain'],
            ['git', 'log', '-1', '--oneline'],
            ['git', 'branch', '-a'],
            ['git', 'remote', '-v']
        ]

        initial_size = len(cache._cache)

        # æ‰§è¡Œå¤§é‡ä¸åŒçš„å‘½ä»¤ä»¥å¡«å……ç¼“å­˜
        for i in range(50):
            for cmd in commands:
                # æ·»åŠ éšæœºå‚æ•°ä½¿æ¯ä¸ªå‘½ä»¤éƒ½ä¸åŒ
                modified_cmd = cmd + [f'--dummy-{i}-{random.randint(1, 1000)}']
                try:
                    cache.get_cached_git_result(modified_cmd)
                except:
                    pass  # å¿½ç•¥é”™è¯¯ï¼Œå…³æ³¨ç¼“å­˜è¡Œä¸º

        stats = cache.get_stats()
        cache_size = stats.get('cache_size', 0)
        max_cache_size = stats.get('max_cache_size', 1000)

        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¢«é™åˆ¶
        cache_within_limits = cache_size <= max_cache_size
        eviction_occurred = stats.get('cache_invalidations', 0) > 0

        passed = cache_within_limits
        self.record_test_result(
            "cache_size_limits_and_eviction",
            passed,
            f"ç¼“å­˜å¤§å°: {cache_size}/{max_cache_size}, "
            f"åœ¨é™åˆ¶å†…: {'âœ…' if cache_within_limits else 'âŒ'}, "
            f"å‘ç”Ÿé©±é€: {'âœ…' if eviction_occurred else 'âŒ'}"
        )

    def test_atomic_cache_operations(self):
        """æµ‹è¯•åŸå­æ€§ç¼“å­˜æ“ä½œ"""
        print("\nâš›ï¸ æµ‹è¯•åŸå­æ€§ç¼“å­˜æ“ä½œ")

        cache = get_git_cache(self.project_root, cache_timeout=10)

        # æµ‹è¯•å¹¶å‘è¯»å†™çš„åŸå­æ€§
        read_results = []
        write_operations = []

        def reader_worker(thread_id: int):
            """è¯»å–å·¥ä½œçº¿ç¨‹"""
            for i in range(20):
                try:
                    result = cache.batch_git_status()
                    read_results.append({
                        'thread_id': thread_id,
                        'iteration': i,
                        'result': result.get('current_branch', 'unknown'),
                        'timestamp': time.time()
                    })
                except Exception as e:
                    read_results.append({
                        'thread_id': thread_id,
                        'iteration': i,
                        'error': str(e),
                        'timestamp': time.time()
                    })
                time.sleep(0.01)

        def writer_worker():
            """å†™å…¥å·¥ä½œçº¿ç¨‹ï¼ˆç¼“å­˜æ¸…ç†ï¼‰"""
            for i in range(5):
                time.sleep(0.05)
                cache.clear_cache()
                write_operations.append({
                    'operation': 'clear_cache',
                    'timestamp': time.time()
                })

        # å¯åŠ¨è¯»å†™çº¿ç¨‹
        readers = [threading.Thread(target=reader_worker, args=(i,)) for i in range(3)]
        writer = threading.Thread(target=writer_worker)

        for reader in readers:
            reader.start()
        writer.start()

        for reader in readers:
            reader.join()
        writer.join()

        # éªŒè¯åŸå­æ€§ - æ²¡æœ‰æŸåçš„æ•°æ®
        valid_reads = [r for r in read_results if 'error' not in r and r.get('result') != '']
        corrupted_reads = [r for r in read_results if 'error' in r and 'corrupt' in str(r.get('error', '')).lower()]

        passed = len(corrupted_reads) == 0 and len(valid_reads) > 0
        self.record_test_result(
            "atomic_cache_operations",
            passed,
            f"æœ‰æ•ˆè¯»å–: {len(valid_reads)}, æŸåè¯»å–: {len(corrupted_reads)}, "
            f"å†™æ“ä½œ: {len(write_operations)}"
        )

    def run_performance_benchmark(self):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\nğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•")

        cache = get_git_cache(self.project_root, cache_timeout=30)

        # å•çº¿ç¨‹æ€§èƒ½
        start_time = time.time()
        for _ in range(100):
            cache.batch_git_status()
        single_thread_time = time.time() - start_time

        # æ¸…ç†ç¼“å­˜é‡æ–°æµ‹è¯•
        cache.clear_cache()

        # å¤šçº¿ç¨‹æ€§èƒ½
        def multi_thread_worker():
            for _ in range(20):
                cache.batch_git_status()

        start_time = time.time()
        threads = [threading.Thread(target=multi_thread_worker) for _ in range(5)]
        for thread in threads:
            thread.start()
        for thread in threads:
            thread.join()
        multi_thread_time = time.time() - start_time

        # æ€§èƒ½æŒ‡æ ‡
        stats = cache.get_stats()
        health_report = cache.get_cache_health_report()

        self.test_results['performance_metrics']['benchmark'] = {
            'single_thread_time': single_thread_time,
            'multi_thread_time': multi_thread_time,
            'cache_stats': stats,
            'health_score': health_report.get('health_score', 0)
        }

        # å¤šçº¿ç¨‹åº”è¯¥æœ‰æ›´å¥½çš„ååé‡ï¼ˆè€ƒè™‘åˆ°ç¼“å­˜ï¼‰
        efficiency_ratio = single_thread_time / multi_thread_time if multi_thread_time > 0 else 0

        passed = efficiency_ratio > 0.5 and health_report.get('health_score', 0) >= 70
        self.record_test_result(
            "performance_benchmark",
            passed,
            f"å•çº¿ç¨‹: {single_thread_time:.3f}s, å¤šçº¿ç¨‹: {multi_thread_time:.3f}s, "
            f"æ•ˆç‡æ¯”: {efficiency_ratio:.2f}, å¥åº·åˆ†æ•°: {health_report.get('health_score', 0)}"
        )

    def print_comprehensive_report(self):
        """æ‰“å°ç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ¯ Gitç¼“å­˜çº¿ç¨‹å®‰å…¨ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
        print("="*80)

        results = self.test_results

        print(f"ğŸ“‹ æµ‹è¯•æ¦‚è§ˆ:")
        print(f"  æ€»æµ‹è¯•æ•°: {results['total_tests']}")
        print(f"  é€šè¿‡æµ‹è¯•: {results['passed_tests']} âœ…")
        print(f"  å¤±è´¥æµ‹è¯•: {results['failed_tests']} âŒ")
        print(f"  æˆåŠŸç‡: {results['passed_tests']/results['total_tests']*100:.1f}%" if results['total_tests'] > 0 else "  æˆåŠŸç‡: N/A")

        print(f"\nğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
        for metric_name, metrics in results['performance_metrics'].items():
            print(f"  {metric_name}:")
            if isinstance(metrics, dict):
                for key, value in metrics.items():
                    if isinstance(value, (int, float)):
                        print(f"    {key}: {value}")
                    elif isinstance(value, list) and len(value) <= 5:
                        print(f"    {key}: {value}")

        print(f"\nğŸ“ æµ‹è¯•è¯¦æƒ…:")
        for detail in results['test_details']:
            print(f"  {detail['status']}: {detail['test']}")
            if detail['details']:
                print(f"      {detail['details']}")

        # è·å–å½“å‰ç¼“å­˜ç»Ÿè®¡
        try:
            all_stats = get_cache_stats()
            print(f"\nğŸ¥ å½“å‰ç¼“å­˜å¥åº·çŠ¶æ€:")
            for cache_key, stats in all_stats.items():
                if isinstance(stats, dict) and 'thread_safety_enabled' in stats:
                    print(f"  ç¼“å­˜ {cache_key}:")
                    print(f"    çº¿ç¨‹å®‰å…¨: âœ…")
                    print(f"    å‘½ä¸­ç‡: {stats.get('hit_rate', 'N/A')}")
                    print(f"    ç¼“å­˜å¤§å°: {stats.get('cache_size', 0)}")
                    print(f"    é”ç­‰å¾…æ¬¡æ•°: {stats.get('lock_waits', 0)}")
        except Exception as e:
            print(f"  è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")

        print("\nğŸ¯ çº¿ç¨‹å®‰å…¨ä¿®å¤éªŒè¯:")
        if results['passed_tests'] >= results['total_tests'] * 0.8:
            print("  âœ… çº¿ç¨‹å®‰å…¨ä¿®å¤æˆåŠŸï¼æ‰€æœ‰å…³é”®æµ‹è¯•é€šè¿‡")
        else:
            print("  âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")

        print("\n" + "="*80)


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Gitç¼“å­˜çº¿ç¨‹å®‰å…¨å®Œæ•´æµ‹è¯•å¼€å§‹")
    print("="*50)

    # é‡ç½®ç¼“å­˜ç¡®ä¿å¹²å‡€çš„æµ‹è¯•ç¯å¢ƒ
    reset_git_cache()

    tester = ComprehensiveThreadSafetyTest()

    try:
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        test_methods = [
            tester.test_concurrent_cache_access,
            tester.test_double_checked_locking,
            tester.test_cache_invalidation_strategy,
            tester.test_error_recovery_mechanism,
            tester.test_cache_manager_singleton,
            tester.test_fine_grained_locking,
            tester.test_cache_size_limits_and_eviction,
            tester.test_atomic_cache_operations,
            tester.run_performance_benchmark
        ]

        for test_method in test_methods:
            try:
                test_method()
            except Exception as e:
                logger.error(f"æµ‹è¯• {test_method.__name__} æ‰§è¡Œå¤±è´¥: {e}")
                tester.record_test_result(
                    test_method.__name__,
                    False,
                    f"æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                )

        # æ‰“å°ç»¼åˆæŠ¥å‘Š
        tester.print_comprehensive_report()

        # æœ€ç»ˆéªŒè¯
        final_success_rate = tester.test_results['passed_tests'] / tester.test_results['total_tests'] * 100
        if final_success_rate >= 80:
            print("\nğŸ‰ çº¿ç¨‹å®‰å…¨ä¿®å¤éªŒè¯æˆåŠŸï¼")
            return 0
        else:
            print(f"\nâš ï¸ çº¿ç¨‹å®‰å…¨ä¿®å¤éœ€è¦æ”¹è¿›ï¼ŒæˆåŠŸç‡: {final_success_rate:.1f}%")
            return 1

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())