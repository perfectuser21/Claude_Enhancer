#!/usr/bin/env python3
"""
Perfect21 è´¨é‡é—¨æµ‹è¯•
==================

æµ‹è¯•è‡ªåŠ¨åŒ–è´¨é‡é—¨ç³»ç»Ÿ
"""

import asyncio
import json
import time
from datetime import datetime
from pathlib import Path

from features.quality_gates.quality_gate_engine import QualityGateEngine, QualityGateConfig
from features.quality_gates.ci_integration import CIIntegration


async def test_individual_gates():
    """æµ‹è¯•å„ä¸ªè´¨é‡é—¨"""
    print("ğŸ” æµ‹è¯•å„ä¸ªè´¨é‡é—¨...")

    config = QualityGateConfig()
    config.min_line_coverage = 70.0  # é™ä½è¦æ±‚ç”¨äºæµ‹è¯•
    config.max_complexity = 20      # é€‚åº¦æ”¾å®½

    engine = QualityGateEngine('.', config)

    # æµ‹è¯•ä»£ç è´¨é‡é—¨
    print("\n1. æµ‹è¯•ä»£ç è´¨é‡é—¨...")
    from features.quality_gates.code_quality_gate import CodeQualityGate
    code_gate = CodeQualityGate('.', config)
    code_result = await code_gate.check('test')
    print(f"   çŠ¶æ€: {code_result.status.value}")
    print(f"   åˆ†æ•°: {code_result.score:.1f}")
    print(f"   æ¶ˆæ¯: {code_result.message}")

    # æµ‹è¯•å®‰å…¨é—¨
    print("\n2. æµ‹è¯•å®‰å…¨é—¨...")
    from features.quality_gates.security_gate import SecurityGate
    security_gate = SecurityGate('.', config)
    security_result = await security_gate.check('test')
    print(f"   çŠ¶æ€: {security_result.status.value}")
    print(f"   åˆ†æ•°: {security_result.score:.1f}")
    print(f"   æ¶ˆæ¯: {security_result.message}")

    # æµ‹è¯•è¦†ç›–ç‡é—¨
    print("\n3. æµ‹è¯•è¦†ç›–ç‡é—¨...")
    from features.quality_gates.coverage_gate import CoverageGate
    coverage_gate = CoverageGate('.', config)
    coverage_result = await coverage_gate.check('test')
    print(f"   çŠ¶æ€: {coverage_result.status.value}")
    print(f"   åˆ†æ•°: {coverage_result.score:.1f}")
    print(f"   æ¶ˆæ¯: {coverage_result.message}")

    # æµ‹è¯•æ€§èƒ½é—¨
    print("\n4. æµ‹è¯•æ€§èƒ½é—¨...")
    from features.quality_gates.performance_gate import PerformanceGate
    performance_gate = PerformanceGate('.', config)
    performance_result = await performance_gate.check('test')
    print(f"   çŠ¶æ€: {performance_result.status.value}")
    print(f"   åˆ†æ•°: {performance_result.score:.1f}")
    print(f"   æ¶ˆæ¯: {performance_result.message}")

    # æµ‹è¯•æ¶æ„é—¨
    print("\n5. æµ‹è¯•æ¶æ„é—¨...")
    from features.quality_gates.architecture_gate import ArchitectureGate
    architecture_gate = ArchitectureGate('.', config)
    architecture_result = await architecture_gate.check('test')
    print(f"   çŠ¶æ€: {architecture_result.status.value}")
    print(f"   åˆ†æ•°: {architecture_result.score:.1f}")
    print(f"   æ¶ˆæ¯: {architecture_result.message}")

    return {
        'code_quality': code_result,
        'security': security_result,
        'coverage': coverage_result,
        'performance': performance_result,
        'architecture': architecture_result
    }


async def test_quality_gate_engine():
    """æµ‹è¯•è´¨é‡é—¨å¼•æ“"""
    print("\nğŸ¯ æµ‹è¯•è´¨é‡é—¨å¼•æ“...")

    config = QualityGateConfig()
    config.min_line_coverage = 70.0
    config.max_complexity = 20
    config.parallel_execution = True
    config.fail_fast = False

    engine = QualityGateEngine('.', config)

    # æµ‹è¯•å¿«é€Ÿæ£€æŸ¥
    print("\n1. æµ‹è¯•å¿«é€Ÿæ£€æŸ¥...")
    start_time = time.time()
    quick_results = await engine.run_quick_check()
    quick_time = time.time() - start_time

    print(f"   çŠ¶æ€: {quick_results['status']}")
    print(f"   åˆ†æ•°: {quick_results['score']:.1f}")
    print(f"   è€—æ—¶: {quick_time:.2f}ç§’")
    print(f"   æ¶ˆæ¯: {quick_results['message']}")

    # æµ‹è¯•å®Œæ•´æ£€æŸ¥
    print("\n2. æµ‹è¯•å®Œæ•´æ£€æŸ¥...")
    start_time = time.time()
    full_results = await engine.run_all_gates('test')
    full_time = time.time() - start_time

    overall = full_results.get('overall')
    print(f"   çŠ¶æ€: {overall.status.value if overall else 'unknown'}")
    print(f"   åˆ†æ•°: {overall.score:.1f if overall else 0}")
    print(f"   è€—æ—¶: {full_time:.2f}ç§’")
    print(f"   æ‰§è¡Œçš„è´¨é‡é—¨: {len(full_results) - 1}")  # å‡å»overall

    # ç”ŸæˆæŠ¥å‘Š
    print("\n3. ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
    report = engine.generate_report(full_results)
    print(report)

    # æµ‹è¯•è´¨é‡è¶‹åŠ¿
    print("\n4. æµ‹è¯•è´¨é‡è¶‹åŠ¿...")
    trends = engine.get_quality_trends(days=7)
    print(f"   æ€»æ‰§è¡Œæ¬¡æ•°: {trends.get('total_executions', 0)}")
    print(f"   å¸¸è§è¿è§„: {list(trends.get('common_violations', {}).keys())[:3]}")

    return full_results


async def test_ci_integration():
    """æµ‹è¯•CI/CDé›†æˆ"""
    print("\nğŸš€ æµ‹è¯•CI/CDé›†æˆ...")

    ci = CIIntegration('.')

    # æµ‹è¯•Git hooksè®¾ç½®
    print("\n1. æµ‹è¯•Git hooksè®¾ç½®...")
    hooks_result = await ci.setup_pre_commit_hooks()
    print(f"   çŠ¶æ€: {hooks_result['status']}")
    print(f"   æ¶ˆæ¯: {hooks_result['message']}")
    if hooks_result['status'] == 'success':
        print(f"   å®‰è£…çš„hooks: {hooks_result['hooks_installed']}")

    # æµ‹è¯•GitHub Actionsç”Ÿæˆ
    print("\n2. æµ‹è¯•GitHub Actionså·¥ä½œæµç”Ÿæˆ...")
    github_result = await ci.generate_github_actions_workflow()
    print(f"   çŠ¶æ€: {github_result['status']}")
    print(f"   æ¶ˆæ¯: {github_result['message']}")

    # æµ‹è¯•GitLab CIç”Ÿæˆ
    print("\n3. æµ‹è¯•GitLab CIé…ç½®ç”Ÿæˆ...")
    gitlab_result = await ci.generate_gitlab_ci_config()
    print(f"   çŠ¶æ€: {gitlab_result['status']}")
    print(f"   æ¶ˆæ¯: {gitlab_result['message']}")

    # æµ‹è¯•æŒç»­ç›‘æ§è®¾ç½®
    print("\n4. æµ‹è¯•æŒç»­ç›‘æ§è®¾ç½®...")
    monitoring_result = await ci.setup_continuous_monitoring()
    print(f"   çŠ¶æ€: {monitoring_result['status']}")
    print(f"   æ¶ˆæ¯: {monitoring_result['message']}")

    # æµ‹è¯•è´¨é‡ä»ªè¡¨æ¿
    print("\n5. æµ‹è¯•è´¨é‡ä»ªè¡¨æ¿...")
    dashboard_result = await ci.create_quality_dashboard()
    print(f"   çŠ¶æ€: {dashboard_result['status']}")
    print(f"   æ¶ˆæ¯: {dashboard_result['message']}")

    return {
        'hooks': hooks_result,
        'github': github_result,
        'gitlab': gitlab_result,
        'monitoring': monitoring_result,
        'dashboard': dashboard_result
    }


async def test_quality_scenarios():
    """æµ‹è¯•ä¸åŒè´¨é‡åœºæ™¯"""
    print("\nğŸ“‹ æµ‹è¯•ä¸åŒè´¨é‡åœºæ™¯...")

    config = QualityGateConfig()
    engine = QualityGateEngine('.', config)

    scenarios = [
        ('commit', 'æäº¤åœºæ™¯'),
        ('merge', 'åˆå¹¶åœºæ™¯'),
        ('release', 'å‘å¸ƒåœºæ™¯'),
        ('performance_test', 'æ€§èƒ½æµ‹è¯•åœºæ™¯')
    ]

    results = {}

    for context, description in scenarios:
        print(f"\næµ‹è¯• {description} ({context})...")
        start_time = time.time()

        try:
            scenario_results = await engine.run_all_gates(context)
            execution_time = time.time() - start_time

            overall = scenario_results.get('overall')
            if overall:
                print(f"   çŠ¶æ€: {overall.status.value}")
                print(f"   åˆ†æ•°: {overall.score:.1f}")
                print(f"   è€—æ—¶: {execution_time:.2f}ç§’")
                print(f"   è¿è§„æ•°: {len(overall.violations)}")

                results[context] = {
                    'status': overall.status.value,
                    'score': overall.score,
                    'execution_time': execution_time,
                    'violations': len(overall.violations)
                }
            else:
                results[context] = {'error': 'No overall result'}

        except Exception as e:
            print(f"   é”™è¯¯: {str(e)}")
            results[context] = {'error': str(e)}

    return results


async def test_configuration_options():
    """æµ‹è¯•é…ç½®é€‰é¡¹"""
    print("\nâš™ï¸  æµ‹è¯•é…ç½®é€‰é¡¹...")

    # æµ‹è¯•ä¸¥æ ¼é…ç½®
    print("\n1. æµ‹è¯•ä¸¥æ ¼é…ç½®...")
    strict_config = QualityGateConfig()
    strict_config.min_line_coverage = 95.0
    strict_config.max_complexity = 5
    strict_config.max_security_issues = 0
    strict_config.fail_fast = True

    strict_engine = QualityGateEngine('.', strict_config)
    strict_results = await strict_engine.run_quick_check()
    print(f"   ä¸¥æ ¼æ¨¡å¼çŠ¶æ€: {strict_results['status']}")
    print(f"   ä¸¥æ ¼æ¨¡å¼åˆ†æ•°: {strict_results['score']:.1f}")

    # æµ‹è¯•å®½æ¾é…ç½®
    print("\n2. æµ‹è¯•å®½æ¾é…ç½®...")
    lenient_config = QualityGateConfig()
    lenient_config.min_line_coverage = 50.0
    lenient_config.max_complexity = 50
    lenient_config.max_security_issues = 10
    lenient_config.fail_fast = False

    lenient_engine = QualityGateEngine('.', lenient_config)
    lenient_results = await lenient_engine.run_quick_check()
    print(f"   å®½æ¾æ¨¡å¼çŠ¶æ€: {lenient_results['status']}")
    print(f"   å®½æ¾æ¨¡å¼åˆ†æ•°: {lenient_results['score']:.1f}")

    return {
        'strict': strict_results,
        'lenient': lenient_results
    }


async def generate_test_report(results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\nğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")

    report = {
        'timestamp': datetime.now().isoformat(),
        'test_results': results,
        'summary': {
            'total_tests': 5,
            'passed_tests': 0,
            'failed_tests': 0
        }
    }

    # ç»Ÿè®¡æµ‹è¯•ç»“æœ
    for test_name, test_result in results.items():
        if isinstance(test_result, dict) and not test_result.get('error'):
            report['summary']['passed_tests'] += 1
        else:
            report['summary']['failed_tests'] += 1

    # ä¿å­˜æŠ¥å‘Š
    report_file = Path('.perfect21/quality_gates_test_report.json')
    report_file.parent.mkdir(exist_ok=True)

    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    # ç”ŸæˆHTMLæŠ¥å‘Š
    html_report = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Perfect21 è´¨é‡é—¨æµ‹è¯•æŠ¥å‘Š</title>
    <meta charset="utf-8">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        .header {{ background: #2196F3; color: white; padding: 20px; border-radius: 8px; }}
        .summary {{ background: #f5f5f5; padding: 15px; margin: 20px 0; border-radius: 5px; }}
        .test-result {{ background: white; border: 1px solid #ddd; margin: 10px 0; padding: 15px; border-radius: 5px; }}
        .passed {{ border-left: 4px solid #4caf50; }}
        .failed {{ border-left: 4px solid #f44336; }}
        .code {{ background: #f8f8f8; padding: 10px; font-family: monospace; font-size: 12px; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ¯ Perfect21 è´¨é‡é—¨æµ‹è¯•æŠ¥å‘Š</h1>
        <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    </div>

    <div class="summary">
        <h2>ğŸ“‹ æµ‹è¯•æ‘˜è¦</h2>
        <p>æ€»æµ‹è¯•æ•°: {report['summary']['total_tests']}</p>
        <p>é€šè¿‡: {report['summary']['passed_tests']}</p>
        <p>å¤±è´¥: {report['summary']['failed_tests']}</p>
        <p>æˆåŠŸç‡: {(report['summary']['passed_tests'] / report['summary']['total_tests'] * 100):.1f}%</p>
    </div>
    """

    for test_name, test_result in results.items():
        status_class = 'passed' if not test_result.get('error') else 'failed'
        html_report += f"""
    <div class="test-result {status_class}">
        <h3>{test_name}</h3>
        <div class="code">{json.dumps(test_result, indent=2, ensure_ascii=False)}</div>
    </div>
        """

    html_report += """
</body>
</html>
    """

    html_file = Path('.perfect21/quality_gates_test_report.html')
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(html_report)

    print(f"ğŸŒ HTMLæŠ¥å‘Šå·²ä¿å­˜: {html_file}")
    print(f"   åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: file://{html_file.absolute()}")

    return report


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Perfect21è´¨é‡é—¨æµ‹è¯•")
    print("=" * 60)

    results = {}

    try:
        # 1. æµ‹è¯•å„ä¸ªè´¨é‡é—¨
        results['individual_gates'] = await test_individual_gates()

        # 2. æµ‹è¯•è´¨é‡é—¨å¼•æ“
        results['gate_engine'] = await test_quality_gate_engine()

        # 3. æµ‹è¯•CI/CDé›†æˆ
        results['ci_integration'] = await test_ci_integration()

        # 4. æµ‹è¯•ä¸åŒåœºæ™¯
        results['scenarios'] = await test_quality_scenarios()

        # 5. æµ‹è¯•é…ç½®é€‰é¡¹
        results['configurations'] = await test_configuration_options()

        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        report = await generate_test_report(results)

        print("\n" + "=" * 60)
        print("ğŸ‰ æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“Š é€šè¿‡: {report['summary']['passed_tests']}/{report['summary']['total_tests']}")

        if report['summary']['failed_tests'] > 0:
            print("âš ï¸  è¯·æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•å¹¶ä¿®å¤é—®é¢˜")
            return 1
        else:
            print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
            return 0

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
        return 1


if __name__ == "__main__":
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)