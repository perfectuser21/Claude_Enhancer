#!/usr/bin/env python3
"""
Perfect21 è¾¹ç•Œæ¡ä»¶ç»¼åˆæµ‹è¯•
æµ‹è¯•ç©ºè¾“å…¥ã€å¼‚å¸¸è¾“å…¥ã€å¹¶å‘æ‰§è¡Œé™åˆ¶ã€é”™è¯¯æ¢å¤æœºåˆ¶
"""

import os
import sys
import time
import json
import unittest
import threading
import asyncio
import psutil
import gc
import tempfile
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from unittest.mock import Mock, patch
import subprocess

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

class TestInputValidation(unittest.TestCase):
    """æµ‹è¯•è¾“å…¥éªŒè¯å’Œè¾¹ç•Œæ¡ä»¶"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        try:
            from features.workflow_orchestrator.dynamic_workflow_generator import DynamicWorkflowGenerator
            self.generator = DynamicWorkflowGenerator()
        except ImportError:
            self.generator = Mock()
            self.generator.generate_workflow.return_value = {
                'name': 'mock_workflow',
                'stages': [],
                'task_requirements': {},
                'execution_metadata': {}
            }

    def test_empty_and_whitespace_inputs(self):
        """æµ‹è¯•ç©ºè¾“å…¥å’Œç©ºç™½å­—ç¬¦è¾“å…¥"""
        empty_inputs = [
            "",           # ç©ºå­—ç¬¦ä¸²
            " ",          # å•ä¸ªç©ºæ ¼
            "\t",         # åˆ¶è¡¨ç¬¦
            "\n",         # æ¢è¡Œç¬¦
            "   ",        # å¤šä¸ªç©ºæ ¼
            "\t\n  \r",   # æ··åˆç©ºç™½å­—ç¬¦
            None,         # Noneå€¼
        ]

        for i, empty_input in enumerate(empty_inputs):
            with self.subTest(input_type=f"empty_input_{i}", input_value=repr(empty_input)):
                if empty_input is None:
                    # æµ‹è¯•Noneè¾“å…¥
                    with self.assertRaises((TypeError, ValueError, AttributeError)):
                        self.generator.generate_workflow(empty_input)
                else:
                    try:
                        result = self.generator.generate_workflow(empty_input)

                        # å¦‚æœæ²¡æœ‰æŠ›å‡ºå¼‚å¸¸ï¼ŒéªŒè¯è¿”å›ç»“æœ
                        if hasattr(self.generator, 'generate_workflow') and not isinstance(self.generator, Mock):
                            self.assertIsInstance(result, dict)
                            if 'stages' in result:
                                self.assertIsInstance(result['stages'], list)

                    except (ValueError, TypeError) as e:
                        # ç©ºè¾“å…¥æŠ›å‡ºè¿™äº›å¼‚å¸¸æ˜¯åˆç†çš„
                        error_message = str(e).lower()
                        self.assertTrue(
                            any(keyword in error_message for keyword in ['empty', 'invalid', 'none', 'null']),
                            f"å¼‚å¸¸æ¶ˆæ¯åº”è¯¥è¯´æ˜ç©ºè¾“å…¥é—®é¢˜: {e}"
                        )

    def test_extremely_long_inputs(self):
        """æµ‹è¯•æé•¿è¾“å…¥å¤„ç†"""
        long_inputs = [
            "a" * 1000,      # 1Kå­—ç¬¦
            "æµ‹è¯•" * 500,     # 1Kä¸­æ–‡å­—ç¬¦
            "x" * 10000,     # 10Kå­—ç¬¦
            "very long task description " * 1000,  # é‡å¤çš„é•¿æè¿°
        ]

        for i, long_input in enumerate(long_inputs):
            with self.subTest(input_length=len(long_input), test_case=i):
                start_time = time.time()

                try:
                    result = self.generator.generate_workflow(long_input)
                    execution_time = time.time() - start_time

                    # éªŒè¯æ‰§è¡Œæ—¶é—´åˆç†
                    self.assertLess(execution_time, 5.0,
                                  f"å¤„ç†é•¿è¾“å…¥({len(long_input)}å­—ç¬¦)è€—æ—¶è¿‡é•¿: {execution_time:.2f}ç§’")

                    # éªŒè¯ç»“æœç»“æ„
                    if isinstance(result, dict):
                        self.assertIn('name', result)

                except (MemoryError, TimeoutError, ValueError) as e:
                    # è¿™äº›å¼‚å¸¸å¯¹äºæé•¿è¾“å…¥æ˜¯å¯ä»¥æ¥å—çš„
                    print(f"é•¿è¾“å…¥({len(long_input)}å­—ç¬¦)å¤„ç†å¼‚å¸¸: {type(e).__name__}")

    def test_special_characters_and_encoding(self):
        """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å’Œç¼–ç å¤„ç†"""
        special_inputs = [
            "ä»»åŠ¡åŒ…å«ä¸­æ–‡å­—ç¬¦å’Œè‹±æ–‡mixed",
            "Task with Ã©mojis ğŸš€ğŸ”¥ğŸ’»ğŸ¯ğŸ“Š",
            "Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸",
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù†Øµ",
            "æ—¥æœ¬èªã®ã‚¿ã‚¹ã‚¯èª¬æ˜",
            "Special chars: !@#$%^&*()_+-=[]{}|;:',.<>?",
            "Path separators: \\windows\\path and /unix/path",
            "Quotes: 'single' and \"double\" and `backtick`",
            "Numbers: 123456789 and floating 3.14159",
            "æ··åˆcontent with 123 numbers and ğŸ‰ emoji",
        ]

        for special_input in special_inputs:
            with self.subTest(input=special_input[:30] + "..."):
                try:
                    result = self.generator.generate_workflow(special_input)

                    # éªŒè¯åŸºæœ¬ç»“æ„
                    if isinstance(result, dict):
                        # éªŒè¯ä»»åŠ¡æè¿°è¢«æ­£ç¡®ä¿å­˜
                        if 'global_context' in result and 'task_description' in result['global_context']:
                            saved_description = result['global_context']['task_description']
                            self.assertEqual(saved_description, special_input,
                                           "ä»»åŠ¡æè¿°åº”è¯¥å®Œæ•´ä¿å­˜ï¼ŒåŒ…æ‹¬ç‰¹æ®Šå­—ç¬¦")

                except UnicodeError as e:
                    self.fail(f"ç¼–ç é”™è¯¯ä¸åº”è¯¥å‘ç”Ÿ: {e}")
                except Exception as e:
                    # è®°å½•ä½†ä¸å¤±è´¥ï¼Œå› ä¸ºæŸäº›ç‰¹æ®Šå­—ç¬¦å¯èƒ½ç¡®å®ä¼šå¼•èµ·é—®é¢˜
                    print(f"ç‰¹æ®Šå­—ç¬¦è¾“å…¥ '{special_input[:50]}...' å¼•å‘å¼‚å¸¸: {type(e).__name__}: {e}")

    def test_injection_attack_prevention(self):
        """æµ‹è¯•æ³¨å…¥æ”»å‡»é˜²æŠ¤"""
        malicious_inputs = [
            "<script>alert('xss')</script>",
            "'; DROP TABLE tasks; --",
            "$(rm -rf /)",
            "`cat /etc/passwd`",
            "{{7*7}}",  # æ¨¡æ¿æ³¨å…¥
            "${java.lang.Runtime.getRuntime().exec('calc')}",
            "eval('malicious code')",
            "<iframe src='javascript:alert(1)'></iframe>",
            "\\x00\\x01\\x02",  # æ§åˆ¶å­—ç¬¦
            "../../../etc/passwd",  # è·¯å¾„éå†
        ]

        for malicious_input in malicious_inputs:
            with self.subTest(attack_type=malicious_input[:30]):
                try:
                    result = self.generator.generate_workflow(malicious_input)

                    # éªŒè¯æ¶æ„ä»£ç æ²¡æœ‰è¢«æ‰§è¡Œ
                    if isinstance(result, dict):
                        # æ£€æŸ¥ç»“æœä¸­æ˜¯å¦åŒ…å«åŸå§‹æ¶æ„è¾“å…¥ï¼ˆåº”è¯¥è¢«è½¬ä¹‰æˆ–å¤„ç†ï¼‰
                        result_str = json.dumps(result)

                        # æ¶æ„è„šæœ¬æ ‡ç­¾ä¸åº”è¯¥ä»¥åŸå§‹å½¢å¼å‡ºç°
                        if '<script>' in malicious_input:
                            self.assertNotIn('<script>', result_str,
                                           "æ¶æ„è„šæœ¬æ ‡ç­¾åº”è¯¥è¢«è¿‡æ»¤æˆ–è½¬ä¹‰")

                        # SQLæ³¨å…¥å†…å®¹ä¸åº”è¯¥ä»¥åŸå§‹å½¢å¼å‡ºç°
                        if 'DROP TABLE' in malicious_input:
                            # å…è®¸åœ¨æè¿°ä¸­å‡ºç°ï¼Œä½†ä¸åº”è¯¥åœ¨å…¶ä»–åœ°æ–¹
                            pass

                except Exception as e:
                    # æ‹’ç»å¤„ç†æ¶æ„è¾“å…¥æ˜¯å¯ä»¥æ¥å—çš„
                    print(f"æ¶æ„è¾“å…¥è¢«æ‹’ç»: {type(e).__name__}")

class TestConcurrencyAndLimits(unittest.TestCase):
    """æµ‹è¯•å¹¶å‘æ‰§è¡Œå’Œé™åˆ¶"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        try:
            from features.workflow_orchestrator.dynamic_workflow_generator import DynamicWorkflowGenerator
            self.generator = DynamicWorkflowGenerator()
        except ImportError:
            self.generator = Mock()
            self.generator.generate_workflow.side_effect = lambda x: {
                'name': f'workflow_{hash(x) % 1000}',
                'stages': [{'name': 'test', 'agents': ['test-agent']}]
            }

    def test_concurrent_workflow_generation(self):
        """æµ‹è¯•å¹¶å‘å·¥ä½œæµç”Ÿæˆ"""
        def generate_workflow_task(task_id):
            """å•ä¸ªå·¥ä½œæµç”Ÿæˆä»»åŠ¡"""
            task_description = f"å¹¶å‘æµ‹è¯•ä»»åŠ¡ {task_id}"
            start_time = time.time()

            try:
                result = self.generator.generate_workflow(task_description)
                execution_time = time.time() - start_time

                return {
                    'task_id': task_id,
                    'success': True,
                    'execution_time': execution_time,
                    'result_type': type(result).__name__
                }
            except Exception as e:
                return {
                    'task_id': task_id,
                    'success': False,
                    'error': str(e),
                    'error_type': type(e).__name__
                }

        # æµ‹è¯•ä¸åŒçš„å¹¶å‘çº§åˆ«
        concurrency_levels = [5, 10, 20]

        for max_workers in concurrency_levels:
            with self.subTest(concurrency=max_workers):
                results = []
                start_time = time.time()

                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    futures = [executor.submit(generate_workflow_task, i)
                             for i in range(max_workers)]

                    for future in as_completed(futures, timeout=30):
                        try:
                            result = future.result()
                            results.append(result)
                        except Exception as e:
                            results.append({
                                'success': False,
                                'error': str(e),
                                'error_type': type(e).__name__
                            })

                total_time = time.time() - start_time

                # éªŒè¯ç»“æœ
                successful_results = [r for r in results if r.get('success', False)]
                failed_results = [r for r in results if not r.get('success', False)]

                print(f"å¹¶å‘çº§åˆ« {max_workers}: {len(successful_results)}æˆåŠŸ, {len(failed_results)}å¤±è´¥, æ€»æ—¶é—´{total_time:.2f}ç§’")

                # è‡³å°‘åº”è¯¥æœ‰ä¸€äº›æˆåŠŸçš„ç»“æœ
                success_rate = len(successful_results) / len(results) if results else 0
                self.assertGreater(success_rate, 0.5,
                                 f"å¹¶å‘çº§åˆ«{max_workers}çš„æˆåŠŸç‡({success_rate:.1%})è¿‡ä½")

                # å¹¶å‘æ‰§è¡Œä¸åº”è¯¥æ¯”ä¸²è¡Œæ…¢å¤ªå¤š
                if successful_results:
                    avg_execution_time = sum(r.get('execution_time', 0) for r in successful_results) / len(successful_results)
                    self.assertLess(total_time, avg_execution_time * max_workers * 1.5,
                                  "å¹¶å‘æ‰§è¡Œæ•ˆç‡è¿‡ä½")

    def test_memory_usage_under_load(self):
        """æµ‹è¯•è´Ÿè½½ä¸‹çš„å†…å­˜ä½¿ç”¨"""
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # ç”Ÿæˆå¤§é‡å·¥ä½œæµæ¥æµ‹è¯•å†…å­˜ä½¿ç”¨
        task_count = 100
        for i in range(task_count):
            try:
                task_description = f"å†…å­˜æµ‹è¯•ä»»åŠ¡ {i} " + "é¢å¤–æè¿°å†…å®¹ " * 20
                result = self.generator.generate_workflow(task_description)

                # æ¯20ä¸ªä»»åŠ¡æ£€æŸ¥ä¸€æ¬¡å†…å­˜
                if i % 20 == 0:
                    current_memory = process.memory_info().rss / 1024 / 1024  # MB
                    memory_increase = current_memory - initial_memory

                    # å†…å­˜å¢é•¿åº”è¯¥æ˜¯åˆç†çš„
                    max_allowed_increase = 200  # 200MB
                    if memory_increase > max_allowed_increase:
                        print(f"è­¦å‘Š: å†…å­˜å¢é•¿è¿‡å¤§ {memory_increase:.1f}MB (ä»»åŠ¡{i})")

            except Exception as e:
                print(f"å†…å­˜æµ‹è¯•ä»»åŠ¡ {i} å¤±è´¥: {e}")

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()

        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        total_memory_increase = final_memory - initial_memory

        print(f"å†…å­˜ä½¿ç”¨æµ‹è¯•: åˆå§‹{initial_memory:.1f}MB, æœ€ç»ˆ{final_memory:.1f}MB, å¢é•¿{total_memory_increase:.1f}MB")

        # éªŒè¯å†…å­˜å¢é•¿åœ¨åˆç†èŒƒå›´å†…
        max_total_increase = 300  # 300MB
        self.assertLess(total_memory_increase, max_total_increase,
                       f"æ€»å†…å­˜å¢é•¿({total_memory_increase:.1f}MB)è¶…è¿‡é™åˆ¶({max_total_increase}MB)")

    def test_timeout_handling(self):
        """æµ‹è¯•è¶…æ—¶å¤„ç†"""
        def slow_operation():
            """æ¨¡æ‹Ÿæ…¢æ“ä½œ"""
            time.sleep(3)  # 3ç§’çš„æ…¢æ“ä½œ
            return "å®Œæˆ"

        # æµ‹è¯•è¶…æ—¶å¤„ç†
        async def run_with_timeout():
            try:
                return await asyncio.wait_for(
                    asyncio.get_event_loop().run_in_executor(None, slow_operation),
                    timeout=1.0  # 1ç§’è¶…æ—¶
                )
            except asyncio.TimeoutError:
                return "timeout"

        start_time = time.time()
        result = asyncio.run(run_with_timeout())
        execution_time = time.time() - start_time

        # éªŒè¯è¶…æ—¶å¤„ç†
        self.assertEqual(result, "timeout", "åº”è¯¥å› è¶…æ—¶è€Œå¤±è´¥")
        self.assertLess(execution_time, 2.0, "è¶…æ—¶å¤„ç†åº”è¯¥åŠæ—¶ç”Ÿæ•ˆ")

    def test_resource_cleanup_under_stress(self):
        """æµ‹è¯•å‹åŠ›ä¸‹çš„èµ„æºæ¸…ç†"""
        def create_temporary_resources():
            """åˆ›å»ºä¸´æ—¶èµ„æº"""
            # æ¨¡æ‹Ÿåˆ›å»ºä¸´æ—¶æ–‡ä»¶å’Œå¯¹è±¡
            temp_files = []
            temp_objects = []

            try:
                for i in range(10):
                    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                    temp_file = tempfile.NamedTemporaryFile(delete=False)
                    temp_file.write(b"test data " * 100)
                    temp_file.close()
                    temp_files.append(temp_file.name)

                    # åˆ›å»ºå†…å­˜å¯¹è±¡
                    temp_objects.append([0] * 1000)

                return temp_files, temp_objects

            except Exception as e:
                # æ¸…ç†å·²åˆ›å»ºçš„èµ„æº
                for temp_file in temp_files:
                    try:
                        os.unlink(temp_file)
                    except:
                        pass
                raise e

        # åœ¨å¹¶å‘ç¯å¢ƒä¸‹æµ‹è¯•èµ„æºåˆ›å»ºå’Œæ¸…ç†
        def stress_test_task(task_id):
            try:
                temp_files, temp_objects = create_temporary_resources()

                # æ¨¡æ‹Ÿä¸€äº›å¤„ç†
                time.sleep(0.1)

                # æ¸…ç†èµ„æº
                for temp_file in temp_files:
                    try:
                        os.unlink(temp_file)
                    except:
                        pass

                return {'task_id': task_id, 'success': True, 'files_created': len(temp_files)}

            except Exception as e:
                return {'task_id': task_id, 'success': False, 'error': str(e)}

        # å¹¶å‘æ‰§è¡Œå‹åŠ›æµ‹è¯•
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(stress_test_task, i) for i in range(20)]

            results = []
            for future in as_completed(futures, timeout=30):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    results.append({'success': False, 'error': str(e)})

        # éªŒè¯ç»“æœ
        successful_tasks = [r for r in results if r.get('success', False)]
        success_rate = len(successful_tasks) / len(results) if results else 0

        self.assertGreater(success_rate, 0.8,
                         f"èµ„æºç®¡ç†å‹åŠ›æµ‹è¯•æˆåŠŸç‡({success_rate:.1%})è¿‡ä½")

class TestErrorRecoveryMechanisms(unittest.TestCase):
    """æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶"""

    def test_network_error_simulation(self):
        """æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯å’Œæ¢å¤"""
        class NetworkErrorSimulator:
            def __init__(self):
                self.failure_count = 0
                self.max_failures = 2

            def attempt_network_operation(self):
                """æ¨¡æ‹Ÿç½‘ç»œæ“ä½œï¼Œå‰å‡ æ¬¡å¤±è´¥"""
                self.failure_count += 1
                if self.failure_count <= self.max_failures:
                    raise ConnectionError(f"ç½‘ç»œè¿æ¥å¤±è´¥ (å°è¯• {self.failure_count})")
                return "ç½‘ç»œæ“ä½œæˆåŠŸ"

        def retry_with_backoff(operation, max_retries=3, base_delay=0.1):
            """å¸¦é€€é¿çš„é‡è¯•æœºåˆ¶"""
            for attempt in range(max_retries + 1):
                try:
                    return operation()
                except Exception as e:
                    if attempt == max_retries:
                        raise e

                    delay = base_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                    time.sleep(delay)

        # æµ‹è¯•é‡è¯•æœºåˆ¶
        simulator = NetworkErrorSimulator()
        start_time = time.time()

        try:
            result = retry_with_backoff(simulator.attempt_network_operation)
            execution_time = time.time() - start_time

            self.assertEqual(result, "ç½‘ç»œæ“ä½œæˆåŠŸ")
            self.assertGreater(execution_time, 0.1,  # è‡³å°‘ç»è¿‡äº†ä¸€äº›é‡è¯•å»¶è¿Ÿ
                             "é‡è¯•æœºåˆ¶åº”è¯¥åŒ…å«å»¶è¿Ÿ")

        except Exception as e:
            self.fail(f"é‡è¯•æœºåˆ¶å¤±è´¥: {e}")

    def test_file_system_error_handling(self):
        """æµ‹è¯•æ–‡ä»¶ç³»ç»Ÿé”™è¯¯å¤„ç†"""
        def safe_file_operation(file_path, content="test"):
            """å®‰å…¨çš„æ–‡ä»¶æ“ä½œ"""
            try:
                # å°è¯•å†™å…¥æ–‡ä»¶
                with open(file_path, 'w') as f:
                    f.write(content)
                return f"æˆåŠŸå†™å…¥ {file_path}"

            except PermissionError:
                return f"æƒé™é”™è¯¯: æ— æ³•è®¿é—® {file_path}"
            except FileNotFoundError:
                # å°è¯•åˆ›å»ºç›®å½•
                try:
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    with open(file_path, 'w') as f:
                        f.write(content)
                    return f"åˆ›å»ºç›®å½•åæˆåŠŸå†™å…¥ {file_path}"
                except Exception as e:
                    return f"æ–‡ä»¶æ“ä½œæœ€ç»ˆå¤±è´¥: {e}"
            except Exception as e:
                return f"æœªçŸ¥æ–‡ä»¶é”™è¯¯: {e}"

        # æµ‹è¯•å„ç§æ–‡ä»¶æ“ä½œé”™è¯¯åœºæ™¯
        test_cases = [
            "/tmp/perfect21_test/normal_file.txt",  # æ­£å¸¸æƒ…å†µ
            "/tmp/perfect21_test/deep/nested/file.txt",  # éœ€è¦åˆ›å»ºç›®å½•
        ]

        for file_path in test_cases:
            with self.subTest(file_path=file_path):
                result = safe_file_operation(file_path)

                # éªŒè¯æ“ä½œç»“æœ
                self.assertIsInstance(result, str)
                self.assertTrue(
                    any(keyword in result for keyword in ["æˆåŠŸ", "é”™è¯¯", "å¤±è´¥"]),
                    f"ç»“æœåº”è¯¥åŒ…å«çŠ¶æ€ä¿¡æ¯: {result}"
                )

                # æ¸…ç†æµ‹è¯•æ–‡ä»¶
                try:
                    if os.path.exists(file_path):
                        os.unlink(file_path)
                except:
                    pass

    def test_graceful_degradation(self):
        """æµ‹è¯•ä¼˜é›…é™çº§"""
        class ServiceWithFallback:
            def __init__(self):
                self.primary_service_available = False
                self.secondary_service_available = True

            def get_data(self):
                """å°è¯•å¤šç§æ•°æ®è·å–æ–¹å¼"""
                if self.primary_service_available:
                    return {"source": "primary", "data": "å®Œæ•´æ•°æ®"}

                elif self.secondary_service_available:
                    return {"source": "secondary", "data": "å¤‡ç”¨æ•°æ®"}

                else:
                    return {"source": "fallback", "data": "é»˜è®¤æ•°æ®"}

        service = ServiceWithFallback()

        # æµ‹è¯•å„ç§é™çº§åœºæ™¯
        scenarios = [
            ("ä¸»æœåŠ¡å¯ç”¨", True, True, "primary"),
            ("ä¸»æœåŠ¡ä¸å¯ç”¨ï¼Œå¤‡ç”¨å¯ç”¨", False, True, "secondary"),
            ("æ‰€æœ‰æœåŠ¡ä¸å¯ç”¨", False, False, "fallback"),
        ]

        for scenario_name, primary_available, secondary_available, expected_source in scenarios:
            with self.subTest(scenario=scenario_name):
                service.primary_service_available = primary_available
                service.secondary_service_available = secondary_available

                result = service.get_data()

                self.assertEqual(result["source"], expected_source)
                self.assertIn("data", result)
                self.assertIsInstance(result["data"], str)

    def test_circuit_breaker_pattern(self):
        """æµ‹è¯•æ–­è·¯å™¨æ¨¡å¼"""
        class CircuitBreaker:
            def __init__(self, failure_threshold=3, recovery_timeout=1.0):
                self.failure_threshold = failure_threshold
                self.recovery_timeout = recovery_timeout
                self.failure_count = 0
                self.last_failure_time = None
                self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN

            def call(self, operation):
                if self.state == "OPEN":
                    if time.time() - self.last_failure_time > self.recovery_timeout:
                        self.state = "HALF_OPEN"
                    else:
                        raise Exception("æ–­è·¯å™¨å¼€å¯ï¼ŒæœåŠ¡ä¸å¯ç”¨")

                try:
                    result = operation()
                    if self.state == "HALF_OPEN":
                        self.state = "CLOSED"
                        self.failure_count = 0
                    return result

                except Exception as e:
                    self.failure_count += 1
                    self.last_failure_time = time.time()

                    if self.failure_count >= self.failure_threshold:
                        self.state = "OPEN"

                    raise e

        # æ¨¡æ‹Ÿä¸ç¨³å®šçš„æœåŠ¡
        class UnstableService:
            def __init__(self):
                self.call_count = 0

            def unstable_operation(self):
                self.call_count += 1
                if self.call_count <= 3:  # å‰3æ¬¡è°ƒç”¨å¤±è´¥
                    raise Exception(f"æœåŠ¡å¤±è´¥ {self.call_count}")
                return f"æœåŠ¡æˆåŠŸ {self.call_count}"

        # æµ‹è¯•æ–­è·¯å™¨
        circuit_breaker = CircuitBreaker(failure_threshold=3, recovery_timeout=0.5)
        service = UnstableService()

        results = []

        # è¿›è¡Œå¤šæ¬¡è°ƒç”¨æµ‹è¯•
        for i in range(8):
            try:
                result = circuit_breaker.call(service.unstable_operation)
                results.append(f"æˆåŠŸ: {result}")
            except Exception as e:
                results.append(f"å¤±è´¥: {e}")

            # åœ¨æ–­è·¯å™¨æ‰“å¼€åç­‰å¾…æ¢å¤
            if i == 4:
                time.sleep(0.6)  # ç­‰å¾…æ¢å¤è¶…æ—¶

        # éªŒè¯æ–­è·¯å™¨è¡Œä¸º
        failure_results = [r for r in results if r.startswith("å¤±è´¥")]
        success_results = [r for r in results if r.startswith("æˆåŠŸ")]

        # åº”è¯¥æœ‰å¤±è´¥å’ŒæˆåŠŸçš„ç»“æœ
        self.assertGreater(len(failure_results), 0, "åº”è¯¥æœ‰å¤±è´¥çš„è°ƒç”¨")
        self.assertGreater(len(success_results), 0, "åº”è¯¥æœ‰æˆåŠŸçš„è°ƒç”¨")

        # éªŒè¯æ–­è·¯å™¨æœ€ç»ˆæ¢å¤
        circuit_breaker_final_state = circuit_breaker.state
        self.assertIn(circuit_breaker_final_state, ["CLOSED", "HALF_OPEN"],
                     "æ–­è·¯å™¨æœ€ç»ˆåº”è¯¥æ¢å¤åˆ°å¯ç”¨çŠ¶æ€")

def run_boundary_conditions_tests():
    """è¿è¡Œè¾¹ç•Œæ¡ä»¶ç»¼åˆæµ‹è¯•"""
    print("ğŸ”¬ Perfect21 è¾¹ç•Œæ¡ä»¶ç»¼åˆæµ‹è¯•")
    print("=" * 60)

    test_classes = [
        TestInputValidation,
        TestConcurrencyAndLimits,
        TestErrorRecoveryMechanisms,
    ]

    all_results = []
    total_time = 0

    for test_class in test_classes:
        print(f"\nğŸ“‹ è¿è¡Œ {test_class.__name__}")
        print("-" * 40)

        suite = unittest.TestLoader().loadTestsFromTestCase(test_class)
        runner = unittest.TextTestRunner(verbosity=1, stream=sys.stdout)

        start_time = time.time()
        result = runner.run(suite)
        class_time = time.time() - start_time
        total_time += class_time

        all_results.append({
            'class_name': test_class.__name__,
            'tests_run': result.testsRun,
            'failures': len(result.failures),
            'errors': len(result.errors),
            'success_rate': ((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100) if result.testsRun > 0 else 0,
            'execution_time': class_time
        })

    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š è¾¹ç•Œæ¡ä»¶æµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)

    total_tests = sum(r['tests_run'] for r in all_results)
    total_failures = sum(r['failures'] for r in all_results)
    total_errors = sum(r['errors'] for r in all_results)
    overall_success_rate = ((total_tests - total_failures - total_errors) / total_tests * 100) if total_tests > 0 else 0

    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"æˆåŠŸ: {total_tests - total_failures - total_errors}")
    print(f"å¤±è´¥: {total_failures}")
    print(f"é”™è¯¯: {total_errors}")
    print(f"æ•´ä½“æˆåŠŸç‡: {overall_success_rate:.1f}%")
    print(f"æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}ç§’")

    print(f"\nğŸ“‹ å„æµ‹è¯•ç±»ç»“æœ:")
    for result in all_results:
        status_icon = "âœ…" if result['success_rate'] == 100 else "âš ï¸" if result['success_rate'] > 70 else "âŒ"
        print(f"  {status_icon} {result['class_name']}: {result['success_rate']:.1f}% ({result['tests_run']}ä¸ªæµ‹è¯•)")

    # æµ‹è¯•è¦†ç›–èŒƒå›´
    coverage_areas = {
        'ç©ºè¾“å…¥å’Œå¼‚å¸¸è¾“å…¥å¤„ç†': 'âœ… TestInputValidation',
        'ç‰¹æ®Šå­—ç¬¦å’Œç¼–ç å¤„ç†': 'âœ… TestInputValidation',
        'æ³¨å…¥æ”»å‡»é˜²æŠ¤': 'âœ… TestInputValidation',
        'å¹¶å‘æ‰§è¡Œé™åˆ¶': 'âœ… TestConcurrencyAndLimits',
        'å†…å­˜ä½¿ç”¨æ§åˆ¶': 'âœ… TestConcurrencyAndLimits',
        'è¶…æ—¶å¤„ç†æœºåˆ¶': 'âœ… TestConcurrencyAndLimits',
        'ç½‘ç»œé”™è¯¯æ¢å¤': 'âœ… TestErrorRecoveryMechanisms',
        'æ–‡ä»¶ç³»ç»Ÿé”™è¯¯å¤„ç†': 'âœ… TestErrorRecoveryMechanisms',
        'ä¼˜é›…é™çº§æœºåˆ¶': 'âœ… TestErrorRecoveryMechanisms',
        'æ–­è·¯å™¨æ¨¡å¼': 'âœ… TestErrorRecoveryMechanisms',
    }

    print(f"\nğŸ¯ è¾¹ç•Œæ¡ä»¶æµ‹è¯•è¦†ç›–:")
    for area, status in coverage_areas.items():
        print(f"  {status} {area}")

    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    detailed_report = {
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'test_focus': 'Boundary Conditions and Error Handling',
        'overall_stats': {
            'total_tests': total_tests,
            'total_failures': total_failures,
            'total_errors': total_errors,
            'success_rate': overall_success_rate,
            'execution_time': total_time
        },
        'class_results': all_results,
        'coverage_areas': coverage_areas,
        'boundary_conditions_tested': [
            'ç©ºè¾“å…¥å’Œç©ºç™½å­—ç¬¦',
            'æé•¿è¾“å…¥å¤„ç†',
            'ç‰¹æ®Šå­—ç¬¦å’ŒUnicode',
            'æ¶æ„è¾“å…¥é˜²æŠ¤',
            'å¹¶å‘æ‰§è¡Œå‹åŠ›',
            'å†…å­˜ä½¿ç”¨é™åˆ¶',
            'è¶…æ—¶å¤„ç†',
            'ç½‘ç»œé”™è¯¯æ¢å¤',
            'æ–‡ä»¶ç³»ç»Ÿé”™è¯¯',
            'ä¼˜é›…é™çº§',
            'æ–­è·¯å™¨æ¨¡å¼'
        ],
        'summary': f"è¾¹ç•Œæ¡ä»¶ç»¼åˆæµ‹è¯•å®Œæˆï¼ŒæˆåŠŸç‡ {overall_success_rate:.1f}%"
    }

    report_file = 'boundary_conditions_test_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(detailed_report, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    return overall_success_rate >= 75  # 75%æˆåŠŸç‡ä¸ºé€šè¿‡æ ‡å‡†

if __name__ == '__main__':
    success = run_boundary_conditions_tests()
    sys.exit(0 if success else 1)