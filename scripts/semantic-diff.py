#!/usr/bin/env python3
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Semantic Diff Gate - è¯­ä¹‰å¯¹æ¯”å®ˆé—¨ç³»ç»Ÿ
Claude Enhancer Self-Healing Component
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

åŠŸèƒ½ï¼šåœ¨AIä¿®æ”¹æ–‡ä»¶å‰ï¼Œå¯¹æ¯”æ–°æ—§é€»è¾‘å·®å¼‚ï¼Œé˜²æ­¢ï¼š
1. é‡æ–°æ·»åŠ å·²åˆ é™¤çš„åŠŸèƒ½
2. æ¨ç¿»ä¹‹å‰çš„ä¼˜åŒ–å†³ç­–
3. å¼•å…¥å·²è§£å†³çš„é—®é¢˜

åŸç†ï¼šä¸åªæ˜¯æ–‡æœ¬diffï¼Œè€Œæ˜¯è¯­ä¹‰åˆ†æ
- æ£€æµ‹åŠŸèƒ½æ·»åŠ /åˆ é™¤
- æ£€æµ‹é…ç½®å›é€€
- æ£€æµ‹å¤æ‚åº¦å¢åŠ 
- æ£€æµ‹å®šä½åç§»
"""

import os
import sys
import json
import re
import difflib
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é…ç½®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECT_ROOT = Path(__file__).parent.parent
MEMORY_CACHE = PROJECT_ROOT / ".claude" / "memory-cache.json"
CONFIG_FILE = PROJECT_ROOT / ".self-healing.config"

# é¢œè‰²è¾“å‡º
class Colors:
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    CYAN = '\033[0;36m'
    BOLD = '\033[1m'
    NC = '\033[0m'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è¯­ä¹‰åˆ†æå™¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SemanticAnalyzer:
    """è¯­ä¹‰åˆ†æå™¨ - ç†è§£ä»£ç /é…ç½®çš„æ„å›¾å˜åŒ–"""

    def __init__(self):
        self.memory = self.load_memory()
        self.forbidden_patterns = self.load_forbidden_patterns()

    def load_memory(self) -> Dict:
        """åŠ è½½è®°å¿†ç¼“å­˜"""
        if not MEMORY_CACHE.exists():
            return {}

        with open(MEMORY_CACHE, 'r', encoding='utf-8') as f:
            return json.load(f)

    def load_forbidden_patterns(self) -> Dict:
        """åŠ è½½ç¦æ­¢æ¨¡å¼ï¼ˆä»è®°å¿†ä¸­æå–ï¼‰"""
        patterns = {
            'do_not_add_back': [],
            'do_not_recreate': [],
            'forbidden_terms': [],
            'enterprise_features': []
        }

        if 'recent_decisions' in self.memory:
            for decision_key, decision in self.memory['recent_decisions'].items():
                if 'do_not_add_back' in decision:
                    patterns['do_not_add_back'].extend(decision['do_not_add_back'])
                if 'do_not_recreate' in decision and decision.get('do_not_recreate'):
                    if 'deleted_files' in decision:
                        patterns['do_not_recreate'].extend(decision['deleted_files'])
                if 'forbidden_terms' in decision:
                    patterns['forbidden_terms'].extend(decision['forbidden_terms'])

        if 'system_constraints' in self.memory:
            constraints = self.memory['system_constraints']
            if 'forbidden_additions' in constraints:
                fa = constraints['forbidden_additions']
                if 'enterprise_features' in fa:
                    patterns['enterprise_features'].extend(fa['enterprise_features'])

        return patterns

    def analyze_diff(self, old_content: str, new_content: str,
                    file_path: str) -> Tuple[bool, List[str]]:
        """
        åˆ†ææ–‡ä»¶å·®å¼‚çš„è¯­ä¹‰å«ä¹‰

        Returns:
            (is_safe, warnings) - æ˜¯å¦å®‰å…¨ï¼Œè­¦å‘Šåˆ—è¡¨
        """
        warnings = []

        # 1. æ£€æµ‹åŠŸèƒ½é‡æ–°æ·»åŠ 
        warnings.extend(self._check_readded_features(old_content, new_content))

        # 2. æ£€æµ‹æ–‡ä»¶é‡æ–°åˆ›å»º
        warnings.extend(self._check_recreated_files(file_path, old_content, new_content))

        # 3. æ£€æµ‹å®šä½åç§»
        warnings.extend(self._check_positioning_drift(old_content, new_content))

        # 4. æ£€æµ‹å¤æ‚åº¦å¢åŠ 
        warnings.extend(self._check_complexity_increase(old_content, new_content, file_path))

        # 5. æ£€æµ‹ä¼ä¸šåŠŸèƒ½æ·»åŠ 
        warnings.extend(self._check_enterprise_features(new_content, file_path))

        is_safe = len(warnings) == 0
        return is_safe, warnings

    def _check_readded_features(self, old: str, new: str) -> List[str]:
        """æ£€æµ‹å·²åˆ é™¤åŠŸèƒ½çš„é‡æ–°æ·»åŠ """
        warnings = []

        for pattern in self.forbidden_patterns['do_not_add_back']:
            # æ£€æŸ¥ï¼šæ—§ç‰ˆæœ¬æ²¡æœ‰ï¼Œæ–°ç‰ˆæœ¬æœ‰
            pattern_regex = re.compile(re.escape(pattern), re.IGNORECASE)

            old_has = bool(pattern_regex.search(old))
            new_has = bool(pattern_regex.search(new))

            if not old_has and new_has:
                warnings.append(
                    f"ğŸš« æ£€æµ‹åˆ°é‡æ–°æ·»åŠ å·²åˆ é™¤åŠŸèƒ½: '{pattern}'\n"
                    f"   å†å²å†³ç­–: æ­¤åŠŸèƒ½å·²åœ¨ä¹‹å‰å†³ç­–ä¸­åˆ é™¤\n"
                    f"   å»ºè®®: æ£€æŸ¥memory-cache.jsonäº†è§£åˆ é™¤åŸå› "
                )

        return warnings

    def _check_recreated_files(self, file_path: str, old: str, new: str) -> List[str]:
        """æ£€æµ‹å·²åˆ é™¤æ–‡ä»¶çš„é‡æ–°åˆ›å»º"""
        warnings = []

        file_name = os.path.basename(file_path)

        for pattern in self.forbidden_patterns['do_not_recreate']:
            if pattern in file_name or file_name in pattern:
                warnings.append(
                    f"ğŸš« æ£€æµ‹åˆ°é‡æ–°åˆ›å»ºå·²åˆ é™¤æ–‡ä»¶: '{file_name}'\n"
                    f"   å†å²å†³ç­–: æ­¤æ–‡ä»¶å·²åœ¨ä¹‹å‰å†³ç­–ä¸­åˆ é™¤\n"
                    f"   åŸå› : {self._get_deletion_reason(pattern)}\n"
                    f"   å»ºè®®: ç¡®è®¤æ˜¯å¦çœŸçš„éœ€è¦é‡æ–°åˆ›å»º"
                )

        return warnings

    def _check_positioning_drift(self, old: str, new: str) -> List[str]:
        """æ£€æµ‹å®šä½åç§»ï¼ˆå¦‚é‡æ–°å˜æˆä¼ä¸šçº§ï¼‰"""
        warnings = []

        for term in self.forbidden_patterns['forbidden_terms']:
            term_regex = re.compile(re.escape(term), re.IGNORECASE)

            old_has = bool(term_regex.search(old))
            new_has = bool(term_regex.search(new))

            if not old_has and new_has:
                warnings.append(
                    f"ğŸš« æ£€æµ‹åˆ°å®šä½åç§»: æ·»åŠ äº†'{term}'\n"
                    f"   ç³»ç»Ÿå®šä½: ä¸ªäººAIç¼–ç¨‹åŠ©æ‰‹ï¼ˆéä¼ä¸šçº§ï¼‰\n"
                    f"   å»ºè®®: ä½¿ç”¨'ä¸ªäººå·¥å…·'ã€'ç¼–ç¨‹å°ç™½å‹å¥½'ç­‰è¡¨è¿°"
                )

        return warnings

    def _check_complexity_increase(self, old: str, new: str, file_path: str) -> List[str]:
        """æ£€æµ‹å¤æ‚åº¦å¢åŠ """
        warnings = []

        # æ£€æŸ¥æ˜¯å¦æ·»åŠ äº†å¤§é‡æ–°å†…å®¹
        old_lines = old.split('\n')
        new_lines = new.split('\n')

        if len(new_lines) > len(old_lines) * 1.3:  # å¢åŠ è¶…è¿‡30%
            increase = len(new_lines) - len(old_lines)
            warnings.append(
                f"âš ï¸  æ£€æµ‹åˆ°æ–‡ä»¶å¤§å¹…å¢é•¿: +{increase}è¡Œ (+{increase/len(old_lines)*100:.0f}%)\n"
                f"   å½“å‰ç›®æ ‡: ç®€åŒ–ç³»ç»Ÿï¼Œä¿æŒç¼–ç¨‹å°ç™½å‹å¥½\n"
                f"   å»ºè®®: è€ƒè™‘æ˜¯å¦æœ‰æ›´ç®€æ´çš„å®ç°æ–¹å¼"
            )

        # æ£€æŸ¥CLAUDE.mdç‰¹æ®Šé€»è¾‘
        if 'CLAUDE.md' in file_path:
            constraints = self.memory.get('system_constraints', {})
            max_lines = constraints.get('complexity_limits', {}).get('max_claude_md_lines', 400)

            if len(new_lines) > max_lines:
                warnings.append(
                    f"âš ï¸  CLAUDE.mdè¶…è¿‡ç›®æ ‡è¡Œæ•°: {len(new_lines)}è¡Œ (ç›®æ ‡<{max_lines}è¡Œ)\n"
                    f"   ç¼–ç¨‹å°ç™½å‹å¥½åŸåˆ™: æ–‡æ¡£åº”ç®€æ´æ˜“è¯»\n"
                    f"   å»ºè®®: å°†é«˜çº§å†…å®¹ç§»åˆ°docs/advanced/"
                )

        return warnings

    def _check_enterprise_features(self, new: str, file_path: str) -> List[str]:
        """æ£€æµ‹ä¼ä¸šåŠŸèƒ½æ·»åŠ """
        warnings = []

        for feature in self.forbidden_patterns['enterprise_features']:
            if feature in new:
                warnings.append(
                    f"ğŸš« æ£€æµ‹åˆ°ä¼ä¸šçº§åŠŸèƒ½: '{feature}'\n"
                    f"   ç”¨æˆ·å®šä½: ç¼–ç¨‹å°ç™½ + ä¸ªäººé¡¹ç›®\n"
                    f"   å»ºè®®: ç¡®è®¤Max 20Xç”¨æˆ·æ˜¯å¦çœŸçš„éœ€è¦æ­¤åŠŸèƒ½"
                )

        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
        enterprise_paths = ['sre/', 'canary', 'observability/slo']
        for path in enterprise_paths:
            if path in file_path:
                warnings.append(
                    f"ğŸš« æ£€æµ‹åˆ°ä¼ä¸šçº§è·¯å¾„: '{path}' in {file_path}\n"
                    f"   ç”¨æˆ·å®šä½: ä¸ªäººé¡¹ç›®ï¼Œä¸éœ€è¦SRE/é‡‘ä¸é›€ç­‰åŠŸèƒ½\n"
                    f"   å»ºè®®: è€ƒè™‘ä½¿ç”¨æ›´ç®€å•çš„æ›¿ä»£æ–¹æ¡ˆ"
                )

        return warnings

    def _get_deletion_reason(self, file_pattern: str) -> str:
        """è·å–æ–‡ä»¶åˆ é™¤åŸå› """
        for decision_key, decision in self.memory.get('recent_decisions', {}).items():
            if 'deleted_files' in decision:
                for deleted in decision['deleted_files']:
                    if file_pattern in deleted:
                        return decision.get('rationale', 'åŸå› æœªè®°å½•')
        return "åŸå› æœªè®°å½•"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Diffæ¯”å¯¹å™¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DiffComparator:
    """Diffæ¯”å¯¹å™¨ - ç”Ÿæˆå‹å¥½çš„å·®å¼‚æŠ¥å‘Š"""

    def __init__(self):
        self.analyzer = SemanticAnalyzer()

    def compare_files(self, file_path: str, old_content: str,
                     new_content: str, show_diff: bool = True) -> Dict:
        """
        æ¯”å¯¹æ–‡ä»¶å¹¶ç”ŸæˆæŠ¥å‘Š

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            old_content: æ—§å†…å®¹
            new_content: æ–°å†…å®¹
            show_diff: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†diff

        Returns:
            {
                'is_safe': bool,
                'warnings': List[str],
                'diff': str,
                'summary': Dict
            }
        """
        # è¯­ä¹‰åˆ†æ
        is_safe, warnings = self.analyzer.analyze_diff(old_content, new_content, file_path)

        # ç»Ÿè®¡å·®å¼‚
        old_lines = old_content.split('\n')
        new_lines = new_content.split('\n')

        # ç”Ÿæˆunified diff
        diff = list(difflib.unified_diff(
            old_lines,
            new_lines,
            fromfile=f'a/{file_path}',
            tofile=f'b/{file_path}',
            lineterm=''
        ))

        # ç»Ÿè®¡æ·»åŠ /åˆ é™¤
        additions = sum(1 for line in diff if line.startswith('+') and not line.startswith('+++'))
        deletions = sum(1 for line in diff if line.startswith('-') and not line.startswith('---'))

        summary = {
            'additions': additions,
            'deletions': deletions,
            'net_change': additions - deletions,
            'old_lines': len(old_lines),
            'new_lines': len(new_lines)
        }

        return {
            'is_safe': is_safe,
            'warnings': warnings,
            'diff': '\n'.join(diff) if show_diff else '',
            'summary': summary
        }

    def print_report(self, file_path: str, result: Dict):
        """æ‰“å°å‹å¥½çš„æŠ¥å‘Š"""
        print(f"\n{Colors.CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.NC}")
        print(f"{Colors.BOLD}Semantic Diff Gate Report{Colors.NC}")
        print(f"{Colors.CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.NC}\n")

        print(f"{Colors.BOLD}File:{Colors.NC} {file_path}")

        summary = result['summary']
        print(f"\n{Colors.BLUE}Changes:{Colors.NC}")
        print(f"  +{summary['additions']} lines added")
        print(f"  -{summary['deletions']} lines deleted")
        print(f"  Net: {summary['net_change']:+d} lines")
        print(f"  Size: {summary['old_lines']} â†’ {summary['new_lines']} lines")

        if result['warnings']:
            print(f"\n{Colors.YELLOW}{Colors.BOLD}âš ï¸  WARNINGS:{Colors.NC}")
            for warning in result['warnings']:
                print(f"\n{Colors.YELLOW}{warning}{Colors.NC}")

        if result['is_safe']:
            print(f"\n{Colors.GREEN}{Colors.BOLD}âœ… SAFE TO PROCEED{Colors.NC}")
            print(f"{Colors.GREEN}No semantic conflicts detected{Colors.NC}")
        else:
            print(f"\n{Colors.RED}{Colors.BOLD}âŒ REVIEW REQUIRED{Colors.NC}")
            print(f"{Colors.RED}Potential regression or self-contradiction detected{Colors.NC}")
            print(f"\n{Colors.YELLOW}Actions:{Colors.NC}")
            print(f"  1. Review memory-cache.json for context")
            print(f"  2. Confirm this change aligns with previous decisions")
            print(f"  3. Update memory-cache.json if this is a new decision")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLIæ¥å£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Semantic Diff Gate - é˜²æ­¢AIè‡ªæˆ‘æ¨ç¿»çš„è¯­ä¹‰å¯¹æ¯”å·¥å…·"
    )
    parser.add_argument('file', help='è¦æ£€æŸ¥çš„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--old', help='æ—§æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸ºå½“å‰HEADç‰ˆæœ¬ï¼‰')
    parser.add_argument('--new', help='æ–°æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸ºworking treeï¼‰')
    parser.add_argument('--show-diff', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†diff')
    parser.add_argument('--strict', action='store_true', help='ä¸¥æ ¼æ¨¡å¼ï¼ˆä»»ä½•è­¦å‘Šéƒ½å¤±è´¥ï¼‰')

    args = parser.parse_args()

    # è¯»å–æ–‡ä»¶å†…å®¹
    file_path = args.file

    if args.old:
        with open(args.old, 'r') as f:
            old_content = f.read()
    else:
        # ä»gitè¯»å–HEADç‰ˆæœ¬
        import subprocess
        try:
            old_content = subprocess.check_output(
                ['git', 'show', f'HEAD:{file_path}'],
                stderr=subprocess.DEVNULL
            ).decode('utf-8')
        except:
            old_content = ""  # æ–°æ–‡ä»¶

    if args.new:
        with open(args.new, 'r') as f:
            new_content = f.read()
    else:
        # è¯»å–working tree
        with open(file_path, 'r') as f:
            new_content = f.read()

    # æ‰§è¡Œæ¯”å¯¹
    comparator = DiffComparator()
    result = comparator.compare_files(file_path, old_content, new_content, args.show_diff)

    # æ‰“å°æŠ¥å‘Š
    comparator.print_report(file_path, result)

    # è¿”å›é€€å‡ºç 
    if args.strict:
        sys.exit(0 if result['is_safe'] else 1)
    else:
        sys.exit(0)  # éä¸¥æ ¼æ¨¡å¼æ€»æ˜¯æˆåŠŸ

if __name__ == '__main__':
    main()
