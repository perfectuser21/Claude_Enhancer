#!/usr/bin/env python3
"""
Perfect21æ€§èƒ½ä¼˜åŒ–CLI
æä¾›ä¾¿æ·çš„æ€§èƒ½ä¼˜åŒ–å’Œç›‘æ§å‘½ä»¤
"""

import os
import sys
import asyncio
import argparse
import json
import time
from typing import Dict, Any

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from modules.logger import log_info, log_error
from features.performance.performance_optimizer_feature import (
    performance_optimizer_feature,
    optimize_perfect21_performance,
    analyze_perfect21_performance,
    get_perfect21_performance_status
)

def print_performance_report(report: Dict[str, Any]) -> None:
    """æ ¼å¼åŒ–æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
    print("ğŸš€ Perfect21æ€§èƒ½æŠ¥å‘Š")
    print("=" * 60)

    # å¥åº·åˆ†æ•°
    if 'analysis' in report and 'overall_health' in report['analysis']:
        health = report['analysis']['overall_health']
        status_icons = {
            'excellent': 'ğŸŸ¢',
            'good': 'ğŸŸ¡',
            'fair': 'ğŸŸ ',
            'poor': 'ğŸ”´'
        }
        icon = status_icons.get(health['status'], 'âšª')
        print(f"{icon} ç³»ç»Ÿå¥åº·åˆ†æ•°: {health['score']:.1f}/100 ({health['status'].upper()})")
        print()

    # æ ¸å¿ƒæŒ‡æ ‡
    print("ğŸ“Š æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡:")
    print("-" * 40)

    cache_stats = report.get('cache_stats', {})
    if cache_stats:
        hit_rate = cache_stats.get('hit_rate', '0%')
        cache_size = cache_stats.get('total_entries', 0)
        memory_usage = cache_stats.get('total_size_mb', 0)
        print(f"  ğŸ“¦ ç¼“å­˜å‘½ä¸­ç‡: {hit_rate}")
        print(f"  ğŸ“¦ ç¼“å­˜æ¡ç›®æ•°: {cache_size}")
        print(f"  ğŸ“¦ ç¼“å­˜å†…å­˜ä½¿ç”¨: {memory_usage:.2f}MB")

    memory_stats = report.get('memory_stats', {})
    if memory_stats:
        rss_mb = memory_stats.get('rss_mb', 0)
        percent = memory_stats.get('percent', 0)
        print(f"  ğŸ’¾ è¿›ç¨‹å†…å­˜ä½¿ç”¨: {rss_mb:.2f}MB ({percent:.1f}%)")

    git_stats = report.get('git_optimization_stats', {})
    if git_stats:
        optimization_ratio = git_stats.get('optimization_ratio', '0%')
        pending = git_stats.get('pending_operations', 0)
        print(f"  ğŸ”§ Gitä¼˜åŒ–ç‡: {optimization_ratio}")
        print(f"  ğŸ”§ å¾…å¤„ç†Gitæ“ä½œ: {pending}")

    # ç“¶é¢ˆè¯†åˆ«
    if 'analysis' in report and 'bottlenecks' in report['analysis']:
        bottlenecks = report['analysis']['bottlenecks']
        if bottlenecks:
            print("\nâš ï¸  è¯†åˆ«çš„æ€§èƒ½ç“¶é¢ˆ:")
            print("-" * 40)
            for bottleneck in bottlenecks[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                severity_icons = {'high': 'ğŸ”´', 'medium': 'ğŸŸ ', 'low': 'ğŸŸ¡'}
                icon = severity_icons.get(bottleneck['severity'], 'âšª')
                print(f"  {icon} {bottleneck['description']}")

    # ä¼˜åŒ–å»ºè®®
    if 'analysis' in report and 'recommendations' in report['analysis']:
        recommendations = report['analysis']['recommendations']
        if recommendations:
            print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            print("-" * 40)
            for i, rec in enumerate(recommendations[:3], 1):  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                priority_icons = {'high': 'ğŸ”´', 'medium': 'ğŸŸ ', 'low': 'ğŸŸ¡'}
                icon = priority_icons.get(rec['priority'], 'âšª')
                print(f"  {i}. {icon} {rec['title']}")
                print(f"     {rec['description']}")
                print(f"     é¢„æœŸæ”¹å–„: {rec['expected_improvement']}")
                print()

    # åŸºå‡†æµ‹è¯•æ‘˜è¦
    if 'benchmark_summary' in report:
        benchmark = report['benchmark_summary']
        if benchmark:
            print("ğŸ åŸºå‡†æµ‹è¯•æ‘˜è¦:")
            print("-" * 40)
            for test_name, stats in benchmark.items():
                latest = stats.get('latest', 0)
                baseline = stats.get('baseline', 0)
                if baseline > 0:
                    ratio = (latest - baseline) / baseline
                    status = "ğŸ”´ å›å½’" if ratio > 0.2 else "ğŸŸ¢ æ­£å¸¸" if ratio < 0.1 else "ğŸŸ¡ æ³¨æ„"
                    print(f"  {test_name}: {latest:.3f}s {status}")

def print_optimization_result(result: Dict[str, Any]) -> None:
    """æ ¼å¼åŒ–æ‰“å°ä¼˜åŒ–ç»“æœ"""
    print("âš¡ Perfect21æ€§èƒ½ä¼˜åŒ–ç»“æœ")
    print("=" * 50)

    optimization_time = result.get('optimization_time', 0)
    print(f"ğŸ• ä¼˜åŒ–è€—æ—¶: {optimization_time:.3f}ç§’")
    print()

    # å†…å­˜ä¼˜åŒ–ç»“æœ
    if 'memory' in result:
        memory_result = result['memory']
        improvement = memory_result.get('improvement_mb', 0)
        if improvement > 0:
            print(f"ğŸ’¾ å†…å­˜ä¼˜åŒ–: é‡Šæ”¾ {improvement:.2f}MB å†…å­˜")

    # ç¼“å­˜ä¼˜åŒ–ç»“æœ
    if 'cache' in result:
        cache_result = result['cache']
        hit_rate = cache_result.get('hit_rate', '0%')
        print(f"ğŸ“¦ ç¼“å­˜ä¼˜åŒ–: å‘½ä¸­ç‡ {hit_rate}")

    # Gitä¼˜åŒ–ç»“æœ
    if 'git' in result:
        git_result = result['git']
        optimization_ratio = git_result.get('optimization_ratio', '0%')
        print(f"ğŸ”§ Gitä¼˜åŒ–: æ‰¹é‡åŒ–ç‡ {optimization_ratio}")

    # åŸºå‡†æµ‹è¯•ç»“æœ
    if 'benchmark' in result:
        benchmark_result = result['benchmark']
        if 'regressions' in benchmark_result and benchmark_result['regressions']:
            print(f"âš ï¸  æ£€æµ‹åˆ° {len(benchmark_result['regressions'])} ä¸ªæ€§èƒ½å›å½’")
        else:
            print("ğŸŸ¢ åŸºå‡†æµ‹è¯•é€šè¿‡ï¼Œæ— æ€§èƒ½å›å½’")

    print("\nâœ… ä¼˜åŒ–å®Œæˆï¼")

async def cmd_optimize(args: argparse.Namespace) -> None:
    """æ‰§è¡Œæ€§èƒ½ä¼˜åŒ–"""
    optimization_types = []

    if args.memory:
        optimization_types.append('memory')
    if args.cache:
        optimization_types.append('cache')
    if args.git:
        optimization_types.append('git')
    if args.benchmark:
        optimization_types.append('benchmark')

    # å¦‚æœæ²¡æœ‰æŒ‡å®šç±»å‹ï¼Œé»˜è®¤æ‰§è¡Œæ‰€æœ‰ä¼˜åŒ–
    if not optimization_types:
        optimization_types = ['memory', 'cache', 'git', 'benchmark']

    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ€§èƒ½ä¼˜åŒ–: {', '.join(optimization_types)}")
    print("è¯·ç¨å€™...")

    try:
        result = await optimize_perfect21_performance(optimization_types)
        print_optimization_result(result)

        if args.report:
            print("\n" + "=" * 50)
            report = await analyze_perfect21_performance()
            print_performance_report(report)

    except Exception as e:
        log_error(f"æ€§èƒ½ä¼˜åŒ–å¤±è´¥: {e}")
        print(f"âŒ ä¼˜åŒ–å¤±è´¥: {e}")

async def cmd_analyze(args: argparse.Namespace) -> None:
    """æ‰§è¡Œæ€§èƒ½åˆ†æ"""
    print("ğŸ” æ­£åœ¨åˆ†æç³»ç»Ÿæ€§èƒ½...")

    try:
        report = await analyze_perfect21_performance()

        if args.json:
            print(json.dumps(report, indent=2, ensure_ascii=False))
        else:
            print_performance_report(report)

        if args.save:
            filename = args.save or f"performance_report_{int(time.time())}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜è‡³: {filename}")

    except Exception as e:
        log_error(f"æ€§èƒ½åˆ†æå¤±è´¥: {e}")
        print(f"âŒ åˆ†æå¤±è´¥: {e}")

def cmd_status(args: argparse.Namespace) -> None:
    """æ˜¾ç¤ºæ€§èƒ½çŠ¶æ€"""
    try:
        status = get_perfect21_performance_status()

        print("ğŸ“Š Perfect21æ€§èƒ½çŠ¶æ€")
        print("=" * 40)

        print(f"ğŸ“¦ åŠŸèƒ½: {status['name']} v{status['version']}")
        print(f"ğŸ¤– è‡ªåŠ¨ä¼˜åŒ–: {'å¯ç”¨' if status['auto_optimization'] else 'ç¦ç”¨'}")
        print()

        quick_stats = status.get('quick_stats', {})
        if 'cache_stats' in quick_stats:
            cache_stats = quick_stats['cache_stats']
            hit_rate = cache_stats.get('hit_rate', '0%')
            entries = cache_stats.get('total_entries', 0)
            print(f"ğŸ“¦ ç¼“å­˜å‘½ä¸­ç‡: {hit_rate} ({entries} æ¡ç›®)")

        if 'memory_rss_mb' in quick_stats:
            memory = quick_stats['memory_rss_mb']
            print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory:.2f}MB")

        if 'resource_pools' in quick_stats:
            pools = quick_stats['resource_pools']
            print(f"ğŸ”§ èµ„æºæ± æ•°: {pools}")

        if 'optimization_history' in quick_stats:
            history = quick_stats['optimization_history']
            print(f"ğŸ“ˆ ä¼˜åŒ–å†å²: {history} æ¬¡")

        if args.detailed:
            print("\nè¯¦ç»†é…ç½®:")
            print("-" * 20)
            config = status.get('config', {})
            for key, value in config.items():
                print(f"  {key}: {value}")

    except Exception as e:
        log_error(f"è·å–çŠ¶æ€å¤±è´¥: {e}")
        print(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {e}")

async def cmd_benchmark(args: argparse.Namespace) -> None:
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    print("ğŸ è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")

    try:
        from modules.enhanced_performance_optimizer import run_benchmark
        result = run_benchmark()

        if args.json:
            print(json.dumps(result, indent=2, ensure_ascii=False))
            return

        print("\nğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœ:")
        print("-" * 30)

        results = result.get('results', {})
        for test_name, time_taken in results.items():
            print(f"  {test_name}: {time_taken:.3f}ç§’")

        regressions = result.get('regressions', [])
        if regressions:
            print(f"\nâš ï¸  æ£€æµ‹åˆ° {len(regressions)} ä¸ªæ€§èƒ½å›å½’:")
            for regression in regressions:
                print(f"  ğŸ”´ {regression['test_name']}: "
                      f"{regression['current']:.3f}s (åŸºçº¿: {regression['baseline']:.3f}s, "
                      f"å›å½’: {regression['regression_ratio']:.1%})")
        else:
            print("\nğŸŸ¢ æ— æ€§èƒ½å›å½’æ£€æµ‹")

        if args.save:
            filename = args.save or f"benchmark_result_{int(time.time())}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ“ åŸºå‡†æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {filename}")

    except Exception as e:
        log_error(f"åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")

async def cmd_auto_optimize(args: argparse.Namespace) -> None:
    """è‡ªåŠ¨ä¼˜åŒ–æ§åˆ¶"""
    from modules.enhanced_performance_optimizer import enhanced_performance_optimizer

    if args.action == 'start':
        enhanced_performance_optimizer.start_auto_optimization()
        print("ğŸ¤– è‡ªåŠ¨æ€§èƒ½ä¼˜åŒ–å·²å¯åŠ¨")
        print(f"â° ä¼˜åŒ–é—´éš”: {enhanced_performance_optimizer.optimization_interval}ç§’")

    elif args.action == 'stop':
        enhanced_performance_optimizer.stop_auto_optimization()
        print("â¹ï¸  è‡ªåŠ¨æ€§èƒ½ä¼˜åŒ–å·²åœæ­¢")

    elif args.action == 'status':
        status = enhanced_performance_optimizer.auto_optimization
        print(f"ğŸ¤– è‡ªåŠ¨ä¼˜åŒ–çŠ¶æ€: {'è¿è¡Œä¸­' if status else 'å·²åœæ­¢'}")

        if status:
            interval = enhanced_performance_optimizer.optimization_interval
            print(f"â° ä¼˜åŒ–é—´éš”: {interval}ç§’")

def create_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="Perfect21æ€§èƒ½ä¼˜åŒ–CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python3 performance_cli.py optimize --memory --cache
  python3 performance_cli.py analyze --report --save report.json
  python3 performance_cli.py status --detailed
  python3 performance_cli.py benchmark --save benchmark.json
  python3 performance_cli.py auto start
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # optimizeå‘½ä»¤
    optimize_parser = subparsers.add_parser('optimize', help='æ‰§è¡Œæ€§èƒ½ä¼˜åŒ–')
    optimize_parser.add_argument('--memory', action='store_true', help='ä¼˜åŒ–å†…å­˜ä½¿ç”¨')
    optimize_parser.add_argument('--cache', action='store_true', help='ä¼˜åŒ–ç¼“å­˜ç­–ç•¥')
    optimize_parser.add_argument('--git', action='store_true', help='ä¼˜åŒ–Gitæ“ä½œ')
    optimize_parser.add_argument('--benchmark', action='store_true', help='è¿è¡ŒåŸºå‡†æµ‹è¯•')
    optimize_parser.add_argument('--report', action='store_true', help='ä¼˜åŒ–åæ˜¾ç¤ºåˆ†ææŠ¥å‘Š')

    # analyzeå‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze', help='åˆ†æç³»ç»Ÿæ€§èƒ½')
    analyze_parser.add_argument('--json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')
    analyze_parser.add_argument('--save', nargs='?', const=True, help='ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶')

    # statuså‘½ä»¤
    status_parser = subparsers.add_parser('status', help='æ˜¾ç¤ºæ€§èƒ½çŠ¶æ€')
    status_parser.add_argument('--detailed', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†é…ç½®')

    # benchmarkå‘½ä»¤
    benchmark_parser = subparsers.add_parser('benchmark', help='è¿è¡ŒåŸºå‡†æµ‹è¯•')
    benchmark_parser.add_argument('--json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')
    benchmark_parser.add_argument('--save', nargs='?', const=True, help='ä¿å­˜ç»“æœåˆ°æ–‡ä»¶')

    # autoå‘½ä»¤
    auto_parser = subparsers.add_parser('auto', help='è‡ªåŠ¨ä¼˜åŒ–æ§åˆ¶')
    auto_parser.add_argument('action', choices=['start', 'stop', 'status'],
                           help='è‡ªåŠ¨ä¼˜åŒ–æ“ä½œ')

    return parser

async def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    # åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–å™¨
    if not await performance_optimizer_feature.initialize():
        print("âŒ æ€§èƒ½ä¼˜åŒ–å™¨åˆå§‹åŒ–å¤±è´¥")
        return

    try:
        if args.command == 'optimize':
            await cmd_optimize(args)
        elif args.command == 'analyze':
            await cmd_analyze(args)
        elif args.command == 'status':
            cmd_status(args)
        elif args.command == 'benchmark':
            await cmd_benchmark(args)
        elif args.command == 'auto':
            await cmd_auto_optimize(args)
        else:
            parser.print_help()

    except KeyboardInterrupt:
        print("\nâŒ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        log_error(f"æ‰§è¡Œå‘½ä»¤å¤±è´¥: {e}")
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())